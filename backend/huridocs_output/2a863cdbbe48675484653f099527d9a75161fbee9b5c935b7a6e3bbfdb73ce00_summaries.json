{"seg_0": {"summary": "Insufficient content for summary.", "text": "The Impact of Generative AI Coding Assistants on Developers Who Are Visually Impaired", "page": 1, "bbox": []}, "seg_1": {"summary": "Summary: This text segment lists the authors and their affiliations. Claudia Flores-Saviaga, Kashif Imteyaz, and Saiph Savage are affiliated with Northeastern University in the USA, while Benjamin V. Hanrahan and Steven Clarke are affiliated with Microsoft in the USA and United Kingdom, respectively.", "text": "CLAUDIA FLORES-SAVIAGA, Northeastern University, USA BENJAMIN V. HANRAHAN, Microsoft, USA KASHIF IMTEYAZ, Northeastern University, USA STEVEN CLARKE, Microsoft, United Kingdom SAIPH SAVAGE, Northeastern University, USA", "page": 1, "bbox": []}, "seg_3": {"summary": "Summary: Figure 1 provides an overview of research focused on understanding how developers with visual impairments interact with AI coding assistants.  This research aims to analyze the specific ways visually impaired developers use and engage with AI coding assistants.", "text": "Fig. 1. Overview of our research to analyze how developers who are visually impaired interact with AI coding assistants.", "page": 1, "bbox": []}, "seg_4": {"summary": "A study exploring the use of AI coding assistants by developers with visual impairments found that while beneficial, these tools also presented accessibility challenges, such as overwhelming suggestions and difficulty switching between AI-generated and user code.  Despite these issues, participants were optimistic about the potential of AI assistants, highlighting the need for activity-centered design to improve inclusivity and effectiveness for developers with visual impairments.  This approach can lead to more intuitive and accessible AI tools for software development.", "text": "The rapid adoption of generative AI in software development has impacted the industry, yet its effects on developers with visual impairments remain largely unexplored. To address this gap, we used an Activity Theory framework to examine how developers with visual impairments interact with AI coding assistants. For this purpose, we conducted a study where developers who are visually impaired completed a series of programming tasks using a generative AI coding assistant. We uncovered that, while participants found the AI assistant beneficial and reported significant advantages, they also highlighted accessibility challenges. Specifically, the AI coding assistant often exacerbated existing accessibility barriers and introduced new challenges. For example, it overwhelmed users with an excessive number of suggestions, leading developers who are visually impaired to express a desire for \u201cAI timeouts.\u201d Additionally, the generative AI coding assistant made it more difficult for developers to switch contexts between the AI-generated content and their own code. Despite these challenges, participants were optimistic about the potential of AI coding assistants to transform the coding experience for developers with visual impairments. Our findings emphasize the need to apply activity-centered design principles to generative AI assistants, ensuring they better align with user behaviors and address specific accessibility needs. This approach can enable the assistants to provide more intuitive, inclusive, and effective experiences, while also contributing to the broader goal of enhancing accessibility in software development.", "page": 1, "bbox": []}, "seg_5": {"summary": "Insufficient content for summary.", "text": "ACM Reference Format:", "page": 1, "bbox": []}, "seg_6": {"summary": "Summary: This research paper, authored by Flores-Saviaga, Hanrahan, Imteyaz, Clarke, and Savage, investigates the impact of generative AI coding assistants on developers with visual impairments.  Published in March 2025, the 25-page study is accessible via the provided DOI link.", "text": "Claudia Flores-Saviaga, Benjamin V. Hanrahan, Kashif Imteyaz, Steven Clarke, and Saiph Savage. 2025. The Impact of Generative AI Coding Assistants on Developers Who Are Visually Impaired. 1, 1 (March 2025), 25 pages. https://doi.org/10.1145/nnnnnnn.nnnnnnn", "page": 1, "bbox": []}, "seg_7": {"summary": "Summary: This text segment lists the authors of a publication, along with their affiliations at Northeastern University and Microsoft, and their respective email addresses.  It provides contact information for each author.", "text": "Authors\u2019 addresses: Claudia Flores-Saviaga, floressaviaga.c@northeastern.edu, Northeastern University, USA; Benjamin V. Hanrahan, benhanrahan@ microsoft.com, Microsoft, USA; Kashif Imteyaz, imteyaz.k@northeastern.edu, Northeastern University, USA; Steven Clarke, stevencl@microsoft.com, Microsoft, United Kingdom; Saiph Savage, s.savage@northeastern.edu, Northeastern University, USA.", "page": 1, "bbox": []}, "seg_8": {"summary": "Summary: This text segment is a copyright notice from the Association for Computing Machinery (ACM) regarding permitted uses of their work.  It grants free permission for personal and classroom use, provided it is not for profit and includes proper citation.  Any other use, such as commercial redistribution or republication, requires explicit permission and potentially a fee, obtainable from ACM.", "text": "Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. \u00a9 2025 Association for Computing Machinery.", "page": 1, "bbox": []}, "seg_9": {"summary": "Summary: A manuscript has been submitted to ACM.", "text": "Manuscript submitted to ACM", "page": 1, "bbox": []}, "seg_10": {"summary": "Insufficient content for summary.", "text": "Manuscript submitted to ACM", "page": 1, "bbox": []}, "seg_13": {"summary": "Summary: Insufficient content for summary.", "text": "Flores-Saviaga, et al.", "page": 2, "bbox": []}, "seg_14": {"summary": "Insufficient content for summary.", "text": "1 INTRODUCTION", "page": 2, "bbox": []}, "seg_15": {"summary": "Generative AI is transforming software development through coding assistants like GitHub Copilot, which offer functionalities such as auto-completion and code generation.  This technological shift raises an important question regarding the impact of these AI tools on developers with visual impairments. The text segment highlights the need to understand how this emerging technology affects accessibility and inclusivity in coding.", "text": "The integration of generative artificial intelligence (AI) into software development is fundamentally transforming coding practices [ 55 ]. AI coding assistants, such as GitHub Copilot [ 34 ], provide functionalities like auto-completion, code generation, and test generation [ 76 ], which have the potential to revolutionize how developers work [ 73 ]. Amidst this surge of new capabilities driven by AI, an important question emerges: How do these generative AI coding assistants impact developers with visual impairments?", "page": 2, "bbox": []}, "seg_16": {"summary": "AI's integration into coding offers opportunities to improve accessibility for developers with visual impairments by automating tasks and providing intelligent support.  However, if AI coding assistants are not designed with accessibility in mind, they risk creating new obstacles, especially for screen reader users.  Therefore, careful consideration of accessibility is crucial in the development of AI-powered coding tools.", "text": "The convergence of AI and accessibility in coding presents both tremendous opportunities and intricate challenges [ 55 , 67 ]. On one hand, AI has the potential to make coding more accessible for developers with visual impairments by reducing manual coding tasks and providing intelligent assistance [ 89 ]. On the other hand, if these AI coding assistants are not designed with accessibility in mind, they may inadvertently create new barriers or worsen existing ones [ 67 , 103 ]. This risk is especially high if the AI coding assistants depend heavily on visual cues or employ interaction methods incompatible with screen readers [ 61 , 86 , 109 ].", "page": 2, "bbox": []}, "seg_17": {"summary": "The accessibility challenges in AI assistants mirror those in web accessibility, particularly for visually impaired users, due to dynamic content and complex interactions.  Traditional accessibility guidelines may not fully address these issues in AI coding assistants, where AI-generated suggestions and interfaces can create new hurdles for visually impaired developers.  Further research is needed to understand and address these difficulties to make AI coding assistants truly accessible and user-friendly for all developers.", "text": "In this context, it is important to understand that the relationship between accessibility and usability in AI assistants mirrors longstanding challenges in web accessibility [ 38 , 51 ], particularly for visually impaired users [ 14 , 43 ]. Similar to rich internet applications [ 9 , 72 ], AI assistants often introduce dynamic content and complex interactions that traditional accessibility approaches may not fully address [ 39 , 47 ]. For instance, Petrie and Kheir [ 74 ] found that existing accessibility guidelines fail to capture many of the usability problems encountered by visually impaired users when interacting with dynamic content. This gap could be especially exacerbated in AI coding assistants [ 2 , 65 , 71 ], where AI-generated suggestions, real-time code generation, and sophisticated user interfaces can present new hurdles [ 39 , 41 ]. Just as screen readers struggle with dynamic web content, AJAX updates, and automatic refreshes [ 20 ], developers who are visually impaired may experience similar difficulties when interacting with rapidly changing AI-generated code suggestions and interface elements [ 54 ]. Consequently, simply following basic accessibility rules might not be enough to make AI coding assistants truly easy to use. We might need to rethink how to make these assistants more accessible for everyone. The challenge is that we do not fully understand the difficulties and benefits that visually impaired developers experience when using AI coding assistants. Closing this knowledge gap is important\u2014not just for accessibility, but also for making AI-assisted coding tools more user-friendly and effective for all developers, including those with different levels of vision.", "page": 2, "bbox": []}, "seg_18": {"summary": "Summary: This study investigates the unique challenges and opportunities that AI-assisted coding tools present for developers with visual impairments.  The research is driven by a question focused on understanding these challenges and opportunities.", "text": "Our study addresses this research gap by investigating what unique challenges and opportunities AI-assisted coding tools present for developers with visual impairments. Our research is driven by the following research question:", "page": 2, "bbox": []}, "seg_19": {"summary": "Summary: This research question explores the challenges that AI coding tools present to visually impaired developers.  It also investigates the potential of these tools to create new opportunities and improve the work of developers with visual impairments.", "text": "\u2022 RQ1: What challenges do AI-assisted coding tools pose for developers who are visually impaired, and what opportunities do they offer to empower and enhance their work?", "page": 2, "bbox": []}, "seg_20": {"summary": "This study uses the Activity Theory framework to investigate how visually impaired developers interact with the AI coding assistant GitHub Copilot. Researchers observed ten developers with varying experience levels as they completed a coding task using Copilot and conducted interviews afterwards. The study aimed to identify both the challenges and opportunities these developers encountered when using the AI assistant.", "text": "To study this question, we use the Activity Theory framework [ 44 ], which helps analyze how tools influence human activity and identifies contradictions that occur when a tool\u2019s design does not fit well with users\u2019 workflows and needs [ 12 ]. We applied this framework to examine a qualitative study we conducted with 10 visually impaired developers of varying experience levels. These developers used an AI coding assistant, GitHub Copilot, to complete a coding task. During the study, we observed their real-time interactions with the AI assistant, noting both challenges and opportunities. After the task, we conducted interviews to gain deeper insights into their experiences and the difficulties they faced while using the AI coding assistant.", "page": 2, "bbox": []}, "seg_21": {"summary": "Summary: This study reveals that AI coding assistants have a dual impact, enhancing coding efficiency while simultaneously posing new accessibility challenges.  Based on these findings, the authors propose a roadmap for developing the next generation of accessible AI tools. This research contributes to the understanding of the complex relationship between AI in coding and accessibility.", "text": "Our findings reveal a complex landscape where AI coding assistants can both improve coding efficiency and introduce new accessibility challenges. Based on our findings, we outline a roadmap for the next generation of accessible AI Manuscript submitted to ACM", "page": 2, "bbox": []}, "seg_23": {"summary": "Summary: This text segment will explore how generative AI coding assistants affect developers who are visually impaired. It will likely examine the specific ways these tools impact their coding experience.", "text": "The Impact of Generative AI Coding Assistants on Developers Who Are Visually Impaired", "page": 3, "bbox": []}, "seg_24": {"summary": "Summary: This text segment discusses research focused on the experiences of visually impaired developers using AI coding assistants. The goal of this research is to derive key design insights that can improve accessibility in AI-driven software development. Ultimately, these insights are intended to reshape how accessibility is approached in the development of AI-driven software.", "text": "coding assistants. By analyzing the experiences of visually impaired developers using AI-assisted coding tools, we derive key design insights that can reshape how accessibility is approached in AI-driven software development.", "page": 3, "bbox": []}, "seg_25": {"summary": "Insufficient content for summary.", "text": "The contributions of this paper are twofold:", "page": 3, "bbox": []}, "seg_26": {"summary": "Summary: This research offers a thorough examination of the accessibility of AI coding assistants, specifically looking at the challenges and advantages for developers who are visually impaired. The study is based on practical experiences and perspectives from visually impaired developers themselves.", "text": "\u2022 We conduct a comprehensive analysis of the accessibility challenges and benefits of AI coding assistants, using real-world insights from developers who are visually impaired.", "page": 3, "bbox": []}, "seg_27": {"summary": "Summary: This segment introduces design recommendations aimed at improving the accessibility and inclusivity of AI coding assistants.  The recommendations are specifically targeted towards developers with visual impairments.", "text": "\u2022 We propose a set of design recommendations to make AI coding assistants more accessible and inclusive for developers with visual impairments.", "page": 3, "bbox": []}, "seg_28": {"summary": "Insufficient content for summary.", "text": "2 RELATED WORK", "page": 3, "bbox": []}, "seg_29": {"summary": "Insufficient content for summary.", "text": "2.1 Accessibility and Tools for Developers who are Visually Impaired", "page": 3, "bbox": []}, "seg_30": {"summary": "Studies have consistently shown that visually impaired developers face significant challenges in coding. These challenges span multiple areas, including code navigation, comprehension, editing, debugging, and skimming, as identified by Mountapmbeme et al. Further research by Albusays and Ludi highlights ongoing difficulties in code navigation, diagrams, debugging, and UI layouts, leading to a preference for text editors over IDEs due to accessibility concerns.", "text": "Accessibility in general has been a subject of ongoing research [ 17 , 35 , 36 , 85 ]. Several studies have shed light on the significant challenges developers who are visually impaired face with coding and the techniques these programmers employ to overcome these challenges. Mountapmbeme et al. [ 63 ] categorized these challenges into five main areas: code navigation, code comprehension, code editing, code debugging, and code skimming. Albusays and Ludi [ 5 ] found persistent challenges in code navigation, accessing diagrams, debugging, and UI layout. Their study highlighted a strong preference for text editors over IDEs due to accessibility issues, reduced complexity, and better compatibility with assistive technologies.", "page": 3, "bbox": []}, "seg_31": {"summary": "Visually impaired developers often favor text editors over IDEs due to accessibility limitations, leading to unique coding practices.  Challenges include navigating code structure and debugging with visually oriented tools. To mitigate these issues, researchers have developed tools like StructJumper for code navigation and audio-based debuggers like Wicked Audio Debugger and CodeTalk, as well as collaborative tools like CodeWalk and Grid-Coding to improve coding environment accessibility.", "text": "Further studies by Mealin and Murphy-Hill [ 59 ] and Baker et al. [ 11 ] explored specific tools and techniques that developers who are visually impaired use. Mealin and Murphy-Hill found that many developers who are visually impaired rely on text editors rather than IDEs due to accessibility issues employing unique practices like \u201cout-of-context editing,\u201d where blocks of code are copied, edited separately, and pasted back. This preference for text editors has been corroborated by other researchers [ 6 , 63 ], who attribute it to specific challenges such as navigating line-by-line, understanding indentation, and managing nested code structures [ 56 , 99 ]. To address this issue, Baker et al. [ 11 ] created StructJumper, a plugin that generates a hierarchical tree structure of code for easier navigation. Debugging, presents another significant challenge for developers who are visually impaired, largely due to the reliance on visual interfaces in debugging tools, which screen readers struggle to interpret effectively [ 5 , 78 ]. These challenges have led the development of tools like Wicked Audio Debugger (WAD) [ 94 ] , a tool that provides audio descriptions of programs during execution; CodeTalk [ 78 ], a Visual Studio plugin that introduces \u201cTalkPoints\u201d for audio-based debugging; and CodeWalk, a tool by Potluri et al. [ 77 ], which facilitates accessible, remote, synchronous code review and refactoring activities by tethering collaborators\u2019 cursors with the host of a Live Share session. Additionally, Haque et al. [ 27 ] introduced Grid-Coding, a paradigm designed to improve the accessibility of coding environments by representing code in a structured 2D grid, allowing developers who are visually impaired to navigate and edit code more effectively.", "page": 3, "bbox": []}, "seg_32": {"summary": "Summary: Conversational interfaces, especially speech-based ones, show promise in improving comprehension and navigation. Studies have explored their effectiveness in reducing cognitive load through voice commands and their application in development environments using audio cues for tasks like debugging and file navigation.", "text": "Conversational interfaces have also shown promise [ 15 ], Ludi et al. [ 57 ], found that speech-based cues generally provided the best performance for comprehension and navigation tasks. Phutane et al. [ 75 ] explored the use of voice commands to reduce cognitive load. Meanwhile, Stefik et al. [ 95 ] created Sodbeans, an IDE that relies on audio cues for debugging, while Smith et al. [ 90 ] developed a tool to allow developers to navigate the tree structure of files in Eclipse.", "page": 3, "bbox": []}, "seg_33": {"summary": "Summary: Existing research on accessibility for visually impaired developers may not fully address the new challenges and opportunities presented by generative AI coding tools like GitHub Copilot.  The impact of these tools on accessible programming remains largely unexamined as most current studies predate their emergence.", "text": "While previous research has significantly advanced accessibility for developers who are visually impaired, these findings may not fully apply to the new landscape shaped by generative AI-assisted coding tools such as GitHub Copilot. The introduction of these tools brings new challenges and opportunities in accessible programming, an area that remains largely unexamined. The majority of current studies were conducted before the emergence of generative", "page": 3, "bbox": []}, "seg_34": {"summary": "Summary: A manuscript has been submitted to the ACM, likely for review and potential publication.", "text": "Manuscript submitted to ACM", "page": 3, "bbox": []}, "seg_36": {"summary": "Insufficient content for summary.", "text": "Flores-Saviaga, et al.", "page": 4, "bbox": []}, "seg_37": {"summary": "Summary:  A significant knowledge gap exists concerning the effects of AI coding tools on developers with visual impairments.  This lack of understanding hinders our ability to assess the impact and possibilities of these tools for visually impaired programmers.", "text": "AI in coding environments, resulting in a critical knowledge gap regarding the impact and potential of these advanced tools for developers who are visually impaired.", "page": 4, "bbox": []}, "seg_38": {"summary": "Insufficient content for summary.", "text": "2.2 AI-assisted Coding Environments", "page": 4, "bbox": []}, "seg_39": {"summary": "AI-assisted coding tools like GitHub Copilot are shown to increase developer productivity and speed up programming tasks. However, studies also reveal challenges, as developers can struggle with understanding, editing, and debugging AI-generated code, impacting task effectiveness.  The tool's utility is also dependent on the developer's expertise level, as less experienced developers may find it harder to assess AI suggestions.", "text": "The integration of AI into software development tools has significantly impacted coding practices, with AI-assisted coding assistants like GitHub Copilot showing promise in improving developer productivity. Ziegler et al. [ 108 ] found that Copilot increases users\u2019 feelings of productivity, with almost a third of its proposed code completions being accepted. In a controlled experiment, Peng et al.[ 73 ] demonstrated that software developers using Github Copilot were able to complete programming tasks significantly faster than those without such assistance. However, Vaithilingam et al. [ 100 ] noted that while most participants preferred using Copilot in daily programming tasks, they often faced difficulties in understanding, editing, and debugging code snippets generated by Copilot, which significantly hindered their task-solving effectiveness. This was confirmed by Dakhel et al [ 26 ], who noted that the effectiveness of tools like Github Copilot depends on the developer\u2019s level of expertise, as less experienced developers often lack the necessary skills to effectively evaluate AI-generated code suggestions.", "page": 4, "bbox": []}, "seg_40": {"summary": "Summary: According to a survey by Liang et al., developers primarily use AI programming assistants to reduce keystrokes, speed up task completion, and aid in syntax recall. The survey also indicated that developers are utilizing these tools for a significant portion of their coding, with a median of 30.5% of code being generated with AI assistance.", "text": "A recent survey of developers by Liang et al. [ 55 ] revealed that the primary motivations for using AI programming assistants include reducing keystrokes, finishing programming tasks quickly, and recalling syntax. Developers reported that a median of 30.5% of their code was written with help from tools like Copilot.", "page": 4, "bbox": []}, "seg_41": {"summary": "Studies have explored how developers interact with AI coding assistants, identifying modes like \"acceleration\" and \"exploration\" and comparing human-AI to human-human pair programming.  These studies reveal insights into collaboration dynamics, but a key gap remains in understanding the impact of AI coding assistants on developers with accessibility needs. Further research is needed to address this underrepresented perspective.", "text": "Studies like those by Barke et al.[ 66 ] and Wu et al. [ 58 ] provide insight into the varying modes of interaction with AI coding assistants. Barke et al. [ 66 ] identified \u201cacceleration mode\u201d and \u201cexploration mode\u201d as two broad categories of Copilot use, while Wu et al. [ 58 ] compared human-human pair programming with human-AI pair programming, highlighting differences in collaboration dynamics. However, there is still a significant gap in understanding how these AI tools impact developers with accessibility needs.", "page": 4, "bbox": []}, "seg_42": {"summary": "Insufficient content for summary.", "text": "2.3 Activity Theory", "page": 4, "bbox": []}, "seg_43": {"summary": "A visually impaired software developer uses Github Copilot as a tool to assist with coding tasks. This highlights the use of the tool by a specific user group for a particular purpose.", "text": "Tool ( Github Copilot ) Subject (Software developer who is visually impaired) Object ( Coding task )", "page": 4, "bbox": []}, "seg_44": {"summary": "Summary: Fig. 2 illustrates the relationship between visually impaired software developers (subject), coding tasks (object), and GitHub Copilot (mediating tool). This relationship is presented within the Activity Theory framework.", "text": "Fig. 2. Diagram illustrating the relationship between software developers who are visually impaired (subject), coding tasks (object), and GitHub Copilot (mediating tool) within the Activity Theory framework.", "page": 4, "bbox": []}, "seg_45": {"summary": "Summary: Activity Theory is a conceptual framework used to guide research and problem-solving.  It centers on the concept of \"activity,\" defined as goal-directed actions mediated by artifacts to achieve specific objectives. These actions are carried out through routinized operations.", "text": "Activity Theory is a type of \u201cconceptual frame- work\u201d [ 80 , 82 , 88 , 91 ]. A conceptual framework is an analytical tool or structure used to organize and guide research, projects, or problem-solving efforts [ 40 , 60 ]. The foundational concept of Activity The- ory is the \u201cactivity\u201d, a series of goal directed actions [ 53 ] that aim to achieve specific objectives [ 52 ]. These actions are mediated by artifacts, the instru- ments through which individuals interact with their objectives. Actions themselves are performed via routinized operations, in which individuals are not conscious of or focused on these operations. This process is illustrated in Figure 2 . For example, devel- opers who are visually impaired (the subjects) may have specific goals (objects) related to completing", "page": 4, "bbox": []}, "seg_46": {"summary": "Summary: In the context of programming tasks, an AI programming tool is defined as a mediating artifact, essentially functioning as a tool itself.", "text": "programming tasks. In this context, an AI programming tool acts as the mediating artifact (tool). Manuscript submitted to ACM", "page": 4, "bbox": []}, "seg_48": {"summary": "Insufficient content for summary.", "text": "The Impact of Generative AI Coding Assistants on Developers Who Are Visually Impaired", "page": 5, "bbox": []}, "seg_49": {"summary": "Summary: B\u00f8dker introduced Activity Theory as a foundational framework for HCI, emphasizing the dynamic interplay between users, their goals, and the tools they use, advocating for tool evolution to meet user needs.  Within this theory, contradictions between users, goals, and tools are seen as drivers of change, while misalignments are identified as localized usability issues that may not require systemic changes. Activity Theory, therefore, guides the design of adaptable interactive systems by addressing these tensions and mismatches.", "text": "B\u00f8dker proposed Activity Theory as a foundational framework for HCI [ 18 ], emphasizing its potential to guide the design of interactive systems by focusing on the dynamic interplay between users, their goals, and the tools users employ (interactive systems) [ 19 ]. B\u00f8dker emphasized that tools should evolve over time to meet users\u2019 needs and adapt to the activities they mediate[ 18 ], highlighting the importance of designing systems that adjust to changing workflows and contexts to remain effective[ 19 ]. Within B\u00f8dker\u2019s definition of Activity Theory for HCI [ 18 ], contradictions are discrepancies or tensions that arise between the tools, the goals, and the users, that must be addressed [ 28 ]. These contradictions are not obstacles but drivers of change, pointing out areas where tools or processes need to evolve to better meet user needs [ 29 ]. Within this space, Activity Theory also introduces the concept of misalignments , which are localized issues or practical mismatches. Unlike contradictions , misalignments hinder usability and effectiveness for end-users but may not necessitate systemic changes.", "page": 5, "bbox": []}, "seg_50": {"summary": "This paper uses Activity Theory to investigate the design of AI-assisted coding tools for visually impaired developers.  Activity Theory is presented as a suitable framework due to its established history in studying technologies designed for diverse groups, including individuals with disabilities. Prior research has successfully applied Activity Theory to analyze various technologies for people with disabilities, such as tactile devices and audio-haptic tools.", "text": "In this paper, we use Activity Theory as a framework to examine the design of AI-assisted coding tools for developers who are visually impaired. We chose this approach because Activity Theory has been widely used for decades to study tools and technologies designed for diverse groups, including individuals with disabilities [ 12 , 18 , 28 , 44 , 45 , 81 , 97 ]. For example, Baldwin et al. [ 12 ] applied Activity Theory to investigate the design of tactile devices and enhanced auditory tools, examining whether these technologies align with the unique workflows of users who have no or low-vision. Similarly, Szymczak [ 97 ] applied Activity Theory to analyze how audio-haptic technologies mediated interactions and supported the goals of individuals who are visually impaired, focusing on how these technologies could assist users in interacting with 2D representations, such as maps and drawings. Tlili et al. [ 98 ], also applied Activity Theory to review the use of game-based learning for learners with disabilities and identify inconsistencies in stakeholder involvement, variability in the use of educational technology, and difficulties in standardizing performance measures. Robins [ 81 ] applied Activity Theory to analyze and design accessibility in video games, focusing on the interaction between visually impaired players, game goals, and mediating tools like audio-haptic technologies and game mechanics.", "page": 5, "bbox": []}, "seg_51": {"summary": "Summary: The table presents data for ten male participants with either low vision or no vision who participated in a study.  These participants possess diverse coding experience and have utilized various AI coding tools such as GitHub Copilot and ChatGPT.  Python and C# were the preferred programming languages for the study task, which was successfully completed by all participants.", "text": "P# Gender Age Exp.(yrs) Vision Status AI-Coding Tool Experience Coding Proficiency Pref. Lang. For Study Task Completed P1 Male 32 8 No vision GitHub Copilot C#, JavaScript, Python, Ruby Python Yes P2 Male 34 12 Low vision GitHub Copilot PHP, C#, JavaScript C# Yes P3 Male 38 9 Low vision CodeWhisperer, Codellama, ChatGPT C++, Python Python Yes P4 Male 43 22 Low vision ChatGPT JavaScript, TypeScript, C# C# Yes P5 Male 26 6 No vision GitHub Copilot, ChatGPT Python Python Yes P6 Male 36 17 Low vision GitHub Copilot PHP, Ruby, Swift, Go, Python, JavaScript, Kotlin Python Yes P7 Male 58 23 No vision GitHub Copilot Python, SQL, PowerShell Python Yes P8 Male 54 32 No vision ChatGPT C, R, Ruby, TypeScript, Swift, Python, Kotlin Python Yes P9 Male 42 4 No vision ChatGPT JavaScript, PHP, Python, HTML, CSS Python Yes P10 Male 24 2 No vision Claude, ChatGPT, Gemini C#, HTML, PHP C# Yes", "page": 5, "bbox": []}, "seg_52": {"summary": "Insufficient content for summary.", "text": "Table 1. Participant Demographics, Vision Status, Experience with AI Coding Assistants, and Programming Background.", "page": 5, "bbox": []}, "seg_53": {"summary": "This paper utilizes Activity Theory to study the impact of AI-assisted coding tools, specifically GitHub Copilot, on visually impaired developers.  The analysis investigates how these tools mediate developer tasks and identifies both systemic contradictions and usability misalignments.  Ultimately, the research aims to provide design recommendations to enhance AI coding tools to better meet the needs of developers with visual impairments.", "text": "Building on this foundation, our paper applies Activity Theory to examine how AI-assisted coding tools, particularly GitHub Copilot, mediate and influence the tasks of developers who are visually impaired. Activity Theory provides a particularly useful analysis framework since the introduction of AI coding assistants may operationalize some actions that have not yet become routine for developers. Additionally, we use Activity Theory to guide design recommendations aimed at improving these tools for this population. To achieve this, we analyze both contradictions \u2014systemic tensions within the activity system\u2014and misalignments \u2014localized issues that disrupt usability. By addressing these challenges, we ensure AI tools meet developers\u2019 needs.", "page": 5, "bbox": []}, "seg_54": {"summary": "Summary: Manuscript submission to ACM has occurred.", "text": "Manuscript submitted to ACM", "page": 5, "bbox": []}, "seg_56": {"summary": "Summary: Insufficient content for summary.", "text": "Flores-Saviaga, et al.", "page": 6, "bbox": []}, "seg_57": {"summary": "Summary: This text segment lists various chat functionalities.  It includes features such as inline chat and ghost text suggestions, as well as different types of chat window implementations, specifically floating and embedded panes.", "text": "a.Inline chat b. Ghost text suggestions c. Chat Window (floating element) d. Chat window (embedded pane)", "page": 6, "bbox": []}, "seg_58": {"summary": "Summary: GitHub Copilot offers multiple interaction interfaces to assist users, including an inline chat for quick commands, dynamic ghost text suggestions as users type, a floating chat window for temporary interactions, and an embedded pane chat for more extensive and ongoing conversations. These interfaces cater to different user needs and interaction styles.", "text": "Fig. 3. GitHub Copilot interaction interfaces. (a) Inline chat window for quick command input and AI engagement. (b) Ghost text suggestions dynamically generated as the user types. (c) Floating chat window for temporary interactions, ideal for quick-access queries. (d) Embedded pane chat window for ongoing, more extensive conversations with AI, allowing for sustained reference and deeper coding assistance.", "page": 6, "bbox": []}, "seg_59": {"summary": "Insufficient content for summary.", "text": "2.4 Copilot", "page": 6, "bbox": []}, "seg_60": {"summary": "Summary: GitHub Copilot's interface includes an inline chat feature, enabling developers to interact with the AI coding assistant directly within the code editor. This method allows for seamless and quick communication without interrupting the coding process.", "text": "The GitHub Copilot interface provides multiple ways for developers to interact with its AI-driven coding assistant. One primary method is through its inline chat (Fig. 3 a), where users can type commands or questions directly within the code editor. This allows for seamless, quick interactions without disrupting the coding workflow.", "page": 6, "bbox": []}, "seg_61": {"summary": "Developers can interact with Copilot through a chat window that can be either a floating element or an embedded pane within the interface.  Floating windows are suitable for quick queries, while embedded panes are better for extended interactions and referencing past exchanges. This provides developers with flexible interaction styles to suit their workflow.", "text": "Additionally, developers can engage with Copilot using the chat window , which can appear either as a floating element (Fig. 3 c) or as an embedded pane within the interface (Fig. 3 d). An embedded pane refers to a UI component that is fixed within the main window, allowing for continuous visibility and interaction without obstructing other elements on the screen. The floating element is useful for quick, temporary queries, while the embedded pane is better suited for extended interactions where users may need to frequently reference past exchanges. This flexibility enables developers to choose an interaction style that best fits their workflow and preferences.", "page": 6, "bbox": []}, "seg_62": {"summary": "Insufficient content for summary.", "text": "Manuscript submitted to ACM", "page": 6, "bbox": []}, "seg_64": {"summary": "This text segment discusses the effects of generative AI coding assistants on developers who are visually impaired.  It likely explores how these tools impact their coding experience, accessibility, and productivity.  The content will likely delve into both the benefits and challenges presented by AI assistance for this specific group of developers.", "text": "The Impact of Generative AI Coding Assistants on Developers Who Are Visually Impaired", "page": 7, "bbox": []}, "seg_65": {"summary": "Summary: Copilot offers ghost text suggestions, providing real-time, semi-transparent code completions as developers type, which can be accepted, modified, or ignored.  Additionally, developers can request code completions by writing natural language comments describing the desired functionality, which Copilot then translates into code snippets. These features aim to enhance developer efficiency.", "text": "Another key interaction method is through ghost text suggestions (Fig. 3 b). As the developer types, Copilot continuously analyzes the context and generates relevant code suggestions in real-time. These suggestions appear as semi-transparent text within the editor, allowing developers to seamlessly integrate them into their code. Developers can choose to accept, modify, or ignore these suggestions based on their needs. Beyond real-time suggestions, developers can also request code completions by writing natural language comments that describe the desired functionality. Copilot then processes these descriptions and generates corresponding code snippets, helping developers implement features more efficiently.", "page": 7, "bbox": []}, "seg_66": {"summary": "Summary: GitHub Copilot is a Visual Studio Code extension, not a standalone editor, and its chat windows are features of the extension itself, not default VS Code functionality.  These chat interfaces enable users to engage with AI-generated coding suggestions directly within their VS Code environment.", "text": "It is important to note that GitHub Copilot is not a standalone code editor but an extension designed to work within Visual Studio Code. The chat windows, including both the floating and embedded pane versions, are features introduced by the GitHub Copilot extension and are not part of Visual Studio Code by default. These chat interfaces allow users to interact directly with AI-generated coding suggestions within their coding environment.", "page": 7, "bbox": []}, "seg_67": {"summary": "Researchers selected GitHub Copilot as the primary AI coding assistant for their study due to its widespread use at the time of research.  Visual Studio Code was chosen as the development environment because of its popularity, accessibility, and seamless integration with GitHub Copilot. This setup allowed the researchers to investigate the influence of these tools on the coding experience of developers who are visually impaired.", "text": "GitHub Copilot was selected as the primary AI coding assistant for this study because, at the time of research, it was the most widely used tool of its kind [ 33 , 92 ]. We chose Visual Studio Code as the development environment due to its popularity and accessibility, as well as its seamless integration with GitHub Copilot [ 93 , 101 ]. This setup enabled us to explore how these tools influence the coding experience of developers who are visually impaired.", "page": 7, "bbox": []}, "seg_68": {"summary": "Insufficient content for summary.", "text": "2.5 Research Gap", "page": 7, "bbox": []}, "seg_69": {"summary": "Summary:  While accessibility has improved for visually impaired developers using traditional coding tools, AI coding assistants like GitHub Copilot present new, under-researched challenges.  Existing research mainly focuses on traditional tools, neglecting the unique complexities of AI-assisted coding, highlighting the need to examine and ensure these new AI tools are inclusive.", "text": "Despite progress in accessibility for developers who are visually impaired [ 13 , 23 , 65 ], generative AI coding assistants like GitHub Copilot introduce new challenges and opportunities that remain under-explored. Most existing research focuses on traditional coding tools [ 1 , 49 ], overlooking complexities unique to AI-assisted coding. Our study examines these accessibility issues to ensure AI assistants like GitHub Copilot are inclusive and support equal access for visually impaired developers.", "page": 7, "bbox": []}, "seg_71": {"summary": "Researchers conducted a study to understand the experiences and challenges faced by visually impaired developers when using GitHub Copilot. Utilizing Activity Theory, the study analyzed the interaction between these developers and the AI tool in coding tasks. The findings revealed design limitations of Copilot in meeting the specific needs of visually impaired developers, alongside the identification of potential opportunities.", "text": "To study the relationship between AI coding assistants and accessibility, we conducted a study with developers who are visually impaired. Our goal was to understand their experiences, challenges, and strategies when using an AI coding assistant, specifically GitHub Copilot. Using Activity Theory as our framework, we analyzed how Copilot (tool) mediates the interaction between visually impaired developers (participants) and their coding tasks (object). Our analysis highlights the contradictions and misalignments that occur when Copilot\u2019s design falls short of meeting the unique needs of developers who are visually impaired, while also uncovering new opportunities that emerge in this environment.", "page": 7, "bbox": []}, "seg_72": {"summary": "Insufficient content for summary.", "text": "3.1 Participant Recruitment", "page": 7, "bbox": []}, "seg_73": {"summary": "Summary: This study recruited ten visually impaired male software developers with varying levels of vision and professional experience (2-32 years) to participate in research.  Participants were sourced through specialized networks and had some familiarity with AI coding assistants. The study acknowledges the limited recruitment pool but justifies the sample size by referencing similar HCI studies on underrepresented groups.", "text": "We recruited 10 software developers who were visually impaired, including 4 with low vision and 6 with no vision, with experience ranging from 2 to 32 years in the field (see Table 1 ). Participants were sourced through professional networks, accessibility-focused online forums, and organizations supporting professionals in tech with visual impairments. To participate, developers needed some familiarity with AI coding assistants, though extensive experience with Copilot was not required. All participants identified as male. Given the specialized nature of developers who are visually impaired, our recruitment pool was naturally limited. However, our sample size aligns with prior HCI studies on underrepresented populations [ 25 , 30 , 69 , 79 , 83 ]. Despite these constraints, our study provides valuable insights into the accessibility", "page": 7, "bbox": []}, "seg_74": {"summary": "Insufficient content for summary.", "text": "Manuscript submitted to ACM", "page": 7, "bbox": []}, "seg_76": {"summary": "Summary: Insufficient content for summary.", "text": "Flores-Saviaga, et al.", "page": 8, "bbox": []}, "seg_77": {"summary": "Summary: This text segment refers to an underrepresented group and mentions challenges and opportunities they face.  Participants from this group received $50 USD as compensation for their time, suggesting involvement in a study or event.", "text": "challenges and opportunities for this underrepresented group. Each participant received $50 USD (or its equivalent in local currency) as compensation for their time.", "page": 8, "bbox": []}, "seg_78": {"summary": "Insufficient content for summary.", "text": "3.2 Study setup", "page": 8, "bbox": []}, "seg_79": {"summary": "Summary: This study was conducted remotely, allowing participants to utilize their preferred accessible setups.  Each session was approximately 90 minutes long and followed four sequential phases.", "text": "We conducted our study remotely, ensuring that participants could use their preferred accessible setup. Each session lasted approximately 90 minutes and followed four sequential phases:", "page": 8, "bbox": []}, "seg_80": {"summary": "Summary: This section of the study focuses on participant backgrounds and their experience with AI coding assistants.  Researchers collected information on participants' professional and technical backgrounds and their prior use of tools like GitHub Copilot.", "text": "(1) Participant Background and Copilot Experience: We asked participants to describe their professional and technical backgrounds and share their prior experience with AI coding assistants like GitHub Copilot.", "page": 8, "bbox": []}, "seg_81": {"summary": "Summary: Participants attended a training session to learn about GitHub Copilot and its features. The session also detailed how Copilot works with accessible development environments and assistive technologies that participants were already familiar with. This training was designed to prepare participants to effectively use Copilot for upcoming coding tasks.", "text": "(2) Training Session: We provided participants with a training session that introduced GitHub Copilot and its key features. The session also covered how Copilot integrates with accessible development environments and assistive technologies participants were already using. This ensured that all participants had a solid understanding of how to interact with Copilot before starting the coding tasks.", "page": 8, "bbox": []}, "seg_82": {"summary": "Participants in the study engaged in practical coding and debugging exercises.  These tasks were performed using GitHub Copilot within the Visual Studio Code environment. This hands-on component aimed to assess participant interaction with the tool in realistic software development scenarios.", "text": "(3) Hands-on Coding and Debugging Tasks: We instructed participants to complete a coding task followed by a debugging task using GitHub Copilot in Visual Studio Code.", "page": 8, "bbox": []}, "seg_83": {"summary": "Summary: Participants were tasked with writing a program to calculate the days until a user's next birthday, requiring specific date input formats and class implementation with unit tests.  They were instructed to use the \"think-aloud\" protocol and utilize Copilot while completing the programming task. This programming assignment was designed following prior research methods.", "text": "\u2022 Programming Task: Following prior work [ 46 ], we asked participants to write a program that calculates the number of days until the user\u2019s next birthday. The program required a birthday string input in either DDMMYY or DDMMYYYY format and a class implementation to handle date calculations. We also asked participants to write unit tests for their class. Throughout the task, we encouraged them to use the \"think-aloud\" protocol, verbalizing their thought process while interacting with Copilot.", "page": 8, "bbox": []}, "seg_84": {"summary": "Insufficient content for summary.", "text": "We selected this task because:", "page": 8, "bbox": []}, "seg_85": {"summary": "Summary: This tool integrates familiar programming concepts like string manipulation, date calculations, and object-oriented principles.  These features ensure relevance and applicability to participants' standard coding practices.", "text": "\u2013 It incorporates common programming concepts such as string manipulation, date calculations, and object- oriented principles, making it relevant to participants\u2019 typical coding workflows.", "page": 8, "bbox": []}, "seg_86": {"summary": "Summary: The subject matter does not necessitate specific programming framework expertise. This simplifies the process of recruiting participants.", "text": "\u2013 It does not require specialized knowledge of specific programming frameworks, simplifying participant recruitment.", "page": 8, "bbox": []}, "seg_87": {"summary": "Participants participated in a debugging task where they had to find and correct errors in code produced by Copilot.  This session involved them discussing the debugging process as they worked to fix the code.", "text": "\u2022 Debugging Task: We then asked participants to engage in a debugging session, where they identified and fixed errors in the code generated by Copilot. During this session, we prompted them to discuss:", "page": 8, "bbox": []}, "seg_88": {"summary": "Summary: Insufficient content for summary.", "text": "\u2013 Their usual approach to evaluating code accuracy.", "page": 8, "bbox": []}, "seg_89": {"summary": "Insufficient content for summary.", "text": "\u2013 The methods they used to handle encountered issues.", "page": 8, "bbox": []}, "seg_90": {"summary": "Insufficient content for summary.", "text": "\u2013 Whether Copilot simplified or complicated their debugging process.", "page": 8, "bbox": []}, "seg_91": {"summary": "Summary: Following the programming tasks, semi-structured interviews were conducted where participants detailed their code organization, adjustments made due to Copilot, and challenges encountered.  Participants also reflected on Copilot's impact on task complexity, highlighting instances of its helpfulness or difficulty.  Further details about the interview questions can be found in the Appendix.", "text": "(4) Post-Interview: After completing the programming and debugging tasks, we conducted a semi-structured interview with each participant. We asked them to explain their approach to organizing their code and describe any adjustments they made based on Copilot\u2019s suggestions. They also shared the challenges they encountered and the solutions they implemented. Additionally, we encouraged them to reflect on how Copilot influenced the complexity of their tasks, providing examples of when it was particularly helpful or challenging. Our Appendix contains further details on the post-study interview questions.", "page": 8, "bbox": []}, "seg_92": {"summary": "Summary: Figure 1 illustrates the study setup with a diagram.", "text": "A diagram illustrating our study setup is shown in Figure 1 .", "page": 8, "bbox": []}, "seg_93": {"summary": "Insufficient content for summary.", "text": "3.3 Data Collection and Analysis", "page": 8, "bbox": []}, "seg_94": {"summary": "The researchers collected data through interviews, recording and transcribing both participant verbal responses and audio cues from assistive technologies.  They then analyzed this data using thematic coding to identify key patterns and insights. This methodology allowed for a comprehensive understanding of the participant experience.", "text": "We recorded and transcribed all interviews, capturing both verbal responses and relevant audio cues from participants\u2019 screen readers and other assistive technologies. We analyzed the data using thematic coding, focusing on significant Manuscript submitted to ACM", "page": 8, "bbox": []}, "seg_96": {"summary": "Insufficient content for summary.", "text": "The Impact of Generative AI Coding Assistants on Developers Who Are Visually Impaired", "page": 9, "bbox": []}, "seg_97": {"summary": "This study analyzed the experiences of visually impaired developers using GitHub Copilot by qualitatively coding interview transcripts to identify key themes and patterns.  Researchers focused on critical incidents to understand how Copilot impacted accessibility and aligned with or diverged from non-visual coding strategies. Activity Theory was used to further analyze the opportunities and challenges encountered by these developers when using the AI coding assistant.", "text": "events that participants experienced while using GitHub Copilot. Two of us independently coded the transcripts, identifying emerging themes and patterns. We paid special attention to pivotal moments that either enhanced or hindered participants\u2019 coding processes. These critical incidents provided concrete examples of how Copilot mediated accessibility, revealing specific ways in which the tool aligned with or diverged from the non-visual coding strategies used by developers who are visually impaired. To deepen our analysis, we integrated Activity Theory , which allowed us to examine the opportunities and contradictions that visually impaired developers encountered when interacting with an AI coding assistant. In particular, Activity Theory helped us explore within our themes:", "page": 9, "bbox": []}, "seg_98": {"summary": "Researchers applied Activity Theory to study how visually impaired developers used GitHub Copilot for coding tasks.  The study mapped the interactions within this activity system to understand how Copilot impacted developer workflows and to identify any resulting challenges or misalignments. This framework helped analyze the dynamics between developers, Copilot, and their coding activities.", "text": "(1) Activity-Centric Lens: how developers who are visually impaired ( subjects ) used GitHub Copilot ( tool ) to complete their coding tasks ( object ). By applying Activity Theory, we mapped the observed dynamics within the activity system, identifying key interactions and tensions among its components. This framework helped us understand how Copilot influenced developers\u2019 workflows and where misalignments or challenges emerged.", "page": 9, "bbox": []}, "seg_99": {"summary": "Visually impaired developers encounter challenges due to systemic contradictions in AI tools like Copilot.  Specifically, context switching and dynamic behaviors within these tools disrupt the sequential workflows crucial for these developers. These disruptions necessitate extra navigation adaptations to maintain productivity.", "text": "(2) Systemic Contradictions: challenges that developers who are visually impaired faced, particularly those arising from systemic contradictions . For example, some participants struggled with context switching imposed by the AI, while others had difficulty navigating Copilot\u2019s dynamic behaviors, which disrupted the sequential workflows that are critical for developers who are visually impaired. These disruptions required additional navigation adaptations to maintain productivity.", "page": 9, "bbox": []}, "seg_100": {"summary": "Summary: The text segment discusses adaptive solutions to identified challenges and mentions the application of the Activity Theory framework. This framework provides insights into how AI assistants can be improved to better suit the workflows of visually impaired developers. The ultimate goal is to create more inclusive and efficient coding environments.", "text": "(3) Adaptive Solutions: possible adaptive solutions to the challenges we identified. By applying the Activity Theory framework, we gained insights into how AI assistants could be better aligned with the specific workflows of developers who are visually impaired, ultimately fostering more inclusive and efficient coding environments.", "page": 9, "bbox": []}, "seg_101": {"summary": "Summary: This study used Activity Theory to analyze how visually impaired developers interact with AI coding assistants like Copilot. The analysis revealed key accessibility themes and design elements within Copilot that either helped or hindered these developers' workflows.  Ultimately, the findings advocate for a re-evaluation of accessibility standards in AI-assisted coding environments.", "text": "By integrating Activity Theory into our thematic analysis, we gained a deeper understanding of how developers who are visually impaired engage with AI coding assistants. This approach allowed us to identify key accessibility themes and design elements of Copilot that either supported or hindered participants\u2019 work processes. Our findings contribute to the broader goal of rethinking accessibility paradigms in AI-assisted coding environments.", "page": 9, "bbox": []}, "seg_103": {"summary": "Summary: Research involving interviews and observations has identified key themes regarding the intricate connection between AI coding assistants, accessibility requirements, and coding methods. These themes shed light on the challenges and opportunities encountered by visually impaired developers when utilizing AI-assisted coding tools such as GitHub Copilot. This research directly addresses the question of how these tools impact accessibility and coding practices for this specific group of developers.", "text": "Through our interviews and observations, we identified key themes that highlight the complex relationship between AI coding assistants, accessibility needs, and coding practices. These themes address our research question by revealing the challenges and opportunities that developers who are visually impaired encounter when using AI-assisted coding tools like GitHub Copilot.", "page": 9, "bbox": []}, "seg_104": {"summary": "This section presents themes from interviews and critical incidents to illustrate how generative AI coding assistants impact visually impaired developers, both positively and negatively.  Framed within Activity Theory, the findings reveal systemic misalignments between users, tools, and coding environments. The study aims to identify opportunities to improve the accessibility and inclusivity of AI coding assistants.", "text": "In this section, we present these themes. For each theme, we include illustrative quotes and describe critical incidents from our interviews. These incidents provide insight into the lived experiences of our participants, offering concrete examples of how generative AI coding assistants can both empower and hinder developers who are visually impaired. We frame our findings within the Activity Theory framework to contextualize these challenges as systemic misalignments between users, their tools, and the coding environments they work in. This approach allows us to examine how AI coding assistants mediate the development process and where breakdowns occur, helping us identify opportunities for more accessible and inclusive AI coding assistants.", "page": 9, "bbox": []}, "seg_105": {"summary": "Summary: This section, labeled as Research Question 1 (RQ1), explores the challenges and opportunities that AI coding assistants present for developers who are visually impaired. It aims to understand the specific implications of these tools for this user group.", "text": "4.1 RQ1: Challenges and Opportunities of AI Coding Assistants for Developers Who Are Visually Impaired", "page": 9, "bbox": []}, "seg_106": {"summary": "AI coding assistants were found to enhance the sense of control for visually impaired developers.", "text": "4.1.1 AI and Control . Our interviews revealed that AI coding assistants contributed to a dynamic sense of control among developers who are visually impaired. This enhanced control manifested in several positive ways. Participants", "page": 9, "bbox": []}, "seg_107": {"summary": "Summary: A manuscript has been submitted to ACM.", "text": "Manuscript submitted to ACM", "page": 9, "bbox": []}, "seg_109": {"summary": "Summary: Insufficient content for summary.", "text": "Flores-Saviaga, et al.", "page": 10, "bbox": []}, "seg_110": {"summary": "Summary: AI assistants are shifting developers' focus towards strategic control in coding by enabling them to delegate routine tasks. This allows developers to concentrate on high-level decisions and code structure, ultimately increasing their control over the development process. For example, Copilot assists with tedious tasks like generating documentation, freeing developers to focus on more strategic aspects of coding.", "text": "described experiencing a shift toward strategic control over the coding process. Rather than manually performing every task, they found that AI assistant allowed them to delegate routine or less engaging tasks, enabling them to focus on high-level decision-making and overall code structure. This ability to offload work gave them greater control in shaping their development process while maintaining oversight of their projects. For instance, P7 highlighted how Copilot eased their workload and gave them more control over their coding process by handling tasks they found tedious, such as generating docstrings\u2014special multiline comments in programming that explain the functionality of a function, class, or module:", "page": 10, "bbox": []}, "seg_111": {"summary": "Summary: The developer reports a positive experience with Copilot, particularly for its ability to automate tasks they find unenjoyable, such as generating documentation.  They appreciate Copilot's assistance with these less desirable aspects of development, even while planning to write the majority of their code themselves.", "text": "\u201cOverall, my experience with Copilot is positive, especially because it helps me with tasks I don\u2019t enjoy. I will write the majority of my own code [...], but where it [Copilot] can help me, I\u2019ll definitely let it [Copilot] do it. I love having it generate docstrings for me. That\u2019s cool, because frankly, I don\u2019t like writing documentation. I\u2019d rather code and let it do the heavy lifting for me...\u201d - P7, Developer with no vision.", "page": 10, "bbox": []}, "seg_112": {"summary": "Summary: AI empowers developers by automating routine tasks, freeing them to focus on complex challenges and increasing their workflow control.  One participant compared using AI to piloting an aircraft, highlighting this enhanced control.", "text": "This experience demonstrates how AI empowers developers by taking over tedious tasks they prefer to avoid. By automating routine work, AI enables developers to maintain greater control over their workflow and focus on more complex and engaging coding challenges. Similarly, participant P1, who had prior experience with AI coding assistants, compared coding with AI to piloting an aircraft, emphasizing how these assistants increase their sense of control:", "page": 10, "bbox": []}, "seg_113": {"summary": "Summary: This developer likens using Copilot to pair programming and flying a plane, where Copilot handles the repetitive coding tasks, similar to an autopilot.  The developer's role then shifts to a higher-level perspective, focusing on the overall direction and identifying potential problems, much like a pilot monitoring a plane's course.", "text": "\u201cI sort of compare it [Copilot] to pair programming almost, where [...] I\u2019m sort of driving, but the other person is doing all the sort of drudgery work. And what I\u2019m really mostly doing now is almost like what a pilot does when they\u2019re flying a plane. They\u2019re [...] not flying the plane physically for most of it. Most of it, the plane\u2019s flying itself, but the pilot does have to keep an eye on. Are we still going in the right direction? What\u2019s that big thing coming towards us really fast? Should we avoid that?\u201d - P1, Developer with no vision.", "page": 10, "bbox": []}, "seg_114": {"summary": "Summary: Activity Theory suggests AI tools like Copilot mediate the coding process, transforming how developers work. Copilot acts as an intermediary, shifting developer control and enabling them to concentrate on strategic, high-level decisions instead of lower-level coding tasks. This reallocation of focus is exemplified by developers P7 and P1.", "text": "From the perspective of Activity Theory, these findings illustrate the transformative role of AI tools as mediators in the coding process. In this context, Copilot functions as an intermediary that actively shapes a developer\u2019s control over their work, allowing developers to reallocate their focus toward higher-level strategic decisions, as demonstrated by P7 and P1.", "page": 10, "bbox": []}, "seg_115": {"summary": "Visually impaired developers can utilize AI coding assistants in a supervisory control model, where they oversee and guide the AI's output, correcting mistakes and ensuring alignment with their coding objectives. This approach shifts the developer's role from manual code writing to strategically guiding and refining AI-generated code, similar to a pilot managing an aircraft's automated systems.  This allows developers to focus on high-level project direction while delegating implementation details to the AI.", "text": "This shift in control also aligns with the concept of supervisory control [ 24 , 87 ], in which humans oversee and direct automated systems rather than executing tasks manually. In this case, the developers who are visually impaired guide the AI coding assistants by monitoring their outputs, making corrections when necessary, and ensuring alignment with their broader coding goals. Just as a pilot monitors and manages an aircraft\u2019s automated systems while remaining responsible for high-level navigation and safety decisions, developers can delegate routine implementation details to Copilot while maintaining oversight and control over the overall project direction. This dynamic shifts the developer\u2019s role from manually writing every line of code to curating, refining, and strategically guiding the AI\u2019s output.", "page": 10, "bbox": []}, "seg_116": {"summary": "Summary: In this evolving coding paradigm, developer control shifts from writing individual lines of code to a more strategic role of guiding the overall direction and making critical decisions. Developers now oversee AI-generated suggestions, ensuring they align with the broader project architecture and goals, while still retaining ultimate authority. This represents a move towards a more abstract and high-level form of control.", "text": "In this new paradigm, control manifests as the ability to guide the overall direction of the code, make critical decisions, and intervene when necessary. While the developer retains ultimate authority over the coding process, the nature of that control shifts to a more abstract and strategic level. Rather than focusing solely on writing individual lines of code, developers can now oversee and direct AI-generated suggestions to ensure they align with the broader project architecture and goals.", "page": 10, "bbox": []}, "seg_117": {"summary": "Summary: The increasing control developers have with AI tools demands they acquire new skills. These skills include prompt engineering to guide AI outputs, evaluating the quality of AI-generated code, and maintaining a high-level perspective on software design.", "text": "However, this shift in control also requires developers to develop new skills, such as crafting effective prompts to generate useful AI outputs, quickly assessing the quality and relevance of the AI-generated code, and maintaining a high-level understanding of the overall software design. As highlighted by P1:", "page": 10, "bbox": []}, "seg_118": {"summary": "Insufficient content for summary.", "text": "Manuscript submitted to ACM", "page": 10, "bbox": []}, "seg_120": {"summary": "This text segment likely discusses the effects of generative AI coding assistants on developers who are visually impaired. It probably explores how these AI tools influence the workflows, accessibility, and productivity of visually impaired programmers.", "text": "The Impact of Generative AI Coding Assistants on Developers Who Are Visually Impaired", "page": 11, "bbox": []}}