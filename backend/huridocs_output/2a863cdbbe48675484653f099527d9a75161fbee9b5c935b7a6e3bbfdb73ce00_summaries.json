{"seg_0": {"summary": "Insufficient content for summary.", "text": "The Impact of Generative AI Coding Assistants on Developers Who Are Visually Impaired", "page": 1, "bbox": []}, "seg_1": {"summary": "Summary: This text segment lists the authors and their affiliations. Claudia Flores-Saviaga, Kashif Imteyaz, and Saiph Savage are affiliated with Northeastern University in the USA, while Benjamin V. Hanrahan and Steven Clarke are affiliated with Microsoft in the USA and United Kingdom, respectively.", "text": "CLAUDIA FLORES-SAVIAGA, Northeastern University, USA BENJAMIN V. HANRAHAN, Microsoft, USA KASHIF IMTEYAZ, Northeastern University, USA STEVEN CLARKE, Microsoft, United Kingdom SAIPH SAVAGE, Northeastern University, USA", "page": 1, "bbox": []}, "seg_3": {"summary": "Summary: Figure 1 provides an overview of research focused on understanding how developers with visual impairments interact with AI coding assistants.  This research aims to analyze the specific ways visually impaired developers use and engage with AI coding assistants.", "text": "Fig. 1. Overview of our research to analyze how developers who are visually impaired interact with AI coding assistants.", "page": 1, "bbox": []}, "seg_4": {"summary": "A study exploring the use of AI coding assistants by developers with visual impairments found that while beneficial, these tools also presented accessibility challenges, such as overwhelming suggestions and difficulty switching between AI-generated and user code.  Despite these issues, participants were optimistic about the potential of AI assistants, highlighting the need for activity-centered design to improve inclusivity and effectiveness for developers with visual impairments.  This approach can lead to more intuitive and accessible AI tools for software development.", "text": "The rapid adoption of generative AI in software development has impacted the industry, yet its effects on developers with visual impairments remain largely unexplored. To address this gap, we used an Activity Theory framework to examine how developers with visual impairments interact with AI coding assistants. For this purpose, we conducted a study where developers who are visually impaired completed a series of programming tasks using a generative AI coding assistant. We uncovered that, while participants found the AI assistant beneficial and reported significant advantages, they also highlighted accessibility challenges. Specifically, the AI coding assistant often exacerbated existing accessibility barriers and introduced new challenges. For example, it overwhelmed users with an excessive number of suggestions, leading developers who are visually impaired to express a desire for \u201cAI timeouts.\u201d Additionally, the generative AI coding assistant made it more difficult for developers to switch contexts between the AI-generated content and their own code. Despite these challenges, participants were optimistic about the potential of AI coding assistants to transform the coding experience for developers with visual impairments. Our findings emphasize the need to apply activity-centered design principles to generative AI assistants, ensuring they better align with user behaviors and address specific accessibility needs. This approach can enable the assistants to provide more intuitive, inclusive, and effective experiences, while also contributing to the broader goal of enhancing accessibility in software development.", "page": 1, "bbox": []}, "seg_5": {"summary": "Insufficient content for summary.", "text": "ACM Reference Format:", "page": 1, "bbox": []}, "seg_6": {"summary": "Summary: This research paper, authored by Flores-Saviaga, Hanrahan, Imteyaz, Clarke, and Savage, investigates the impact of generative AI coding assistants on developers with visual impairments.  Published in March 2025, the 25-page study is accessible via the provided DOI link.", "text": "Claudia Flores-Saviaga, Benjamin V. Hanrahan, Kashif Imteyaz, Steven Clarke, and Saiph Savage. 2025. The Impact of Generative AI Coding Assistants on Developers Who Are Visually Impaired. 1, 1 (March 2025), 25 pages. https://doi.org/10.1145/nnnnnnn.nnnnnnn", "page": 1, "bbox": []}, "seg_7": {"summary": "Summary: This text segment lists the authors of a publication, along with their affiliations at Northeastern University and Microsoft, and their respective email addresses.  It provides contact information for each author.", "text": "Authors\u2019 addresses: Claudia Flores-Saviaga, floressaviaga.c@northeastern.edu, Northeastern University, USA; Benjamin V. Hanrahan, benhanrahan@ microsoft.com, Microsoft, USA; Kashif Imteyaz, imteyaz.k@northeastern.edu, Northeastern University, USA; Steven Clarke, stevencl@microsoft.com, Microsoft, United Kingdom; Saiph Savage, s.savage@northeastern.edu, Northeastern University, USA.", "page": 1, "bbox": []}, "seg_8": {"summary": "Summary: This text segment is a copyright notice from the Association for Computing Machinery (ACM) regarding permitted uses of their work.  It grants free permission for personal and classroom use, provided it is not for profit and includes proper citation.  Any other use, such as commercial redistribution or republication, requires explicit permission and potentially a fee, obtainable from ACM.", "text": "Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. \u00a9 2025 Association for Computing Machinery.", "page": 1, "bbox": []}, "seg_9": {"summary": "Summary: A manuscript has been submitted to ACM.", "text": "Manuscript submitted to ACM", "page": 1, "bbox": []}, "seg_10": {"summary": "Insufficient content for summary.", "text": "Manuscript submitted to ACM", "page": 1, "bbox": []}, "seg_13": {"summary": "Summary: Insufficient content for summary.", "text": "Flores-Saviaga, et al.", "page": 2, "bbox": []}, "seg_14": {"summary": "Insufficient content for summary.", "text": "1 INTRODUCTION", "page": 2, "bbox": []}, "seg_15": {"summary": "Generative AI is transforming software development through coding assistants like GitHub Copilot, which offer functionalities such as auto-completion and code generation.  This technological shift raises an important question regarding the impact of these AI tools on developers with visual impairments. The text segment highlights the need to understand how this emerging technology affects accessibility and inclusivity in coding.", "text": "The integration of generative artificial intelligence (AI) into software development is fundamentally transforming coding practices [ 55 ]. AI coding assistants, such as GitHub Copilot [ 34 ], provide functionalities like auto-completion, code generation, and test generation [ 76 ], which have the potential to revolutionize how developers work [ 73 ]. Amidst this surge of new capabilities driven by AI, an important question emerges: How do these generative AI coding assistants impact developers with visual impairments?", "page": 2, "bbox": []}, "seg_16": {"summary": "AI's integration into coding offers opportunities to improve accessibility for developers with visual impairments by automating tasks and providing intelligent support.  However, if AI coding assistants are not designed with accessibility in mind, they risk creating new obstacles, especially for screen reader users.  Therefore, careful consideration of accessibility is crucial in the development of AI-powered coding tools.", "text": "The convergence of AI and accessibility in coding presents both tremendous opportunities and intricate challenges [ 55 , 67 ]. On one hand, AI has the potential to make coding more accessible for developers with visual impairments by reducing manual coding tasks and providing intelligent assistance [ 89 ]. On the other hand, if these AI coding assistants are not designed with accessibility in mind, they may inadvertently create new barriers or worsen existing ones [ 67 , 103 ]. This risk is especially high if the AI coding assistants depend heavily on visual cues or employ interaction methods incompatible with screen readers [ 61 , 86 , 109 ].", "page": 2, "bbox": []}, "seg_17": {"summary": "The accessibility challenges in AI assistants mirror those in web accessibility, particularly for visually impaired users, due to dynamic content and complex interactions.  Traditional accessibility guidelines may not fully address these issues in AI coding assistants, where AI-generated suggestions and interfaces can create new hurdles for visually impaired developers.  Further research is needed to understand and address these difficulties to make AI coding assistants truly accessible and user-friendly for all developers.", "text": "In this context, it is important to understand that the relationship between accessibility and usability in AI assistants mirrors longstanding challenges in web accessibility [ 38 , 51 ], particularly for visually impaired users [ 14 , 43 ]. Similar to rich internet applications [ 9 , 72 ], AI assistants often introduce dynamic content and complex interactions that traditional accessibility approaches may not fully address [ 39 , 47 ]. For instance, Petrie and Kheir [ 74 ] found that existing accessibility guidelines fail to capture many of the usability problems encountered by visually impaired users when interacting with dynamic content. This gap could be especially exacerbated in AI coding assistants [ 2 , 65 , 71 ], where AI-generated suggestions, real-time code generation, and sophisticated user interfaces can present new hurdles [ 39 , 41 ]. Just as screen readers struggle with dynamic web content, AJAX updates, and automatic refreshes [ 20 ], developers who are visually impaired may experience similar difficulties when interacting with rapidly changing AI-generated code suggestions and interface elements [ 54 ]. Consequently, simply following basic accessibility rules might not be enough to make AI coding assistants truly easy to use. We might need to rethink how to make these assistants more accessible for everyone. The challenge is that we do not fully understand the difficulties and benefits that visually impaired developers experience when using AI coding assistants. Closing this knowledge gap is important\u2014not just for accessibility, but also for making AI-assisted coding tools more user-friendly and effective for all developers, including those with different levels of vision.", "page": 2, "bbox": []}, "seg_18": {"summary": "Summary: This study investigates the unique challenges and opportunities that AI-assisted coding tools present for developers with visual impairments.  The research is driven by a question focused on understanding these challenges and opportunities.", "text": "Our study addresses this research gap by investigating what unique challenges and opportunities AI-assisted coding tools present for developers with visual impairments. Our research is driven by the following research question:", "page": 2, "bbox": []}, "seg_19": {"summary": "Summary: This research question explores the challenges that AI coding tools present to visually impaired developers.  It also investigates the potential of these tools to create new opportunities and improve the work of developers with visual impairments.", "text": "\u2022 RQ1: What challenges do AI-assisted coding tools pose for developers who are visually impaired, and what opportunities do they offer to empower and enhance their work?", "page": 2, "bbox": []}, "seg_20": {"summary": "This study uses the Activity Theory framework to investigate how visually impaired developers interact with the AI coding assistant GitHub Copilot. Researchers observed ten developers with varying experience levels as they completed a coding task using Copilot and conducted interviews afterwards. The study aimed to identify both the challenges and opportunities these developers encountered when using the AI assistant.", "text": "To study this question, we use the Activity Theory framework [ 44 ], which helps analyze how tools influence human activity and identifies contradictions that occur when a tool\u2019s design does not fit well with users\u2019 workflows and needs [ 12 ]. We applied this framework to examine a qualitative study we conducted with 10 visually impaired developers of varying experience levels. These developers used an AI coding assistant, GitHub Copilot, to complete a coding task. During the study, we observed their real-time interactions with the AI assistant, noting both challenges and opportunities. After the task, we conducted interviews to gain deeper insights into their experiences and the difficulties they faced while using the AI coding assistant.", "page": 2, "bbox": []}, "seg_21": {"summary": "Summary: This study reveals that AI coding assistants have a dual impact, enhancing coding efficiency while simultaneously posing new accessibility challenges.  Based on these findings, the authors propose a roadmap for developing the next generation of accessible AI tools. This research contributes to the understanding of the complex relationship between AI in coding and accessibility.", "text": "Our findings reveal a complex landscape where AI coding assistants can both improve coding efficiency and introduce new accessibility challenges. Based on our findings, we outline a roadmap for the next generation of accessible AI Manuscript submitted to ACM", "page": 2, "bbox": []}, "seg_23": {"summary": "Summary: This text segment will explore how generative AI coding assistants affect developers who are visually impaired. It will likely examine the specific ways these tools impact their coding experience.", "text": "The Impact of Generative AI Coding Assistants on Developers Who Are Visually Impaired", "page": 3, "bbox": []}, "seg_24": {"summary": "Summary: This text segment discusses research focused on the experiences of visually impaired developers using AI coding assistants. The goal of this research is to derive key design insights that can improve accessibility in AI-driven software development. Ultimately, these insights are intended to reshape how accessibility is approached in the development of AI-driven software.", "text": "coding assistants. By analyzing the experiences of visually impaired developers using AI-assisted coding tools, we derive key design insights that can reshape how accessibility is approached in AI-driven software development.", "page": 3, "bbox": []}, "seg_25": {"summary": "Insufficient content for summary.", "text": "The contributions of this paper are twofold:", "page": 3, "bbox": []}, "seg_26": {"summary": "Summary: This research offers a thorough examination of the accessibility of AI coding assistants, specifically looking at the challenges and advantages for developers who are visually impaired. The study is based on practical experiences and perspectives from visually impaired developers themselves.", "text": "\u2022 We conduct a comprehensive analysis of the accessibility challenges and benefits of AI coding assistants, using real-world insights from developers who are visually impaired.", "page": 3, "bbox": []}, "seg_27": {"summary": "Summary: This segment introduces design recommendations aimed at improving the accessibility and inclusivity of AI coding assistants.  The recommendations are specifically targeted towards developers with visual impairments.", "text": "\u2022 We propose a set of design recommendations to make AI coding assistants more accessible and inclusive for developers with visual impairments.", "page": 3, "bbox": []}, "seg_28": {"summary": "Insufficient content for summary.", "text": "2 RELATED WORK", "page": 3, "bbox": []}, "seg_29": {"summary": "Insufficient content for summary.", "text": "2.1 Accessibility and Tools for Developers who are Visually Impaired", "page": 3, "bbox": []}, "seg_30": {"summary": "Studies have consistently shown that visually impaired developers face significant challenges in coding. These challenges span multiple areas, including code navigation, comprehension, editing, debugging, and skimming, as identified by Mountapmbeme et al. Further research by Albusays and Ludi highlights ongoing difficulties in code navigation, diagrams, debugging, and UI layouts, leading to a preference for text editors over IDEs due to accessibility concerns.", "text": "Accessibility in general has been a subject of ongoing research [ 17 , 35 , 36 , 85 ]. Several studies have shed light on the significant challenges developers who are visually impaired face with coding and the techniques these programmers employ to overcome these challenges. Mountapmbeme et al. [ 63 ] categorized these challenges into five main areas: code navigation, code comprehension, code editing, code debugging, and code skimming. Albusays and Ludi [ 5 ] found persistent challenges in code navigation, accessing diagrams, debugging, and UI layout. Their study highlighted a strong preference for text editors over IDEs due to accessibility issues, reduced complexity, and better compatibility with assistive technologies.", "page": 3, "bbox": []}, "seg_31": {"summary": "Visually impaired developers often favor text editors over IDEs due to accessibility limitations, leading to unique coding practices.  Challenges include navigating code structure and debugging with visually oriented tools. To mitigate these issues, researchers have developed tools like StructJumper for code navigation and audio-based debuggers like Wicked Audio Debugger and CodeTalk, as well as collaborative tools like CodeWalk and Grid-Coding to improve coding environment accessibility.", "text": "Further studies by Mealin and Murphy-Hill [ 59 ] and Baker et al. [ 11 ] explored specific tools and techniques that developers who are visually impaired use. Mealin and Murphy-Hill found that many developers who are visually impaired rely on text editors rather than IDEs due to accessibility issues employing unique practices like \u201cout-of-context editing,\u201d where blocks of code are copied, edited separately, and pasted back. This preference for text editors has been corroborated by other researchers [ 6 , 63 ], who attribute it to specific challenges such as navigating line-by-line, understanding indentation, and managing nested code structures [ 56 , 99 ]. To address this issue, Baker et al. [ 11 ] created StructJumper, a plugin that generates a hierarchical tree structure of code for easier navigation. Debugging, presents another significant challenge for developers who are visually impaired, largely due to the reliance on visual interfaces in debugging tools, which screen readers struggle to interpret effectively [ 5 , 78 ]. These challenges have led the development of tools like Wicked Audio Debugger (WAD) [ 94 ] , a tool that provides audio descriptions of programs during execution; CodeTalk [ 78 ], a Visual Studio plugin that introduces \u201cTalkPoints\u201d for audio-based debugging; and CodeWalk, a tool by Potluri et al. [ 77 ], which facilitates accessible, remote, synchronous code review and refactoring activities by tethering collaborators\u2019 cursors with the host of a Live Share session. Additionally, Haque et al. [ 27 ] introduced Grid-Coding, a paradigm designed to improve the accessibility of coding environments by representing code in a structured 2D grid, allowing developers who are visually impaired to navigate and edit code more effectively.", "page": 3, "bbox": []}, "seg_32": {"summary": "Summary: Conversational interfaces, especially speech-based ones, show promise in improving comprehension and navigation. Studies have explored their effectiveness in reducing cognitive load through voice commands and their application in development environments using audio cues for tasks like debugging and file navigation.", "text": "Conversational interfaces have also shown promise [ 15 ], Ludi et al. [ 57 ], found that speech-based cues generally provided the best performance for comprehension and navigation tasks. Phutane et al. [ 75 ] explored the use of voice commands to reduce cognitive load. Meanwhile, Stefik et al. [ 95 ] created Sodbeans, an IDE that relies on audio cues for debugging, while Smith et al. [ 90 ] developed a tool to allow developers to navigate the tree structure of files in Eclipse.", "page": 3, "bbox": []}, "seg_33": {"summary": "Summary: Existing research on accessibility for visually impaired developers may not fully address the new challenges and opportunities presented by generative AI coding tools like GitHub Copilot.  The impact of these tools on accessible programming remains largely unexamined as most current studies predate their emergence.", "text": "While previous research has significantly advanced accessibility for developers who are visually impaired, these findings may not fully apply to the new landscape shaped by generative AI-assisted coding tools such as GitHub Copilot. The introduction of these tools brings new challenges and opportunities in accessible programming, an area that remains largely unexamined. The majority of current studies were conducted before the emergence of generative", "page": 3, "bbox": []}, "seg_34": {"summary": "Summary: A manuscript has been submitted to the ACM, likely for review and potential publication.", "text": "Manuscript submitted to ACM", "page": 3, "bbox": []}, "seg_36": {"summary": "Insufficient content for summary.", "text": "Flores-Saviaga, et al.", "page": 4, "bbox": []}, "seg_37": {"summary": "Summary:  A significant knowledge gap exists concerning the effects of AI coding tools on developers with visual impairments.  This lack of understanding hinders our ability to assess the impact and possibilities of these tools for visually impaired programmers.", "text": "AI in coding environments, resulting in a critical knowledge gap regarding the impact and potential of these advanced tools for developers who are visually impaired.", "page": 4, "bbox": []}, "seg_38": {"summary": "Insufficient content for summary.", "text": "2.2 AI-assisted Coding Environments", "page": 4, "bbox": []}, "seg_39": {"summary": "AI-assisted coding tools like GitHub Copilot are shown to increase developer productivity and speed up programming tasks. However, studies also reveal challenges, as developers can struggle with understanding, editing, and debugging AI-generated code, impacting task effectiveness.  The tool's utility is also dependent on the developer's expertise level, as less experienced developers may find it harder to assess AI suggestions.", "text": "The integration of AI into software development tools has significantly impacted coding practices, with AI-assisted coding assistants like GitHub Copilot showing promise in improving developer productivity. Ziegler et al. [ 108 ] found that Copilot increases users\u2019 feelings of productivity, with almost a third of its proposed code completions being accepted. In a controlled experiment, Peng et al.[ 73 ] demonstrated that software developers using Github Copilot were able to complete programming tasks significantly faster than those without such assistance. However, Vaithilingam et al. [ 100 ] noted that while most participants preferred using Copilot in daily programming tasks, they often faced difficulties in understanding, editing, and debugging code snippets generated by Copilot, which significantly hindered their task-solving effectiveness. This was confirmed by Dakhel et al [ 26 ], who noted that the effectiveness of tools like Github Copilot depends on the developer\u2019s level of expertise, as less experienced developers often lack the necessary skills to effectively evaluate AI-generated code suggestions.", "page": 4, "bbox": []}, "seg_40": {"summary": "Summary: According to a survey by Liang et al., developers primarily use AI programming assistants to reduce keystrokes, speed up task completion, and aid in syntax recall. The survey also indicated that developers are utilizing these tools for a significant portion of their coding, with a median of 30.5% of code being generated with AI assistance.", "text": "A recent survey of developers by Liang et al. [ 55 ] revealed that the primary motivations for using AI programming assistants include reducing keystrokes, finishing programming tasks quickly, and recalling syntax. Developers reported that a median of 30.5% of their code was written with help from tools like Copilot.", "page": 4, "bbox": []}, "seg_41": {"summary": "Studies have explored how developers interact with AI coding assistants, identifying modes like \"acceleration\" and \"exploration\" and comparing human-AI to human-human pair programming.  These studies reveal insights into collaboration dynamics, but a key gap remains in understanding the impact of AI coding assistants on developers with accessibility needs. Further research is needed to address this underrepresented perspective.", "text": "Studies like those by Barke et al.[ 66 ] and Wu et al. [ 58 ] provide insight into the varying modes of interaction with AI coding assistants. Barke et al. [ 66 ] identified \u201cacceleration mode\u201d and \u201cexploration mode\u201d as two broad categories of Copilot use, while Wu et al. [ 58 ] compared human-human pair programming with human-AI pair programming, highlighting differences in collaboration dynamics. However, there is still a significant gap in understanding how these AI tools impact developers with accessibility needs.", "page": 4, "bbox": []}, "seg_42": {"summary": "Insufficient content for summary.", "text": "2.3 Activity Theory", "page": 4, "bbox": []}, "seg_43": {"summary": "A visually impaired software developer uses Github Copilot as a tool to assist with coding tasks. This highlights the use of the tool by a specific user group for a particular purpose.", "text": "Tool ( Github Copilot ) Subject (Software developer who is visually impaired) Object ( Coding task )", "page": 4, "bbox": []}, "seg_44": {"summary": "Summary: Fig. 2 illustrates the relationship between visually impaired software developers (subject), coding tasks (object), and GitHub Copilot (mediating tool). This relationship is presented within the Activity Theory framework.", "text": "Fig. 2. Diagram illustrating the relationship between software developers who are visually impaired (subject), coding tasks (object), and GitHub Copilot (mediating tool) within the Activity Theory framework.", "page": 4, "bbox": []}, "seg_45": {"summary": "Summary: Activity Theory is a conceptual framework used to guide research and problem-solving.  It centers on the concept of \"activity,\" defined as goal-directed actions mediated by artifacts to achieve specific objectives. These actions are carried out through routinized operations.", "text": "Activity Theory is a type of \u201cconceptual frame- work\u201d [ 80 , 82 , 88 , 91 ]. A conceptual framework is an analytical tool or structure used to organize and guide research, projects, or problem-solving efforts [ 40 , 60 ]. The foundational concept of Activity The- ory is the \u201cactivity\u201d, a series of goal directed actions [ 53 ] that aim to achieve specific objectives [ 52 ]. These actions are mediated by artifacts, the instru- ments through which individuals interact with their objectives. Actions themselves are performed via routinized operations, in which individuals are not conscious of or focused on these operations. This process is illustrated in Figure 2 . For example, devel- opers who are visually impaired (the subjects) may have specific goals (objects) related to completing", "page": 4, "bbox": []}, "seg_46": {"summary": "Summary: In the context of programming tasks, an AI programming tool is defined as a mediating artifact, essentially functioning as a tool itself.", "text": "programming tasks. In this context, an AI programming tool acts as the mediating artifact (tool). Manuscript submitted to ACM", "page": 4, "bbox": []}, "seg_48": {"summary": "Insufficient content for summary.", "text": "The Impact of Generative AI Coding Assistants on Developers Who Are Visually Impaired", "page": 5, "bbox": []}, "seg_49": {"summary": "Summary: B\u00f8dker introduced Activity Theory as a foundational framework for HCI, emphasizing the dynamic interplay between users, their goals, and the tools they use, advocating for tool evolution to meet user needs.  Within this theory, contradictions between users, goals, and tools are seen as drivers of change, while misalignments are identified as localized usability issues that may not require systemic changes. Activity Theory, therefore, guides the design of adaptable interactive systems by addressing these tensions and mismatches.", "text": "B\u00f8dker proposed Activity Theory as a foundational framework for HCI [ 18 ], emphasizing its potential to guide the design of interactive systems by focusing on the dynamic interplay between users, their goals, and the tools users employ (interactive systems) [ 19 ]. B\u00f8dker emphasized that tools should evolve over time to meet users\u2019 needs and adapt to the activities they mediate[ 18 ], highlighting the importance of designing systems that adjust to changing workflows and contexts to remain effective[ 19 ]. Within B\u00f8dker\u2019s definition of Activity Theory for HCI [ 18 ], contradictions are discrepancies or tensions that arise between the tools, the goals, and the users, that must be addressed [ 28 ]. These contradictions are not obstacles but drivers of change, pointing out areas where tools or processes need to evolve to better meet user needs [ 29 ]. Within this space, Activity Theory also introduces the concept of misalignments , which are localized issues or practical mismatches. Unlike contradictions , misalignments hinder usability and effectiveness for end-users but may not necessitate systemic changes.", "page": 5, "bbox": []}, "seg_50": {"summary": "This paper uses Activity Theory to investigate the design of AI-assisted coding tools for visually impaired developers.  Activity Theory is presented as a suitable framework due to its established history in studying technologies designed for diverse groups, including individuals with disabilities. Prior research has successfully applied Activity Theory to analyze various technologies for people with disabilities, such as tactile devices and audio-haptic tools.", "text": "In this paper, we use Activity Theory as a framework to examine the design of AI-assisted coding tools for developers who are visually impaired. We chose this approach because Activity Theory has been widely used for decades to study tools and technologies designed for diverse groups, including individuals with disabilities [ 12 , 18 , 28 , 44 , 45 , 81 , 97 ]. For example, Baldwin et al. [ 12 ] applied Activity Theory to investigate the design of tactile devices and enhanced auditory tools, examining whether these technologies align with the unique workflows of users who have no or low-vision. Similarly, Szymczak [ 97 ] applied Activity Theory to analyze how audio-haptic technologies mediated interactions and supported the goals of individuals who are visually impaired, focusing on how these technologies could assist users in interacting with 2D representations, such as maps and drawings. Tlili et al. [ 98 ], also applied Activity Theory to review the use of game-based learning for learners with disabilities and identify inconsistencies in stakeholder involvement, variability in the use of educational technology, and difficulties in standardizing performance measures. Robins [ 81 ] applied Activity Theory to analyze and design accessibility in video games, focusing on the interaction between visually impaired players, game goals, and mediating tools like audio-haptic technologies and game mechanics.", "page": 5, "bbox": []}, "seg_51": {"summary": "Summary: The table presents data for ten male participants with either low vision or no vision who participated in a study.  These participants possess diverse coding experience and have utilized various AI coding tools such as GitHub Copilot and ChatGPT.  Python and C# were the preferred programming languages for the study task, which was successfully completed by all participants.", "text": "P# Gender Age Exp.(yrs) Vision Status AI-Coding Tool Experience Coding Proficiency Pref. Lang. For Study Task Completed P1 Male 32 8 No vision GitHub Copilot C#, JavaScript, Python, Ruby Python Yes P2 Male 34 12 Low vision GitHub Copilot PHP, C#, JavaScript C# Yes P3 Male 38 9 Low vision CodeWhisperer, Codellama, ChatGPT C++, Python Python Yes P4 Male 43 22 Low vision ChatGPT JavaScript, TypeScript, C# C# Yes P5 Male 26 6 No vision GitHub Copilot, ChatGPT Python Python Yes P6 Male 36 17 Low vision GitHub Copilot PHP, Ruby, Swift, Go, Python, JavaScript, Kotlin Python Yes P7 Male 58 23 No vision GitHub Copilot Python, SQL, PowerShell Python Yes P8 Male 54 32 No vision ChatGPT C, R, Ruby, TypeScript, Swift, Python, Kotlin Python Yes P9 Male 42 4 No vision ChatGPT JavaScript, PHP, Python, HTML, CSS Python Yes P10 Male 24 2 No vision Claude, ChatGPT, Gemini C#, HTML, PHP C# Yes", "page": 5, "bbox": []}, "seg_52": {"summary": "Insufficient content for summary.", "text": "Table 1. Participant Demographics, Vision Status, Experience with AI Coding Assistants, and Programming Background.", "page": 5, "bbox": []}, "seg_53": {"summary": "This paper utilizes Activity Theory to study the impact of AI-assisted coding tools, specifically GitHub Copilot, on visually impaired developers.  The analysis investigates how these tools mediate developer tasks and identifies both systemic contradictions and usability misalignments.  Ultimately, the research aims to provide design recommendations to enhance AI coding tools to better meet the needs of developers with visual impairments.", "text": "Building on this foundation, our paper applies Activity Theory to examine how AI-assisted coding tools, particularly GitHub Copilot, mediate and influence the tasks of developers who are visually impaired. Activity Theory provides a particularly useful analysis framework since the introduction of AI coding assistants may operationalize some actions that have not yet become routine for developers. Additionally, we use Activity Theory to guide design recommendations aimed at improving these tools for this population. To achieve this, we analyze both contradictions \u2014systemic tensions within the activity system\u2014and misalignments \u2014localized issues that disrupt usability. By addressing these challenges, we ensure AI tools meet developers\u2019 needs.", "page": 5, "bbox": []}, "seg_54": {"summary": "Summary: Manuscript submission to ACM has occurred.", "text": "Manuscript submitted to ACM", "page": 5, "bbox": []}}