[
  {
    "left": 73.0,
    "top": 93.0,
    "width": 270.0,
    "height": 28.0,
    "page_number": 1,
    "page_width": 612,
    "page_height": 792,
    "text": "The Impact of Generative AI Coding Assistants on Developers Who Are Visually Impaired",
    "type": "Section header"
  },
  {
    "left": 72.0,
    "top": 137.0,
    "width": 246.0,
    "height": 73.0,
    "page_number": 1,
    "page_width": 612,
    "page_height": 792,
    "text": "CLAUDIA FLORES-SAVIAGA, Northeastern University, USA BENJAMIN V. HANRAHAN, Microsoft, USA KASHIF IMTEYAZ, Northeastern University, USA STEVEN CLARKE, Microsoft, United Kingdom SAIPH SAVAGE, Northeastern University, USA",
    "type": "Text"
  },
  {
    "left": 118.0,
    "top": 230.0,
    "width": 332.0,
    "height": 62.0,
    "page_number": 1,
    "page_width": 612,
    "page_height": 792,
    "text": "",
    "type": "Picture"
  },
  {
    "left": 89.0,
    "top": 308.0,
    "width": 395.0,
    "height": 7.0,
    "page_number": 1,
    "page_width": 612,
    "page_height": 792,
    "text": "Fig. 1. Overview of our research to analyze how developers who are visually impaired interact with AI coding assistants.",
    "type": "Caption"
  },
  {
    "left": 73.0,
    "top": 327.0,
    "width": 428.0,
    "height": 157.0,
    "page_number": 1,
    "page_width": 612,
    "page_height": 792,
    "text": "The rapid adoption of generative AI in software development has impacted the industry, yet its effects on developers with visual impairments remain largely unexplored. To address this gap, we used an Activity Theory framework to examine how developers with visual impairments interact with AI coding assistants. For this purpose, we conducted a study where developers who are visually impaired completed a series of programming tasks using a generative AI coding assistant. We uncovered that, while participants found the AI assistant beneficial and reported significant advantages, they also highlighted accessibility challenges. Specifically, the AI coding assistant often exacerbated existing accessibility barriers and introduced new challenges. For example, it overwhelmed users with an excessive number of suggestions, leading developers who are visually impaired to express a desire for \u201cAI timeouts.\u201d Additionally, the generative AI coding assistant made it more difficult for developers to switch contexts between the AI-generated content and their own code. Despite these challenges, participants were optimistic about the potential of AI coding assistants to transform the coding experience for developers with visual impairments. Our findings emphasize the need to apply activity-centered design principles to generative AI assistants, ensuring they better align with user behaviors and address specific accessibility needs. This approach can enable the assistants to provide more intuitive, inclusive, and effective experiences, while also contributing to the broader goal of enhancing accessibility in software development.",
    "type": "Text"
  },
  {
    "left": 72.0,
    "top": 497.0,
    "width": 86.0,
    "height": 8.0,
    "page_number": 1,
    "page_width": 612,
    "page_height": 792,
    "text": "ACM Reference Format:",
    "type": "Section header"
  },
  {
    "left": 72.0,
    "top": 509.0,
    "width": 429.0,
    "height": 19.0,
    "page_number": 1,
    "page_width": 612,
    "page_height": 792,
    "text": "Claudia Flores-Saviaga, Benjamin V. Hanrahan, Kashif Imteyaz, Steven Clarke, and Saiph Savage. 2025. The Impact of Generative AI Coding Assistants on Developers Who Are Visually Impaired. 1, 1 (March 2025), 25 pages. https://doi.org/10.1145/nnnnnnn.nnnnnnn",
    "type": "Text"
  },
  {
    "left": 73.0,
    "top": 544.0,
    "width": 429.0,
    "height": 26.0,
    "page_number": 1,
    "page_width": 612,
    "page_height": 792,
    "text": "Authors\u2019 addresses: Claudia Flores-Saviaga, floressaviaga.c@northeastern.edu, Northeastern University, USA; Benjamin V. Hanrahan, benhanrahan@ microsoft.com, Microsoft, USA; Kashif Imteyaz, imteyaz.k@northeastern.edu, Northeastern University, USA; Steven Clarke, stevencl@microsoft.com, Microsoft, United Kingdom; Saiph Savage, s.savage@northeastern.edu, Northeastern University, USA.",
    "type": "Text"
  },
  {
    "left": 73.0,
    "top": 585.0,
    "width": 428.0,
    "height": 48.0,
    "page_number": 1,
    "page_width": 612,
    "page_height": 792,
    "text": "Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. \u00a9 2025 Association for Computing Machinery.",
    "type": "Footnote"
  },
  {
    "left": 73.0,
    "top": 636.0,
    "width": 86.0,
    "height": 7.0,
    "page_number": 1,
    "page_width": 612,
    "page_height": 792,
    "text": "Manuscript submitted to ACM",
    "type": "Footnote"
  },
  {
    "left": 72.0,
    "top": 658.0,
    "width": 86.0,
    "height": 7.0,
    "page_number": 1,
    "page_width": 612,
    "page_height": 792,
    "text": "Manuscript submitted to ACM",
    "type": "Page footer"
  },
  {
    "left": 497.0,
    "top": 658.0,
    "width": 4.0,
    "height": 7.0,
    "page_number": 1,
    "page_width": 612,
    "page_height": 792,
    "text": "1",
    "type": "Page footer"
  },
  {
    "left": 109.0,
    "top": 71.0,
    "width": 4.0,
    "height": 8.0,
    "page_number": 2,
    "page_width": 612,
    "page_height": 792,
    "text": "2",
    "type": "Page header"
  },
  {
    "left": 463.0,
    "top": 70.0,
    "width": 75.0,
    "height": 8.0,
    "page_number": 2,
    "page_width": 612,
    "page_height": 792,
    "text": "Flores-Saviaga, et al.",
    "type": "Page header"
  },
  {
    "left": 109.0,
    "top": 99.0,
    "width": 84.0,
    "height": 7.0,
    "page_number": 2,
    "page_width": 612,
    "page_height": 792,
    "text": "1 INTRODUCTION",
    "type": "Section header"
  },
  {
    "left": 109.0,
    "top": 115.0,
    "width": 430.0,
    "height": 62.0,
    "page_number": 2,
    "page_width": 612,
    "page_height": 792,
    "text": "The integration of generative artificial intelligence (AI) into software development is fundamentally transforming coding practices [ 55 ]. AI coding assistants, such as GitHub Copilot [ 34 ], provide functionalities like auto-completion, code generation, and test generation [ 76 ], which have the potential to revolutionize how developers work [ 73 ]. Amidst this surge of new capabilities driven by AI, an important question emerges: How do these generative AI coding assistants impact developers with visual impairments?",
    "type": "Text"
  },
  {
    "left": 109.0,
    "top": 184.0,
    "width": 430.0,
    "height": 76.0,
    "page_number": 2,
    "page_width": 612,
    "page_height": 792,
    "text": "The convergence of AI and accessibility in coding presents both tremendous opportunities and intricate challenges [ 55 , 67 ]. On one hand, AI has the potential to make coding more accessible for developers with visual impairments by reducing manual coding tasks and providing intelligent assistance [ 89 ]. On the other hand, if these AI coding assistants are not designed with accessibility in mind, they may inadvertently create new barriers or worsen existing ones [ 67 , 103 ]. This risk is especially high if the AI coding assistants depend heavily on visual cues or employ interaction methods incompatible with screen readers [ 61 , 86 , 109 ].",
    "type": "Text"
  },
  {
    "left": 109.0,
    "top": 265.0,
    "width": 430.0,
    "height": 200.0,
    "page_number": 2,
    "page_width": 612,
    "page_height": 792,
    "text": "In this context, it is important to understand that the relationship between accessibility and usability in AI assistants mirrors longstanding challenges in web accessibility [ 38 , 51 ], particularly for visually impaired users [ 14 , 43 ]. Similar to rich internet applications [ 9 , 72 ], AI assistants often introduce dynamic content and complex interactions that traditional accessibility approaches may not fully address [ 39 , 47 ]. For instance, Petrie and Kheir [ 74 ] found that existing accessibility guidelines fail to capture many of the usability problems encountered by visually impaired users when interacting with dynamic content. This gap could be especially exacerbated in AI coding assistants [ 2 , 65 , 71 ], where AI-generated suggestions, real-time code generation, and sophisticated user interfaces can present new hurdles [ 39 , 41 ]. Just as screen readers struggle with dynamic web content, AJAX updates, and automatic refreshes [ 20 ], developers who are visually impaired may experience similar difficulties when interacting with rapidly changing AI-generated code suggestions and interface elements [ 54 ]. Consequently, simply following basic accessibility rules might not be enough to make AI coding assistants truly easy to use. We might need to rethink how to make these assistants more accessible for everyone. The challenge is that we do not fully understand the difficulties and benefits that visually impaired developers experience when using AI coding assistants. Closing this knowledge gap is important\u2014not just for accessibility, but also for making AI-assisted coding tools more user-friendly and effective for all developers, including those with different levels of vision.",
    "type": "Text"
  },
  {
    "left": 109.0,
    "top": 471.0,
    "width": 429.0,
    "height": 21.0,
    "page_number": 2,
    "page_width": 612,
    "page_height": 792,
    "text": "Our study addresses this research gap by investigating what unique challenges and opportunities AI-assisted coding tools present for developers with visual impairments. Our research is driven by the following research question:",
    "type": "Text"
  },
  {
    "left": 125.0,
    "top": 503.0,
    "width": 414.0,
    "height": 23.0,
    "page_number": 2,
    "page_width": 612,
    "page_height": 792,
    "text": "\u2022 RQ1: What challenges do AI-assisted coding tools pose for developers who are visually impaired, and what opportunities do they offer to empower and enhance their work?",
    "type": "List item"
  },
  {
    "left": 109.0,
    "top": 535.0,
    "width": 429.0,
    "height": 90.0,
    "page_number": 2,
    "page_width": 612,
    "page_height": 792,
    "text": "To study this question, we use the Activity Theory framework [ 44 ], which helps analyze how tools influence human activity and identifies contradictions that occur when a tool\u2019s design does not fit well with users\u2019 workflows and needs [ 12 ]. We applied this framework to examine a qualitative study we conducted with 10 visually impaired developers of varying experience levels. These developers used an AI coding assistant, GitHub Copilot, to complete a coding task. During the study, we observed their real-time interactions with the AI assistant, noting both challenges and opportunities. After the task, we conducted interviews to gain deeper insights into their experiences and the difficulties they faced while using the AI coding assistant.",
    "type": "Text"
  },
  {
    "left": 109.0,
    "top": 631.0,
    "width": 429.0,
    "height": 34.0,
    "page_number": 2,
    "page_width": 612,
    "page_height": 792,
    "text": "Our findings reveal a complex landscape where AI coding assistants can both improve coding efficiency and introduce new accessibility challenges. Based on our findings, we outline a roadmap for the next generation of accessible AI Manuscript submitted to ACM",
    "type": "Text"
  },
  {
    "left": 497.0,
    "top": 78.0,
    "width": 4.0,
    "height": 9.0,
    "page_number": 3,
    "page_width": 612,
    "page_height": 792,
    "text": "3",
    "type": "Page header"
  },
  {
    "left": 72.0,
    "top": 67.0,
    "width": 186.0,
    "height": 20.0,
    "page_number": 3,
    "page_width": 612,
    "page_height": 792,
    "text": "The Impact of Generative AI Coding Assistants on Developers Who Are Visually Impaired",
    "type": "Text"
  },
  {
    "left": 73.0,
    "top": 98.0,
    "width": 429.0,
    "height": 22.0,
    "page_number": 3,
    "page_width": 612,
    "page_height": 792,
    "text": "coding assistants. By analyzing the experiences of visually impaired developers using AI-assisted coding tools, we derive key design insights that can reshape how accessibility is approached in AI-driven software development.",
    "type": "Text"
  },
  {
    "left": 82.0,
    "top": 125.0,
    "width": 159.0,
    "height": 9.0,
    "page_number": 3,
    "page_width": 612,
    "page_height": 792,
    "text": "The contributions of this paper are twofold:",
    "type": "Text"
  },
  {
    "left": 88.0,
    "top": 144.0,
    "width": 414.0,
    "height": 23.0,
    "page_number": 3,
    "page_width": 612,
    "page_height": 792,
    "text": "\u2022 We conduct a comprehensive analysis of the accessibility challenges and benefits of AI coding assistants, using real-world insights from developers who are visually impaired.",
    "type": "List item"
  },
  {
    "left": 88.0,
    "top": 171.0,
    "width": 414.0,
    "height": 24.0,
    "page_number": 3,
    "page_width": 612,
    "page_height": 792,
    "text": "\u2022 We propose a set of design recommendations to make AI coding assistants more accessible and inclusive for developers with visual impairments.",
    "type": "List item"
  },
  {
    "left": 72.0,
    "top": 212.0,
    "width": 85.0,
    "height": 8.0,
    "page_number": 3,
    "page_width": 612,
    "page_height": 792,
    "text": "2 RELATED WORK",
    "type": "Section header"
  },
  {
    "left": 73.0,
    "top": 231.0,
    "width": 285.0,
    "height": 7.0,
    "page_number": 3,
    "page_width": 612,
    "page_height": 792,
    "text": "2.1 Accessibility and Tools for Developers who are Visually Impaired",
    "type": "Section header"
  },
  {
    "left": 73.0,
    "top": 247.0,
    "width": 430.0,
    "height": 90.0,
    "page_number": 3,
    "page_width": 612,
    "page_height": 792,
    "text": "Accessibility in general has been a subject of ongoing research [ 17 , 35 , 36 , 85 ]. Several studies have shed light on the significant challenges developers who are visually impaired face with coding and the techniques these programmers employ to overcome these challenges. Mountapmbeme et al. [ 63 ] categorized these challenges into five main areas: code navigation, code comprehension, code editing, code debugging, and code skimming. Albusays and Ludi [ 5 ] found persistent challenges in code navigation, accessing diagrams, debugging, and UI layout. Their study highlighted a strong preference for text editors over IDEs due to accessibility issues, reduced complexity, and better compatibility with assistive technologies.",
    "type": "Text"
  },
  {
    "left": 73.0,
    "top": 343.0,
    "width": 430.0,
    "height": 200.0,
    "page_number": 3,
    "page_width": 612,
    "page_height": 792,
    "text": "Further studies by Mealin and Murphy-Hill [ 59 ] and Baker et al. [ 11 ] explored specific tools and techniques that developers who are visually impaired use. Mealin and Murphy-Hill found that many developers who are visually impaired rely on text editors rather than IDEs due to accessibility issues employing unique practices like \u201cout-of-context editing,\u201d where blocks of code are copied, edited separately, and pasted back. This preference for text editors has been corroborated by other researchers [ 6 , 63 ], who attribute it to specific challenges such as navigating line-by-line, understanding indentation, and managing nested code structures [ 56 , 99 ]. To address this issue, Baker et al. [ 11 ] created StructJumper, a plugin that generates a hierarchical tree structure of code for easier navigation. Debugging, presents another significant challenge for developers who are visually impaired, largely due to the reliance on visual interfaces in debugging tools, which screen readers struggle to interpret effectively [ 5 , 78 ]. These challenges have led the development of tools like Wicked Audio Debugger (WAD) [ 94 ] , a tool that provides audio descriptions of programs during execution; CodeTalk [ 78 ], a Visual Studio plugin that introduces \u201cTalkPoints\u201d for audio-based debugging; and CodeWalk, a tool by Potluri et al. [ 77 ], which facilitates accessible, remote, synchronous code review and refactoring activities by tethering collaborators\u2019 cursors with the host of a Live Share session. Additionally, Haque et al. [ 27 ] introduced Grid-Coding, a paradigm designed to improve the accessibility of coding environments by representing code in a structured 2D grid, allowing developers who are visually impaired to navigate and edit code more effectively.",
    "type": "Text"
  },
  {
    "left": 73.0,
    "top": 547.0,
    "width": 429.0,
    "height": 50.0,
    "page_number": 3,
    "page_width": 612,
    "page_height": 792,
    "text": "Conversational interfaces have also shown promise [ 15 ], Ludi et al. [ 57 ], found that speech-based cues generally provided the best performance for comprehension and navigation tasks. Phutane et al. [ 75 ] explored the use of voice commands to reduce cognitive load. Meanwhile, Stefik et al. [ 95 ] created Sodbeans, an IDE that relies on audio cues for debugging, while Smith et al. [ 90 ] developed a tool to allow developers to navigate the tree structure of files in Eclipse.",
    "type": "Text"
  },
  {
    "left": 72.0,
    "top": 603.0,
    "width": 429.0,
    "height": 50.0,
    "page_number": 3,
    "page_width": 612,
    "page_height": 792,
    "text": "While previous research has significantly advanced accessibility for developers who are visually impaired, these findings may not fully apply to the new landscape shaped by generative AI-assisted coding tools such as GitHub Copilot. The introduction of these tools brings new challenges and opportunities in accessible programming, an area that remains largely unexamined. The majority of current studies were conducted before the emergence of generative",
    "type": "Text"
  },
  {
    "left": 414.0,
    "top": 658.0,
    "width": 86.0,
    "height": 7.0,
    "page_number": 3,
    "page_width": 612,
    "page_height": 792,
    "text": "Manuscript submitted to ACM",
    "type": "Page footer"
  },
  {
    "left": 109.0,
    "top": 70.0,
    "width": 6.0,
    "height": 8.0,
    "page_number": 4,
    "page_width": 612,
    "page_height": 792,
    "text": "4",
    "type": "Page header"
  },
  {
    "left": 463.0,
    "top": 70.0,
    "width": 76.0,
    "height": 8.0,
    "page_number": 4,
    "page_width": 612,
    "page_height": 792,
    "text": "Flores-Saviaga, et al.",
    "type": "Page header"
  },
  {
    "left": 109.0,
    "top": 98.0,
    "width": 430.0,
    "height": 22.0,
    "page_number": 4,
    "page_width": 612,
    "page_height": 792,
    "text": "AI in coding environments, resulting in a critical knowledge gap regarding the impact and potential of these advanced tools for developers who are visually impaired.",
    "type": "Text"
  },
  {
    "left": 109.0,
    "top": 142.0,
    "width": 157.0,
    "height": 7.0,
    "page_number": 4,
    "page_width": 612,
    "page_height": 792,
    "text": "2.2 AI-assisted Coding Environments",
    "type": "Section header"
  },
  {
    "left": 109.0,
    "top": 158.0,
    "width": 430.0,
    "height": 132.0,
    "page_number": 4,
    "page_width": 612,
    "page_height": 792,
    "text": "The integration of AI into software development tools has significantly impacted coding practices, with AI-assisted coding assistants like GitHub Copilot showing promise in improving developer productivity. Ziegler et al. [ 108 ] found that Copilot increases users\u2019 feelings of productivity, with almost a third of its proposed code completions being accepted. In a controlled experiment, Peng et al.[ 73 ] demonstrated that software developers using Github Copilot were able to complete programming tasks significantly faster than those without such assistance. However, Vaithilingam et al. [ 100 ] noted that while most participants preferred using Copilot in daily programming tasks, they often faced difficulties in understanding, editing, and debugging code snippets generated by Copilot, which significantly hindered their task-solving effectiveness. This was confirmed by Dakhel et al [ 26 ], who noted that the effectiveness of tools like Github Copilot depends on the developer\u2019s level of expertise, as less experienced developers often lack the necessary skills to effectively evaluate AI-generated code suggestions.",
    "type": "Text"
  },
  {
    "left": 109.0,
    "top": 295.0,
    "width": 430.0,
    "height": 35.0,
    "page_number": 4,
    "page_width": 612,
    "page_height": 792,
    "text": "A recent survey of developers by Liang et al. [ 55 ] revealed that the primary motivations for using AI programming assistants include reducing keystrokes, finishing programming tasks quickly, and recalling syntax. Developers reported that a median of 30.5% of their code was written with help from tools like Copilot.",
    "type": "Text"
  },
  {
    "left": 109.0,
    "top": 336.0,
    "width": 430.0,
    "height": 63.0,
    "page_number": 4,
    "page_width": 612,
    "page_height": 792,
    "text": "Studies like those by Barke et al.[ 66 ] and Wu et al. [ 58 ] provide insight into the varying modes of interaction with AI coding assistants. Barke et al. [ 66 ] identified \u201cacceleration mode\u201d and \u201cexploration mode\u201d as two broad categories of Copilot use, while Wu et al. [ 58 ] compared human-human pair programming with human-AI pair programming, highlighting differences in collaboration dynamics. However, there is still a significant gap in understanding how these AI tools impact developers with accessibility needs.",
    "type": "Text"
  },
  {
    "left": 109.0,
    "top": 421.0,
    "width": 85.0,
    "height": 7.0,
    "page_number": 4,
    "page_width": 612,
    "page_height": 792,
    "text": "2.3 Activity Theory",
    "type": "Section header"
  },
  {
    "left": 111.0,
    "top": 450.0,
    "width": 231.0,
    "height": 127.0,
    "page_number": 4,
    "page_width": 612,
    "page_height": 792,
    "text": "Tool ( Github Copilot ) Subject (Software developer who is visually impaired) Object ( Coding task )",
    "type": "Picture"
  },
  {
    "left": 109.0,
    "top": 594.0,
    "width": 236.0,
    "height": 26.0,
    "page_number": 4,
    "page_width": 612,
    "page_height": 792,
    "text": "Fig. 2. Diagram illustrating the relationship between software developers who are visually impaired (subject), coding tasks (object), and GitHub Copilot (mediating tool) within the Activity Theory framework.",
    "type": "Caption"
  },
  {
    "left": 355.0,
    "top": 436.0,
    "width": 185.0,
    "height": 203.0,
    "page_number": 4,
    "page_width": 612,
    "page_height": 792,
    "text": "Activity Theory is a type of \u201cconceptual frame- work\u201d [ 80 , 82 , 88 , 91 ]. A conceptual framework is an analytical tool or structure used to organize and guide research, projects, or problem-solving efforts [ 40 , 60 ]. The foundational concept of Activity The- ory is the \u201cactivity\u201d, a series of goal directed actions [ 53 ] that aim to achieve specific objectives [ 52 ]. These actions are mediated by artifacts, the instru- ments through which individuals interact with their objectives. Actions themselves are performed via routinized operations, in which individuals are not conscious of or focused on these operations. This process is illustrated in Figure 2 . For example, devel- opers who are visually impaired (the subjects) may have specific goals (objects) related to completing",
    "type": "Text"
  },
  {
    "left": 109.0,
    "top": 643.0,
    "width": 354.0,
    "height": 22.0,
    "page_number": 4,
    "page_width": 612,
    "page_height": 792,
    "text": "programming tasks. In this context, an AI programming tool acts as the mediating artifact (tool). Manuscript submitted to ACM",
    "type": "Text"
  },
  {
    "left": 497.0,
    "top": 78.0,
    "width": 4.0,
    "height": 8.0,
    "page_number": 5,
    "page_width": 612,
    "page_height": 792,
    "text": "5",
    "type": "Page header"
  },
  {
    "left": 72.0,
    "top": 67.0,
    "width": 186.0,
    "height": 20.0,
    "page_number": 5,
    "page_width": 612,
    "page_height": 792,
    "text": "The Impact of Generative AI Coding Assistants on Developers Who Are Visually Impaired",
    "type": "Text"
  },
  {
    "left": 73.0,
    "top": 98.0,
    "width": 428.0,
    "height": 131.0,
    "page_number": 5,
    "page_width": 612,
    "page_height": 792,
    "text": "B\u00f8dker proposed Activity Theory as a foundational framework for HCI [ 18 ], emphasizing its potential to guide the design of interactive systems by focusing on the dynamic interplay between users, their goals, and the tools users employ (interactive systems) [ 19 ]. B\u00f8dker emphasized that tools should evolve over time to meet users\u2019 needs and adapt to the activities they mediate[ 18 ], highlighting the importance of designing systems that adjust to changing workflows and contexts to remain effective[ 19 ]. Within B\u00f8dker\u2019s definition of Activity Theory for HCI [ 18 ], contradictions are discrepancies or tensions that arise between the tools, the goals, and the users, that must be addressed [ 28 ]. These contradictions are not obstacles but drivers of change, pointing out areas where tools or processes need to evolve to better meet user needs [ 29 ]. Within this space, Activity Theory also introduces the concept of misalignments , which are localized issues or practical mismatches. Unlike contradictions , misalignments hinder usability and effectiveness for end-users but may not necessitate systemic changes.",
    "type": "Text"
  },
  {
    "left": 73.0,
    "top": 233.0,
    "width": 429.0,
    "height": 160.0,
    "page_number": 5,
    "page_width": 612,
    "page_height": 792,
    "text": "In this paper, we use Activity Theory as a framework to examine the design of AI-assisted coding tools for developers who are visually impaired. We chose this approach because Activity Theory has been widely used for decades to study tools and technologies designed for diverse groups, including individuals with disabilities [ 12 , 18 , 28 , 44 , 45 , 81 , 97 ]. For example, Baldwin et al. [ 12 ] applied Activity Theory to investigate the design of tactile devices and enhanced auditory tools, examining whether these technologies align with the unique workflows of users who have no or low-vision. Similarly, Szymczak [ 97 ] applied Activity Theory to analyze how audio-haptic technologies mediated interactions and supported the goals of individuals who are visually impaired, focusing on how these technologies could assist users in interacting with 2D representations, such as maps and drawings. Tlili et al. [ 98 ], also applied Activity Theory to review the use of game-based learning for learners with disabilities and identify inconsistencies in stakeholder involvement, variability in the use of educational technology, and difficulties in standardizing performance measures. Robins [ 81 ] applied Activity Theory to analyze and design accessibility in video games, focusing on the interaction between visually impaired players, game goals, and mediating tools like audio-haptic technologies and game mechanics.",
    "type": "Text"
  },
  {
    "left": 73.0,
    "top": 413.0,
    "width": 429.0,
    "height": 102.0,
    "page_number": 5,
    "page_width": 612,
    "page_height": 792,
    "text": "P# Gender Age Exp.(yrs) Vision Status AI-Coding Tool Experience Coding Proficiency Pref. Lang. For Study Task Completed P1 Male 32 8 No vision GitHub Copilot C#, JavaScript, Python, Ruby Python Yes P2 Male 34 12 Low vision GitHub Copilot PHP, C#, JavaScript C# Yes P3 Male 38 9 Low vision CodeWhisperer, Codellama, ChatGPT C++, Python Python Yes P4 Male 43 22 Low vision ChatGPT JavaScript, TypeScript, C# C# Yes P5 Male 26 6 No vision GitHub Copilot, ChatGPT Python Python Yes P6 Male 36 17 Low vision GitHub Copilot PHP, Ruby, Swift, Go, Python, JavaScript, Kotlin Python Yes P7 Male 58 23 No vision GitHub Copilot Python, SQL, PowerShell Python Yes P8 Male 54 32 No vision ChatGPT C, R, Ruby, TypeScript, Swift, Python, Kotlin Python Yes P9 Male 42 4 No vision ChatGPT JavaScript, PHP, Python, HTML, CSS Python Yes P10 Male 24 2 No vision Claude, ChatGPT, Gemini C#, HTML, PHP C# Yes",
    "type": "Table"
  },
  {
    "left": 89.0,
    "top": 517.0,
    "width": 393.0,
    "height": 7.0,
    "page_number": 5,
    "page_width": 612,
    "page_height": 792,
    "text": "Table 1. Participant Demographics, Vision Status, Experience with AI Coding Assistants, and Programming Background.",
    "type": "Caption"
  },
  {
    "left": 73.0,
    "top": 562.0,
    "width": 428.0,
    "height": 90.0,
    "page_number": 5,
    "page_width": 612,
    "page_height": 792,
    "text": "Building on this foundation, our paper applies Activity Theory to examine how AI-assisted coding tools, particularly GitHub Copilot, mediate and influence the tasks of developers who are visually impaired. Activity Theory provides a particularly useful analysis framework since the introduction of AI coding assistants may operationalize some actions that have not yet become routine for developers. Additionally, we use Activity Theory to guide design recommendations aimed at improving these tools for this population. To achieve this, we analyze both contradictions \u2014systemic tensions within the activity system\u2014and misalignments \u2014localized issues that disrupt usability. By addressing these challenges, we ensure AI tools meet developers\u2019 needs.",
    "type": "Text"
  },
  {
    "left": 414.0,
    "top": 658.0,
    "width": 86.0,
    "height": 7.0,
    "page_number": 5,
    "page_width": 612,
    "page_height": 792,
    "text": "Manuscript submitted to ACM",
    "type": "Page footer"
  },
  {
    "left": 109.0,
    "top": 71.0,
    "width": 6.0,
    "height": 8.0,
    "page_number": 6,
    "page_width": 612,
    "page_height": 792,
    "text": "6",
    "type": "Page header"
  },
  {
    "left": 463.0,
    "top": 70.0,
    "width": 75.0,
    "height": 8.0,
    "page_number": 6,
    "page_width": 612,
    "page_height": 792,
    "text": "Flores-Saviaga, et al.",
    "type": "Page header"
  },
  {
    "left": 108.0,
    "top": 93.0,
    "width": 431.0,
    "height": 338.0,
    "page_number": 6,
    "page_width": 612,
    "page_height": 792,
    "text": "a.Inline chat b. Ghost text suggestions c. Chat Window (floating element) d. Chat window (embedded pane)",
    "type": "Picture"
  },
  {
    "left": 110.0,
    "top": 458.0,
    "width": 428.0,
    "height": 37.0,
    "page_number": 6,
    "page_width": 612,
    "page_height": 792,
    "text": "Fig. 3. GitHub Copilot interaction interfaces. (a) Inline chat window for quick command input and AI engagement. (b) Ghost text suggestions dynamically generated as the user types. (c) Floating chat window for temporary interactions, ideal for quick-access queries. (d) Embedded pane chat window for ongoing, more extensive conversations with AI, allowing for sustained reference and deeper coding assistance.",
    "type": "Caption"
  },
  {
    "left": 109.0,
    "top": 518.0,
    "width": 50.0,
    "height": 7.0,
    "page_number": 6,
    "page_width": 612,
    "page_height": 792,
    "text": "2.4 Copilot",
    "type": "Section header"
  },
  {
    "left": 109.0,
    "top": 534.0,
    "width": 429.0,
    "height": 36.0,
    "page_number": 6,
    "page_width": 612,
    "page_height": 792,
    "text": "The GitHub Copilot interface provides multiple ways for developers to interact with its AI-driven coding assistant. One primary method is through its inline chat (Fig. 3 a), where users can type commands or questions directly within the code editor. This allows for seamless, quick interactions without disrupting the coding workflow.",
    "type": "Text"
  },
  {
    "left": 109.0,
    "top": 576.0,
    "width": 429.0,
    "height": 79.0,
    "page_number": 6,
    "page_width": 612,
    "page_height": 792,
    "text": "Additionally, developers can engage with Copilot using the chat window , which can appear either as a floating element (Fig. 3 c) or as an embedded pane within the interface (Fig. 3 d). An embedded pane refers to a UI component that is fixed within the main window, allowing for continuous visibility and interaction without obstructing other elements on the screen. The floating element is useful for quick, temporary queries, while the embedded pane is better suited for extended interactions where users may need to frequently reference past exchanges. This flexibility enables developers to choose an interaction style that best fits their workflow and preferences.",
    "type": "Text"
  },
  {
    "left": 109.0,
    "top": 658.0,
    "width": 86.0,
    "height": 7.0,
    "page_number": 6,
    "page_width": 612,
    "page_height": 792,
    "text": "Manuscript submitted to ACM",
    "type": "Text"
  },
  {
    "left": 497.0,
    "top": 78.0,
    "width": 4.0,
    "height": 9.0,
    "page_number": 7,
    "page_width": 612,
    "page_height": 792,
    "text": "7",
    "type": "Page header"
  },
  {
    "left": 72.0,
    "top": 67.0,
    "width": 186.0,
    "height": 20.0,
    "page_number": 7,
    "page_width": 612,
    "page_height": 792,
    "text": "The Impact of Generative AI Coding Assistants on Developers Who Are Visually Impaired",
    "type": "Text"
  },
  {
    "left": 73.0,
    "top": 98.0,
    "width": 428.0,
    "height": 90.0,
    "page_number": 7,
    "page_width": 612,
    "page_height": 792,
    "text": "Another key interaction method is through ghost text suggestions (Fig. 3 b). As the developer types, Copilot continuously analyzes the context and generates relevant code suggestions in real-time. These suggestions appear as semi-transparent text within the editor, allowing developers to seamlessly integrate them into their code. Developers can choose to accept, modify, or ignore these suggestions based on their needs. Beyond real-time suggestions, developers can also request code completions by writing natural language comments that describe the desired functionality. Copilot then processes these descriptions and generates corresponding code snippets, helping developers implement features more efficiently.",
    "type": "Text"
  },
  {
    "left": 73.0,
    "top": 193.0,
    "width": 428.0,
    "height": 50.0,
    "page_number": 7,
    "page_width": 612,
    "page_height": 792,
    "text": "It is important to note that GitHub Copilot is not a standalone code editor but an extension designed to work within Visual Studio Code. The chat windows, including both the floating and embedded pane versions, are features introduced by the GitHub Copilot extension and are not part of Visual Studio Code by default. These chat interfaces allow users to interact directly with AI-generated coding suggestions within their coding environment.",
    "type": "Text"
  },
  {
    "left": 73.0,
    "top": 248.0,
    "width": 429.0,
    "height": 50.0,
    "page_number": 7,
    "page_width": 612,
    "page_height": 792,
    "text": "GitHub Copilot was selected as the primary AI coding assistant for this study because, at the time of research, it was the most widely used tool of its kind [ 33 , 92 ]. We chose Visual Studio Code as the development environment due to its popularity and accessibility, as well as its seamless integration with GitHub Copilot [ 93 , 101 ]. This setup enabled us to explore how these tools influence the coding experience of developers who are visually impaired.",
    "type": "Text"
  },
  {
    "left": 73.0,
    "top": 318.0,
    "width": 76.0,
    "height": 7.0,
    "page_number": 7,
    "page_width": 612,
    "page_height": 792,
    "text": "2.5 Research Gap",
    "type": "Section header"
  },
  {
    "left": 73.0,
    "top": 334.0,
    "width": 429.0,
    "height": 64.0,
    "page_number": 7,
    "page_width": 612,
    "page_height": 792,
    "text": "Despite progress in accessibility for developers who are visually impaired [ 13 , 23 , 65 ], generative AI coding assistants like GitHub Copilot introduce new challenges and opportunities that remain under-explored. Most existing research focuses on traditional coding tools [ 1 , 49 ], overlooking complexities unique to AI-assisted coding. Our study examines these accessibility issues to ensure AI assistants like GitHub Copilot are inclusive and support equal access for visually impaired developers.",
    "type": "Text"
  },
  {
    "left": 72.0,
    "top": 418.0,
    "width": 58.0,
    "height": 7.0,
    "page_number": 7,
    "page_width": 612,
    "page_height": 792,
    "text": "3 METHODS",
    "type": "Section header"
  },
  {
    "left": 73.0,
    "top": 434.0,
    "width": 428.0,
    "height": 91.0,
    "page_number": 7,
    "page_width": 612,
    "page_height": 792,
    "text": "To study the relationship between AI coding assistants and accessibility, we conducted a study with developers who are visually impaired. Our goal was to understand their experiences, challenges, and strategies when using an AI coding assistant, specifically GitHub Copilot. Using Activity Theory as our framework, we analyzed how Copilot (tool) mediates the interaction between visually impaired developers (participants) and their coding tasks (object). Our analysis highlights the contradictions and misalignments that occur when Copilot\u2019s design falls short of meeting the unique needs of developers who are visually impaired, while also uncovering new opportunities that emerge in this environment.",
    "type": "Text"
  },
  {
    "left": 72.0,
    "top": 545.0,
    "width": 119.0,
    "height": 7.0,
    "page_number": 7,
    "page_width": 612,
    "page_height": 792,
    "text": "3.1 Participant Recruitment",
    "type": "Section header"
  },
  {
    "left": 73.0,
    "top": 561.0,
    "width": 428.0,
    "height": 91.0,
    "page_number": 7,
    "page_width": 612,
    "page_height": 792,
    "text": "We recruited 10 software developers who were visually impaired, including 4 with low vision and 6 with no vision, with experience ranging from 2 to 32 years in the field (see Table 1 ). Participants were sourced through professional networks, accessibility-focused online forums, and organizations supporting professionals in tech with visual impairments. To participate, developers needed some familiarity with AI coding assistants, though extensive experience with Copilot was not required. All participants identified as male. Given the specialized nature of developers who are visually impaired, our recruitment pool was naturally limited. However, our sample size aligns with prior HCI studies on underrepresented populations [ 25 , 30 , 69 , 79 , 83 ]. Despite these constraints, our study provides valuable insights into the accessibility",
    "type": "Text"
  },
  {
    "left": 414.0,
    "top": 658.0,
    "width": 86.0,
    "height": 7.0,
    "page_number": 7,
    "page_width": 612,
    "page_height": 792,
    "text": "Manuscript submitted to ACM",
    "type": "Page footer"
  },
  {
    "left": 109.0,
    "top": 71.0,
    "width": 5.0,
    "height": 8.0,
    "page_number": 8,
    "page_width": 612,
    "page_height": 792,
    "text": "8",
    "type": "Page header"
  },
  {
    "left": 463.0,
    "top": 70.0,
    "width": 76.0,
    "height": 8.0,
    "page_number": 8,
    "page_width": 612,
    "page_height": 792,
    "text": "Flores-Saviaga, et al.",
    "type": "Page header"
  },
  {
    "left": 109.0,
    "top": 98.0,
    "width": 430.0,
    "height": 22.0,
    "page_number": 8,
    "page_width": 612,
    "page_height": 792,
    "text": "challenges and opportunities for this underrepresented group. Each participant received $50 USD (or its equivalent in local currency) as compensation for their time.",
    "type": "Text"
  },
  {
    "left": 109.0,
    "top": 138.0,
    "width": 69.0,
    "height": 7.0,
    "page_number": 8,
    "page_width": 612,
    "page_height": 792,
    "text": "3.2 Study setup",
    "type": "Section header"
  },
  {
    "left": 109.0,
    "top": 154.0,
    "width": 431.0,
    "height": 23.0,
    "page_number": 8,
    "page_width": 612,
    "page_height": 792,
    "text": "We conducted our study remotely, ensuring that participants could use their preferred accessible setup. Each session lasted approximately 90 minutes and followed four sequential phases:",
    "type": "Text"
  },
  {
    "left": 119.0,
    "top": 186.0,
    "width": 420.0,
    "height": 23.0,
    "page_number": 8,
    "page_width": 612,
    "page_height": 792,
    "text": "(1) Participant Background and Copilot Experience: We asked participants to describe their professional and technical backgrounds and share their prior experience with AI coding assistants like GitHub Copilot.",
    "type": "List item"
  },
  {
    "left": 120.0,
    "top": 213.0,
    "width": 419.0,
    "height": 50.0,
    "page_number": 8,
    "page_width": 612,
    "page_height": 792,
    "text": "(2) Training Session: We provided participants with a training session that introduced GitHub Copilot and its key features. The session also covered how Copilot integrates with accessible development environments and assistive technologies participants were already using. This ensured that all participants had a solid understanding of how to interact with Copilot before starting the coding tasks.",
    "type": "List item"
  },
  {
    "left": 121.0,
    "top": 268.0,
    "width": 419.0,
    "height": 23.0,
    "page_number": 8,
    "page_width": 612,
    "page_height": 792,
    "text": "(3) Hands-on Coding and Debugging Tasks: We instructed participants to complete a coding task followed by a debugging task using GitHub Copilot in Visual Studio Code.",
    "type": "List item"
  },
  {
    "left": 135.0,
    "top": 295.0,
    "width": 405.0,
    "height": 64.0,
    "page_number": 8,
    "page_width": 612,
    "page_height": 792,
    "text": "\u2022 Programming Task: Following prior work [ 46 ], we asked participants to write a program that calculates the number of days until the user\u2019s next birthday. The program required a birthday string input in either DDMMYY or DDMMYYYY format and a class implementation to handle date calculations. We also asked participants to write unit tests for their class. Throughout the task, we encouraged them to use the \"think-aloud\" protocol, verbalizing their thought process while interacting with Copilot.",
    "type": "List item"
  },
  {
    "left": 142.0,
    "top": 364.0,
    "width": 108.0,
    "height": 9.0,
    "page_number": 8,
    "page_width": 612,
    "page_height": 792,
    "text": "We selected this task because:",
    "type": "Text"
  },
  {
    "left": 142.0,
    "top": 377.0,
    "width": 398.0,
    "height": 24.0,
    "page_number": 8,
    "page_width": 612,
    "page_height": 792,
    "text": "\u2013 It incorporates common programming concepts such as string manipulation, date calculations, and object- oriented principles, making it relevant to participants\u2019 typical coding workflows.",
    "type": "List item"
  },
  {
    "left": 141.0,
    "top": 405.0,
    "width": 398.0,
    "height": 23.0,
    "page_number": 8,
    "page_width": 612,
    "page_height": 792,
    "text": "\u2013 It does not require specialized knowledge of specific programming frameworks, simplifying participant recruitment.",
    "type": "List item"
  },
  {
    "left": 135.0,
    "top": 432.0,
    "width": 405.0,
    "height": 23.0,
    "page_number": 8,
    "page_width": 612,
    "page_height": 792,
    "text": "\u2022 Debugging Task: We then asked participants to engage in a debugging session, where they identified and fixed errors in the code generated by Copilot. During this session, we prompted them to discuss:",
    "type": "List item"
  },
  {
    "left": 142.0,
    "top": 460.0,
    "width": 191.0,
    "height": 8.0,
    "page_number": 8,
    "page_width": 612,
    "page_height": 792,
    "text": "\u2013 Their usual approach to evaluating code accuracy.",
    "type": "List item"
  },
  {
    "left": 142.0,
    "top": 474.0,
    "width": 203.0,
    "height": 9.0,
    "page_number": 8,
    "page_width": 612,
    "page_height": 792,
    "text": "\u2013 The methods they used to handle encountered issues.",
    "type": "List item"
  },
  {
    "left": 141.0,
    "top": 487.0,
    "width": 256.0,
    "height": 9.0,
    "page_number": 8,
    "page_width": 612,
    "page_height": 792,
    "text": "\u2013 Whether Copilot simplified or complicated their debugging process.",
    "type": "List item"
  },
  {
    "left": 120.0,
    "top": 501.0,
    "width": 420.0,
    "height": 78.0,
    "page_number": 8,
    "page_width": 612,
    "page_height": 792,
    "text": "(4) Post-Interview: After completing the programming and debugging tasks, we conducted a semi-structured interview with each participant. We asked them to explain their approach to organizing their code and describe any adjustments they made based on Copilot\u2019s suggestions. They also shared the challenges they encountered and the solutions they implemented. Additionally, we encouraged them to reflect on how Copilot influenced the complexity of their tasks, providing examples of when it was particularly helpful or challenging. Our Appendix contains further details on the post-study interview questions.",
    "type": "List item"
  },
  {
    "left": 120.0,
    "top": 588.0,
    "width": 218.0,
    "height": 9.0,
    "page_number": 8,
    "page_width": 612,
    "page_height": 792,
    "text": "A diagram illustrating our study setup is shown in Figure 1 .",
    "type": "Text"
  },
  {
    "left": 108.0,
    "top": 615.0,
    "width": 138.0,
    "height": 7.0,
    "page_number": 8,
    "page_width": 612,
    "page_height": 792,
    "text": "3.3 Data Collection and Analysis",
    "type": "Section header"
  },
  {
    "left": 109.0,
    "top": 631.0,
    "width": 430.0,
    "height": 34.0,
    "page_number": 8,
    "page_width": 612,
    "page_height": 792,
    "text": "We recorded and transcribed all interviews, capturing both verbal responses and relevant audio cues from participants\u2019 screen readers and other assistive technologies. We analyzed the data using thematic coding, focusing on significant Manuscript submitted to ACM",
    "type": "Text"
  },
  {
    "left": 497.0,
    "top": 78.0,
    "width": 4.0,
    "height": 9.0,
    "page_number": 9,
    "page_width": 612,
    "page_height": 792,
    "text": "9",
    "type": "Page header"
  },
  {
    "left": 72.0,
    "top": 67.0,
    "width": 187.0,
    "height": 20.0,
    "page_number": 9,
    "page_width": 612,
    "page_height": 792,
    "text": "The Impact of Generative AI Coding Assistants on Developers Who Are Visually Impaired",
    "type": "Text"
  },
  {
    "left": 73.0,
    "top": 98.0,
    "width": 430.0,
    "height": 91.0,
    "page_number": 9,
    "page_width": 612,
    "page_height": 792,
    "text": "events that participants experienced while using GitHub Copilot. Two of us independently coded the transcripts, identifying emerging themes and patterns. We paid special attention to pivotal moments that either enhanced or hindered participants\u2019 coding processes. These critical incidents provided concrete examples of how Copilot mediated accessibility, revealing specific ways in which the tool aligned with or diverged from the non-visual coding strategies used by developers who are visually impaired. To deepen our analysis, we integrated Activity Theory , which allowed us to examine the opportunities and contradictions that visually impaired developers encountered when interacting with an AI coding assistant. In particular, Activity Theory helped us explore within our themes:",
    "type": "Text"
  },
  {
    "left": 83.0,
    "top": 198.0,
    "width": 419.0,
    "height": 50.0,
    "page_number": 9,
    "page_width": 612,
    "page_height": 792,
    "text": "(1) Activity-Centric Lens: how developers who are visually impaired ( subjects ) used GitHub Copilot ( tool ) to complete their coding tasks ( object ). By applying Activity Theory, we mapped the observed dynamics within the activity system, identifying key interactions and tensions among its components. This framework helped us understand how Copilot influenced developers\u2019 workflows and where misalignments or challenges emerged.",
    "type": "List item"
  },
  {
    "left": 83.0,
    "top": 253.0,
    "width": 420.0,
    "height": 64.0,
    "page_number": 9,
    "page_width": 612,
    "page_height": 792,
    "text": "(2) Systemic Contradictions: challenges that developers who are visually impaired faced, particularly those arising from systemic contradictions . For example, some participants struggled with context switching imposed by the AI, while others had difficulty navigating Copilot\u2019s dynamic behaviors, which disrupted the sequential workflows that are critical for developers who are visually impaired. These disruptions required additional navigation adaptations to maintain productivity.",
    "type": "List item"
  },
  {
    "left": 83.0,
    "top": 320.0,
    "width": 420.0,
    "height": 37.0,
    "page_number": 9,
    "page_width": 612,
    "page_height": 792,
    "text": "(3) Adaptive Solutions: possible adaptive solutions to the challenges we identified. By applying the Activity Theory framework, we gained insights into how AI assistants could be better aligned with the specific workflows of developers who are visually impaired, ultimately fostering more inclusive and efficient coding environments.",
    "type": "List item"
  },
  {
    "left": 73.0,
    "top": 366.0,
    "width": 430.0,
    "height": 50.0,
    "page_number": 9,
    "page_width": 612,
    "page_height": 792,
    "text": "By integrating Activity Theory into our thematic analysis, we gained a deeper understanding of how developers who are visually impaired engage with AI coding assistants. This approach allowed us to identify key accessibility themes and design elements of Copilot that either supported or hindered participants\u2019 work processes. Our findings contribute to the broader goal of rethinking accessibility paradigms in AI-assisted coding environments.",
    "type": "Text"
  },
  {
    "left": 73.0,
    "top": 435.0,
    "width": 56.0,
    "height": 7.0,
    "page_number": 9,
    "page_width": 612,
    "page_height": 792,
    "text": "4 FINDINGS",
    "type": "Section header"
  },
  {
    "left": 73.0,
    "top": 451.0,
    "width": 430.0,
    "height": 50.0,
    "page_number": 9,
    "page_width": 612,
    "page_height": 792,
    "text": "Through our interviews and observations, we identified key themes that highlight the complex relationship between AI coding assistants, accessibility needs, and coding practices. These themes address our research question by revealing the challenges and opportunities that developers who are visually impaired encounter when using AI-assisted coding tools like GitHub Copilot.",
    "type": "Text"
  },
  {
    "left": 73.0,
    "top": 506.0,
    "width": 430.0,
    "height": 91.0,
    "page_number": 9,
    "page_width": 612,
    "page_height": 792,
    "text": "In this section, we present these themes. For each theme, we include illustrative quotes and describe critical incidents from our interviews. These incidents provide insight into the lived experiences of our participants, offering concrete examples of how generative AI coding assistants can both empower and hinder developers who are visually impaired. We frame our findings within the Activity Theory framework to contextualize these challenges as systemic misalignments between users, their tools, and the coding environments they work in. This approach allows us to examine how AI coding assistants mediate the development process and where breakdowns occur, helping us identify opportunities for more accessible and inclusive AI coding assistants.",
    "type": "Text"
  },
  {
    "left": 73.0,
    "top": 615.0,
    "width": 426.0,
    "height": 8.0,
    "page_number": 9,
    "page_width": 612,
    "page_height": 792,
    "text": "4.1 RQ1: Challenges and Opportunities of AI Coding Assistants for Developers Who Are Visually Impaired",
    "type": "Section header"
  },
  {
    "left": 73.0,
    "top": 630.0,
    "width": 428.0,
    "height": 25.0,
    "page_number": 9,
    "page_width": 612,
    "page_height": 792,
    "text": "4.1.1 AI and Control . Our interviews revealed that AI coding assistants contributed to a dynamic sense of control among developers who are visually impaired. This enhanced control manifested in several positive ways. Participants",
    "type": "Text"
  },
  {
    "left": 414.0,
    "top": 658.0,
    "width": 86.0,
    "height": 7.0,
    "page_number": 9,
    "page_width": 612,
    "page_height": 792,
    "text": "Manuscript submitted to ACM",
    "type": "Page footer"
  },
  {
    "left": 109.0,
    "top": 70.0,
    "width": 10.0,
    "height": 8.0,
    "page_number": 10,
    "page_width": 612,
    "page_height": 792,
    "text": "10",
    "type": "Page header"
  },
  {
    "left": 463.0,
    "top": 70.0,
    "width": 77.0,
    "height": 8.0,
    "page_number": 10,
    "page_width": 612,
    "page_height": 792,
    "text": "Flores-Saviaga, et al.",
    "type": "Page header"
  },
  {
    "left": 109.0,
    "top": 97.0,
    "width": 432.0,
    "height": 91.0,
    "page_number": 10,
    "page_width": 612,
    "page_height": 792,
    "text": "described experiencing a shift toward strategic control over the coding process. Rather than manually performing every task, they found that AI assistant allowed them to delegate routine or less engaging tasks, enabling them to focus on high-level decision-making and overall code structure. This ability to offload work gave them greater control in shaping their development process while maintaining oversight of their projects. For instance, P7 highlighted how Copilot eased their workload and gave them more control over their coding process by handling tasks they found tedious, such as generating docstrings\u2014special multiline comments in programming that explain the functionality of a function, class, or module:",
    "type": "Text"
  },
  {
    "left": 135.0,
    "top": 200.0,
    "width": 381.0,
    "height": 49.0,
    "page_number": 10,
    "page_width": 612,
    "page_height": 792,
    "text": "\u201cOverall, my experience with Copilot is positive, especially because it helps me with tasks I don\u2019t enjoy. I will write the majority of my own code [...], but where it [Copilot] can help me, I\u2019ll definitely let it [Copilot] do it. I love having it generate docstrings for me. That\u2019s cool, because frankly, I don\u2019t like writing documentation. I\u2019d rather code and let it do the heavy lifting for me...\u201d - P7, Developer with no vision.",
    "type": "Text"
  },
  {
    "left": 109.0,
    "top": 260.0,
    "width": 431.0,
    "height": 50.0,
    "page_number": 10,
    "page_width": 612,
    "page_height": 792,
    "text": "This experience demonstrates how AI empowers developers by taking over tedious tasks they prefer to avoid. By automating routine work, AI enables developers to maintain greater control over their workflow and focus on more complex and engaging coding challenges. Similarly, participant P1, who had prior experience with AI coding assistants, compared coding with AI to piloting an aircraft, emphasizing how these assistants increase their sense of control:",
    "type": "Text"
  },
  {
    "left": 134.0,
    "top": 322.0,
    "width": 381.0,
    "height": 64.0,
    "page_number": 10,
    "page_width": 612,
    "page_height": 792,
    "text": "\u201cI sort of compare it [Copilot] to pair programming almost, where [...] I\u2019m sort of driving, but the other person is doing all the sort of drudgery work. And what I\u2019m really mostly doing now is almost like what a pilot does when they\u2019re flying a plane. They\u2019re [...] not flying the plane physically for most of it. Most of it, the plane\u2019s flying itself, but the pilot does have to keep an eye on. Are we still going in the right direction? What\u2019s that big thing coming towards us really fast? Should we avoid that?\u201d - P1, Developer with no vision.",
    "type": "Text"
  },
  {
    "left": 109.0,
    "top": 397.0,
    "width": 431.0,
    "height": 50.0,
    "page_number": 10,
    "page_width": 612,
    "page_height": 792,
    "text": "From the perspective of Activity Theory, these findings illustrate the transformative role of AI tools as mediators in the coding process. In this context, Copilot functions as an intermediary that actively shapes a developer\u2019s control over their work, allowing developers to reallocate their focus toward higher-level strategic decisions, as demonstrated by P7 and P1.",
    "type": "Text"
  },
  {
    "left": 109.0,
    "top": 452.0,
    "width": 431.0,
    "height": 91.0,
    "page_number": 10,
    "page_width": 612,
    "page_height": 792,
    "text": "This shift in control also aligns with the concept of supervisory control [ 24 , 87 ], in which humans oversee and direct automated systems rather than executing tasks manually. In this case, the developers who are visually impaired guide the AI coding assistants by monitoring their outputs, making corrections when necessary, and ensuring alignment with their broader coding goals. Just as a pilot monitors and manages an aircraft\u2019s automated systems while remaining responsible for high-level navigation and safety decisions, developers can delegate routine implementation details to Copilot while maintaining oversight and control over the overall project direction. This dynamic shifts the developer\u2019s role from manually writing every line of code to curating, refining, and strategically guiding the AI\u2019s output.",
    "type": "Text"
  },
  {
    "left": 109.0,
    "top": 547.0,
    "width": 431.0,
    "height": 64.0,
    "page_number": 10,
    "page_width": 612,
    "page_height": 792,
    "text": "In this new paradigm, control manifests as the ability to guide the overall direction of the code, make critical decisions, and intervene when necessary. While the developer retains ultimate authority over the coding process, the nature of that control shifts to a more abstract and strategic level. Rather than focusing solely on writing individual lines of code, developers can now oversee and direct AI-generated suggestions to ensure they align with the broader project architecture and goals.",
    "type": "Text"
  },
  {
    "left": 109.0,
    "top": 615.0,
    "width": 431.0,
    "height": 38.0,
    "page_number": 10,
    "page_width": 612,
    "page_height": 792,
    "text": "However, this shift in control also requires developers to develop new skills, such as crafting effective prompts to generate useful AI outputs, quickly assessing the quality and relevance of the AI-generated code, and maintaining a high-level understanding of the overall software design. As highlighted by P1:",
    "type": "Text"
  },
  {
    "left": 109.0,
    "top": 658.0,
    "width": 87.0,
    "height": 7.0,
    "page_number": 10,
    "page_width": 612,
    "page_height": 792,
    "text": "Manuscript submitted to ACM",
    "type": "Text"
  },
  {
    "left": 492.0,
    "top": 79.0,
    "width": 8.0,
    "height": 8.0,
    "page_number": 11,
    "page_width": 612,
    "page_height": 792,
    "text": "11",
    "type": "Page header"
  },
  {
    "left": 72.0,
    "top": 67.0,
    "width": 186.0,
    "height": 20.0,
    "page_number": 11,
    "page_width": 612,
    "page_height": 792,
    "text": "The Impact of Generative AI Coding Assistants on Developers Who Are Visually Impaired",
    "type": "Text"
  },
  {
    "left": 98.0,
    "top": 98.0,
    "width": 380.0,
    "height": 49.0,
    "page_number": 11,
    "page_width": 612,
    "page_height": 792,
    "text": "\u201c...when I was checking that initial version of the day counting function, I wasn\u2019t sure if it [Copilot] realized that it wasn\u2019t always going to be the same year, and it [Copilot] didn\u2019t realize that in this case. But I\u2019ve seen it make that kind of mistake before [...] You just need to be careful with your prompts [communication with the AI assistant].\u201d - P1, Developer with no vision.",
    "type": "Text"
  },
  {
    "left": 73.0,
    "top": 158.0,
    "width": 429.0,
    "height": 50.0,
    "page_number": 11,
    "page_width": 612,
    "page_height": 792,
    "text": "This shift in AI-assisted coding, where developers focus on strategic oversight rather than manually completing every coding task, marks an evolution in how developers who are visually impaired maintain control over their coding workflows [ 8 ]. The challenge lies in designing AI coding environments that empower developers with this level of control while ensuring accessibility.",
    "type": "Text"
  },
  {
    "left": 73.0,
    "top": 213.0,
    "width": 429.0,
    "height": 118.0,
    "page_number": 11,
    "page_width": 612,
    "page_height": 792,
    "text": "To achieve this, designers of AI coding environments must recognize that the needs of developers who are visually impaired often differ from those of sighted developers [ 8 , 27 , 107 ]. While sighted developers frequently rely on visual cues and dynamic, exploratory interfaces, visually impaired developers usually require predictable, structured interactions with clear, interpretable feedback [ 63 ]. This requirement is not merely a preference but a necessity that allows them to effectively understand, navigate, and maintain control over their workflow [ 48 , 62 ]. Now, a key consideration in designing AI coding environments for visually impaired developers is enabling them to anticipate the AI\u2019s actions and seamlessly integrate its assistance into their coding tasks [ 64 ]. However, generative AI inherently introduces a degree of unpredictability, making this integration complex. As a result, developing AI-driven coding environments that balance strategic oversight with accessibility is not a trivial task and requires careful, thoughtful design.",
    "type": "Text"
  },
  {
    "left": 73.0,
    "top": 346.0,
    "width": 429.0,
    "height": 77.0,
    "page_number": 11,
    "page_width": 612,
    "page_height": 792,
    "text": "4.1.2 Context Switching Difficulties in AI-assisted Interfaces . Although Copilot provided a sense of control and empowerment, it also introduced new challenges related to context switching. Our findings highlight that the dynamic nature of AI-generated suggestions and the frequent need to shift focus between writing code and reviewing AI outputs created disruptions. For developers who are visually impaired, this shift interfered with the structured navigation strategies they had developed for traditional coding environments [ 8 ], making it harder to maintain workflow continuity.",
    "type": "Text"
  },
  {
    "left": 73.0,
    "top": 428.0,
    "width": 429.0,
    "height": 63.0,
    "page_number": 11,
    "page_width": 612,
    "page_height": 792,
    "text": "The AI assistant frequently triggered unexpected view changes, forcing developers to shift their focus to different tasks or sections of the coding environment. For example, as developers interacted with Copilot\u2019s suggestions, the system would automatically switch their view to the newly generated code. This disrupted their workflow, especially because they were not always notified about these sudden shifts. As a result, developers struggled to maintain context, making it even more challenging to navigate and integrate AI-generated code seamlessly.",
    "type": "Text"
  },
  {
    "left": 73.0,
    "top": 496.0,
    "width": 429.0,
    "height": 35.0,
    "page_number": 11,
    "page_width": 612,
    "page_height": 792,
    "text": "The challenges of context switching in AI-assisted coding environments pose a significant accessibility barrier for developers who are visually impaired. These difficulties highlight the need for AI coding assistants to be designed with greater attention to the needs of screen reader users, who rely on sequential navigation [ 37 , 109 ].",
    "type": "Text"
  },
  {
    "left": 72.0,
    "top": 537.0,
    "width": 429.0,
    "height": 37.0,
    "page_number": 11,
    "page_width": 612,
    "page_height": 792,
    "text": "This challenge became evident with P9, who encountered difficulties after typing a question in the embedded chat window. When Copilot generated a response, he struggled to locate and navigate to the text where the answer was displayed, disrupting his workflow and adding unnecessary cognitive load:",
    "type": "Text"
  },
  {
    "left": 98.0,
    "top": 584.0,
    "width": 380.0,
    "height": 35.0,
    "page_number": 11,
    "page_width": 612,
    "page_height": 792,
    "text": "\u201cOkay, so do I need, I\u2019m just, I\u2019m trying to understand if we need to press the up and down [the participant repeatedly pressed keys to locate the AI assistant\u2019s response]. Seems like it still, the focus is still on my question that I typed [and not on the AI\u2019s response]...\u201d - P9, Developer with no vision.",
    "type": "Text"
  },
  {
    "left": 73.0,
    "top": 630.0,
    "width": 428.0,
    "height": 23.0,
    "page_number": 11,
    "page_width": 612,
    "page_height": 792,
    "text": "P1 emphasized that blind users depend on maintaining a stable and consistent context to work efficiently, largely due to how screen readers are designed. However, the frequent and abrupt context switching introduced by AI coding",
    "type": "Text"
  },
  {
    "left": 414.0,
    "top": 658.0,
    "width": 86.0,
    "height": 7.0,
    "page_number": 11,
    "page_width": 612,
    "page_height": 792,
    "text": "Manuscript submitted to ACM",
    "type": "Page footer"
  },
  {
    "left": 109.0,
    "top": 71.0,
    "width": 9.0,
    "height": 8.0,
    "page_number": 12,
    "page_width": 612,
    "page_height": 792,
    "text": "12",
    "type": "Page header"
  },
  {
    "left": 463.0,
    "top": 70.0,
    "width": 75.0,
    "height": 8.0,
    "page_number": 12,
    "page_width": 612,
    "page_height": 792,
    "text": "Flores-Saviaga, et al.",
    "type": "Page header"
  },
  {
    "left": 109.0,
    "top": 98.0,
    "width": 429.0,
    "height": 21.0,
    "page_number": 12,
    "page_width": 612,
    "page_height": 792,
    "text": "assistants disrupts this continuity, making it difficult for developers who are visually impaired to stay oriented and manage their coding tasks effectively:",
    "type": "Text"
  },
  {
    "left": 135.0,
    "top": 129.0,
    "width": 380.0,
    "height": 35.0,
    "page_number": 12,
    "page_width": 612,
    "page_height": 792,
    "text": "\u201cA blind person really only has one thing they can see at any given time. It would be that one window, one line of text, one line of whatever it is [...] because screen readers, that\u2019s just how they work. You can only see one thing at a time. They work sequentially and not parallel.\u201d - P1, Developer with no vision.",
    "type": "Text"
  },
  {
    "left": 109.0,
    "top": 173.0,
    "width": 430.0,
    "height": 49.0,
    "page_number": 12,
    "page_width": 612,
    "page_height": 792,
    "text": "P5 explained that the context-switching issue worsened due to the many keystrokes required to navigate between different contexts, such as reaching the Copilot chat window after writing code. The need for multiple keystrokes or clicks for minor transitions caused him to lose track of his original task, leading to frustration. This additional effort further amplified the challenge, making it harder to maintain workflow and stay focused on coding tasks:",
    "type": "Text"
  },
  {
    "left": 134.0,
    "top": 232.0,
    "width": 381.0,
    "height": 89.0,
    "page_number": 12,
    "page_width": 612,
    "page_height": 792,
    "text": "\u201c...when I\u2019m coding, I have to memorize so much... It\u2019s a lot of, I\u2019m going to reference this file again because I can\u2019t 100% remember what I said...I was going to do. And you know when I\u2019m going to Copilot, when I\u2019m pressing F6 a couple of times and I\u2019m pressing tab a couple of times, that creates a little frustration almost, because I want to get back to the task [The participant used multiple key presses to navigate to the Copilot chat window and then return to their code]. And that frustration makes it hard to remember what I was thinking about, to begin with. And then...I forget the context...now I have to go back and check again.\u201d - P5, Developer with no vision.",
    "type": "Text"
  },
  {
    "left": 109.0,
    "top": 330.0,
    "width": 430.0,
    "height": 49.0,
    "page_number": 12,
    "page_width": 612,
    "page_height": 792,
    "text": "The challenges of context switching in AI-assisted coding environments were further exacerbated by unexpected AI responses that caused sudden and confusing shifts in context. P5, a developer with no vision, described a particularly frustrating experience where merely navigating through the coding interface unintentionally triggered AI actions, making navigation even more difficult:",
    "type": "Text"
  },
  {
    "left": 135.0,
    "top": 389.0,
    "width": 380.0,
    "height": 62.0,
    "page_number": 12,
    "page_width": 612,
    "page_height": 792,
    "text": "\u201cDid I accidentally just accept [accept the AI\u2019s suggestion] I don\u2019t, I think I hit tab. See, this is part of the problem too. It\u2019s so easy to accidentally accept a suggestion because when you move the cursor, Copilot immediately is like, oh, I have a suggestion for this and I\u2019m just going to suggest it to you. But you know, again, the way a lot of us [developers who are visually impaired] navigate the UI is usually with the tab key. And so it\u2019s so easy to just accidentally insert a suggestion\u201d - P5, Developer with no vision.",
    "type": "Text"
  },
  {
    "left": 109.0,
    "top": 461.0,
    "width": 429.0,
    "height": 49.0,
    "page_number": 12,
    "page_width": 612,
    "page_height": 792,
    "text": "Similarly, P2 highlighted a significant challenge for users who rely on screen magnification: the AI assistant sometimes displayed information in areas of the screen that were out of view. Because these users were zoomed into a specific section of the screen, they often remained unaware when the AI assistant provided suggestions, as the content appeared outside their visible area:",
    "type": "Text"
  },
  {
    "left": 135.0,
    "top": 519.0,
    "width": 380.0,
    "height": 104.0,
    "page_number": 12,
    "page_width": 612,
    "page_height": 792,
    "text": "\u201c...If I, for example, zoom in like this [the participant zoomed into a specific screen area], I often don\u2019t get any information if there\u2019s some programming error or something going on in this area [the participant pointed to another part of the screen]. When I look at this [the zoomed-in area] and I just remember every time I have to go this way [The participant pointed to the unseen screen area where Copilot placed suggestions.] Sometimes I don\u2019t see that [AI suggestion] if I zoom in. So for people who are using Zoom, it will be better that it [AI assistant] will show up in the middle of the program because I don\u2019t see it [AI assistant] when it\u2019s in this area [zoomed-in area of the screen]. If there\u2019s something I have to install, for example, to run anything.\u201d - P2, Developer with low vision.",
    "type": "Text"
  },
  {
    "left": 109.0,
    "top": 632.0,
    "width": 429.0,
    "height": 34.0,
    "page_number": 12,
    "page_width": 612,
    "page_height": 792,
    "text": "These participant experiences align with and extend prior research on context-switching challenges for developers who are visually impaired. Our findings build upon the work of Albusays et al. [ 6 ], who conducted interviews and Manuscript submitted to ACM",
    "type": "Text"
  },
  {
    "left": 492.0,
    "top": 78.0,
    "width": 8.0,
    "height": 9.0,
    "page_number": 13,
    "page_width": 612,
    "page_height": 792,
    "text": "13",
    "type": "Page header"
  },
  {
    "left": 72.0,
    "top": 67.0,
    "width": 186.0,
    "height": 20.0,
    "page_number": 13,
    "page_width": 612,
    "page_height": 792,
    "text": "The Impact of Generative AI Coding Assistants on Developers Who Are Visually Impaired",
    "type": "Text"
  },
  {
    "left": 73.0,
    "top": 98.0,
    "width": 431.0,
    "height": 131.0,
    "page_number": 13,
    "page_width": 612,
    "page_height": 792,
    "text": "observations with blind software developers to examine code navigation difficulties in traditional IDEs. Their study identified the challenges blind developers face when moving between different sections of a program. Our research expands on these insights by showing how AI-assisted coding environments amplify these difficulties by introducing additional interface elements and new interaction modes, further complicating navigation and workflow continuity. While Albusays et al. [ 6 ] focused on traditional IDEs, our study reveals that AI-assisted coding environments introduce an additional layer of complexity by requiring developers to frequently switch contexts within the same application. This added complexity exacerbates the already challenging task of code navigation for developers who are visually impaired. The dynamic nature of AI-generated suggestions and the frequent need to shift focus between manually written code and AI-generated content disrupt the mental models and navigation strategies that blind developers have developed.",
    "type": "Text"
  },
  {
    "left": 73.0,
    "top": 234.0,
    "width": 430.0,
    "height": 51.0,
    "page_number": 13,
    "page_width": 612,
    "page_height": 792,
    "text": "From an Activity Theory perspective, the challenges of context switching reveal contradictions in the interaction between the user and the AI coding assistant. These contradictions likely arise because AI coding assistants are primarily designed for visual interaction, which conflicts with the sequential, nonvisual navigation methods used by screen reader users. However, several additional factors contribute to this misalignment:",
    "type": "Text"
  },
  {
    "left": 89.0,
    "top": 293.0,
    "width": 395.0,
    "height": 10.0,
    "page_number": 13,
    "page_width": 612,
    "page_height": 792,
    "text": "\u2022 The need for multiple keystrokes to move between different contexts within the AI-assisted environment.",
    "type": "List item"
  },
  {
    "left": 88.0,
    "top": 306.0,
    "width": 414.0,
    "height": 24.0,
    "page_number": 13,
    "page_width": 612,
    "page_height": 792,
    "text": "\u2022 Unexpected AI behaviors that interfere with established navigation patterns of developers who are visually impaired.",
    "type": "List item"
  },
  {
    "left": 88.0,
    "top": 333.0,
    "width": 294.0,
    "height": 11.0,
    "page_number": 13,
    "page_width": 612,
    "page_height": 792,
    "text": "\u2022 Information being displayed in inaccessible areas due to screen magnification.",
    "type": "List item"
  },
  {
    "left": 73.0,
    "top": 352.0,
    "width": 429.0,
    "height": 23.0,
    "page_number": 13,
    "page_width": 612,
    "page_height": 792,
    "text": "This mismatch between the tool\u2019s design and the needs of developers who are visually impaired disrupts their ability to stay focused and maintain a smooth workflow.",
    "type": "Text"
  },
  {
    "left": 73.0,
    "top": 388.0,
    "width": 431.0,
    "height": 90.0,
    "page_number": 13,
    "page_width": 612,
    "page_height": 792,
    "text": "4.1.3 AI Timeouts . While AI coding assistants gave developers greater control over their code and reduced the need for manually completing every task, they also introduced cognitive challenges. Participants specifically expressed a need for moments of disconnection from the AI. The constant stream of AI-generated suggestions\u2014especially the frequent appearance of ghost text \u2014created a trade-off between maintaining control and mental focus. This tension led to a key theme in our study: participants\u2019 desire for what we call \"AI timeouts\" \u2014periods of uninterrupted coding without AI intervention. For instance, participant P1, a braille display user, stressed the importance of having control over when AI suggestions appear. They found that frequent AI interventions disrupted their thought process, stating:",
    "type": "Text"
  },
  {
    "left": 97.0,
    "top": 489.0,
    "width": 382.0,
    "height": 23.0,
    "page_number": 13,
    "page_width": 612,
    "page_height": 792,
    "text": "\u201cWhat I usually do when this happens [when ghost text is presented] is I\u2019ll turn speech off for a bit so I can think....\u201d - P1, Developer with no vision.",
    "type": "Text"
  },
  {
    "left": 73.0,
    "top": 521.0,
    "width": 430.0,
    "height": 50.0,
    "page_number": 13,
    "page_width": 612,
    "page_height": 792,
    "text": "Participant P1\u2019s strategy of turning off speech to think highlights the issue of information overload , a challenge explored by Ahmed et al. [ 3 ] in their research on non-visual interfaces. Ahmed et al. explain that screen-reader users often struggle to determine the relevance or importance of content without first listening to at least some of it. This necessity frequently results in cognitive overload for users who are visually impaired.",
    "type": "Text"
  },
  {
    "left": 73.0,
    "top": 576.0,
    "width": 430.0,
    "height": 78.0,
    "page_number": 13,
    "page_width": 612,
    "page_height": 792,
    "text": "In AI-assisted coding environments, this issue becomes even more pronounced. P1\u2019s experience illustrates how the continuous stream of AI-generated suggestions, conveyed through speech output, can overwhelm cognitive capacity. By choosing to \u201cturn speech off for a bit,\u201d P1 effectively creates a temporary barrier\u2014an AI timeout \u2014allowing them to pause, process information, and make decisions without the constant influx of new suggestions. This aligns with findings by Bigham et al. [ 16 ], who suggest that slower-paced interactions can enhance usability for visually impaired users.",
    "type": "Text"
  },
  {
    "left": 414.0,
    "top": 658.0,
    "width": 86.0,
    "height": 7.0,
    "page_number": 13,
    "page_width": 612,
    "page_height": 792,
    "text": "Manuscript submitted to ACM",
    "type": "Page footer"
  },
  {
    "left": 109.0,
    "top": 71.0,
    "width": 9.0,
    "height": 8.0,
    "page_number": 14,
    "page_width": 612,
    "page_height": 792,
    "text": "14",
    "type": "Page header"
  },
  {
    "left": 463.0,
    "top": 70.0,
    "width": 76.0,
    "height": 8.0,
    "page_number": 14,
    "page_width": 612,
    "page_height": 792,
    "text": "Flores-Saviaga, et al.",
    "type": "Page header"
  },
  {
    "left": 109.0,
    "top": 98.0,
    "width": 429.0,
    "height": 35.0,
    "page_number": 14,
    "page_width": 612,
    "page_height": 792,
    "text": "The concept of AI timeouts extends beyond merely managing ghost text suggestions. Some participants expressed a need for extended periods of uninterrupted coding without any AI input. For instance, P7 emphasized the importance of having the option to engage in uninterrupted coding sessions, stating:",
    "type": "Text"
  },
  {
    "left": 134.0,
    "top": 145.0,
    "width": 381.0,
    "height": 62.0,
    "page_number": 14,
    "page_width": 612,
    "page_height": 792,
    "text": "\u201cWell, hey, can we get a mode that says, hey, I just want to get all my code done. I just want to write code. I don\u2019t care right now. I don\u2019t care how buggy it is right now. I really don\u2019t care. But I want to stay in the IDE because when I\u2019m done, I\u2019m going to use a shortcut and I\u2019m going to go through, I\u2019m going to find all my errors and I\u2019ll fix them, but I don\u2019t want it [AI assistant] to get in the way [...] But let me just get my thoughts out. \u201d - P7, Developer with no vision.",
    "type": "Text"
  },
  {
    "left": 109.0,
    "top": 218.0,
    "width": 430.0,
    "height": 76.0,
    "page_number": 14,
    "page_width": 612,
    "page_height": 792,
    "text": "This experience highlights the potential for cognitive dissonance when AI assistance operates at a faster pace than the developer\u2019s thought process. Although the AI\u2019s suggestion may have been useful, it momentarily disrupted P7\u2019s train of thought, creating a mismatch between the AI\u2019s proactive assistance and the participant\u2019s cognitive workflow. While P7\u2019s experience underscores the need for AI timeouts, it is important to note that not all participants shared this sentiment. P1\u2019s reflection, for example, illustrates a different perspective\u2014one where AI acts as a catalyst for learning and expanding problem-solving approaches:",
    "type": "Text"
  },
  {
    "left": 135.0,
    "top": 306.0,
    "width": 381.0,
    "height": 90.0,
    "page_number": 14,
    "page_width": 612,
    "page_height": 792,
    "text": "\u201cI think it [AI assistant] was a couple steps ahead of me now and again because I was sort of just expecting, okay, I need to get that date [date requested in their coding task], and then I\u2019m going to need to somehow get a year later out of it. And I didn\u2019t actually really consider that you\u2019d have to sort of parse that date and convert it into an actual date first. [...] So when it [AI assistant] made a constructor and just transformed it into month, day, year, I\u2019m like, okay, well, that\u2019s not immediately what I had in mind, but on second thought, that does make a lot of sense. [...] I probably would have done that as a next step myself, but it just sort of preempted me on there.\u201d - P1, Developer with no vision.",
    "type": "Text"
  },
  {
    "left": 109.0,
    "top": 407.0,
    "width": 430.0,
    "height": 103.0,
    "page_number": 14,
    "page_width": 612,
    "page_height": 792,
    "text": "This experience aligns with Vygotsky\u2019s concept of the Zone of Proximal Development [ 102 ], which suggests that learning is most effective when guidance bridges the gap between what a learner can do independently and what they can achieve with support. In this case, the AI guided P1 toward a more advanced solution. However, maintaining a balance between beneficial cognitive challenges and overwhelming disruptions is crucial. While this instance demonstrated a positive outcome, it highlights the need for AI systems that can dynamically adjust their level of intervention based on the user\u2019s expertise and cognitive load. By incorporating adaptive assistance, AI coding assistants can create a more effective and enriching coding experience\u2014one where developers are both supported and challenged in a way that enhances their problem-solving abilities without causing excessive cognitive overload.",
    "type": "Text"
  },
  {
    "left": 109.0,
    "top": 516.0,
    "width": 429.0,
    "height": 49.0,
    "page_number": 14,
    "page_width": 612,
    "page_height": 792,
    "text": "Conversely, P4\u2019s response to how AI suggestions influenced their planning highlights two key insights. First, AI assistants can encourage developers to adopt best coding practices earlier in the development process. Second, AI timeouts could play a role in giving developers the necessary time to reflect on different aspects of their program before implementing AI-generated suggestions:",
    "type": "Text"
  },
  {
    "left": 134.0,
    "top": 576.0,
    "width": 380.0,
    "height": 77.0,
    "page_number": 14,
    "page_width": 612,
    "page_height": 792,
    "text": "\u201c...[I would] not have remembered to put those guard clauses in until I got, like, my unit testing hat on [the participant was pointing to AI-generated guard clauses, a best practice for handling edge cases]. I\u2019ve seen some videos of like, I think Uncle Bob, Bob Martin did some unit testing videos where he literally had a hat that he would flip around and it was two hats put together and he\u2019d be like, coder, unit test, or coder and those kind of things of like, oh, I wasn\u2019t there yet [was not thinking about guard clauses yet], but if you [AI assistant] want to help me get there early, that\u2019s fine. That\u2019s great.\u201d - P4, Developer with low vision.",
    "type": "Text"
  },
  {
    "left": 109.0,
    "top": 658.0,
    "width": 86.0,
    "height": 7.0,
    "page_number": 14,
    "page_width": 612,
    "page_height": 792,
    "text": "Manuscript submitted to ACM",
    "type": "Text"
  },
  {
    "left": 492.0,
    "top": 78.0,
    "width": 8.0,
    "height": 8.0,
    "page_number": 15,
    "page_width": 612,
    "page_height": 792,
    "text": "15",
    "type": "Page header"
  },
  {
    "left": 72.0,
    "top": 67.0,
    "width": 186.0,
    "height": 20.0,
    "page_number": 15,
    "page_width": 612,
    "page_height": 792,
    "text": "The Impact of Generative AI Coding Assistants on Developers Who Are Visually Impaired",
    "type": "Text"
  },
  {
    "left": 73.0,
    "top": 98.0,
    "width": 429.0,
    "height": 145.0,
    "page_number": 15,
    "page_width": 612,
    "page_height": 792,
    "text": "This reflection highlights how AI can blur the traditional boundaries between different coding phases, potentially reducing the need for certain AI timeouts. In this case, the AI\u2019s proactive suggestions for guard clauses eliminated the need for a \u201ctimeout\u201d between the coding and testing phases by integrating best practices early in the development process. However, this scenario also emphasizes the importance of \u201cflexible AI timeouts\u201d. While P4 valued the early inclusion of guard clauses, other developers might prefer to maintain distinct mental phases in their coding workflow. In this context, AI timeouts do not necessarily mean disengaging from AI assistance entirely but rather enabling developers to control when and how AI interventions occur. By allowing developers to schedule AI timeouts or receive advanced suggestions at specific points in their workflow, AI-assisted coding tools can accommodate different coding styles and personal preferences. This flexibility could be particularly beneficial for developers who are visually impaired, as they may have structured routines or mental models for managing distinct phases of the coding process [ 42 , 50 ]. Providing adaptive AI interaction could enhance productivity without disrupting established workflows.",
    "type": "Text"
  },
  {
    "left": 73.0,
    "top": 248.0,
    "width": 429.0,
    "height": 22.0,
    "page_number": 15,
    "page_width": 612,
    "page_height": 792,
    "text": "P3\u2019s experience further illustrates the need for a balanced approach to AI timeouts, ensuring that AI assistance is helpful without becoming disruptive:",
    "type": "Text"
  },
  {
    "left": 98.0,
    "top": 283.0,
    "width": 380.0,
    "height": 63.0,
    "page_number": 15,
    "page_width": 612,
    "page_height": 792,
    "text": "\u201cHonestly, I think it\u2019s [AI assistant] super helpful because like, I\u2019m going to be honest, like you were saying before, I always forget datetime manipulation. [...] So having the ability to just say what I want, have it [AI assistant] understand the context of the programming language I\u2019m in and help me kind of get there quicker without having to kind of start searching around the web, figuring out the reading documentation again for the datetime methods. Like I have to all the time.\u201d - P3, developer with low vision.",
    "type": "Text"
  },
  {
    "left": 73.0,
    "top": 358.0,
    "width": 430.0,
    "height": 36.0,
    "page_number": 15,
    "page_width": 612,
    "page_height": 792,
    "text": "As the quote illustrates, developers may choose to keep the AI when it provides helpful support, such as recalling correct syntax or assisting with complex code manipulations. However, for tasks requiring deep problem-solving or creative thinking, they may prefer to use AI timeouts to independently work through solutions.",
    "type": "Text"
  },
  {
    "left": 73.0,
    "top": 399.0,
    "width": 429.0,
    "height": 92.0,
    "page_number": 15,
    "page_width": 612,
    "page_height": 792,
    "text": "The concept of \u201cAI timeouts\u201d reflects contradictions within the activity system, arising from misalignments between the subject (developers), the object (coding tasks), and the tool (Copilot). While Copilot serves as a mediating artifact designed to facilitate coding, its dynamic and sometimes intrusive interventions create tensions that can disrupt developers\u2019 workflows. This contradiction likely arises because the tool\u2019s design assumes that continuous AI assistance improves productivity, whereas developers might actually need uninterrupted periods to process and structure information. These tensions highlight the necessity of adaptable AI systems that calibrate their level of intervention based on the user\u2019s needs.",
    "type": "Text"
  },
  {
    "left": 72.0,
    "top": 506.0,
    "width": 430.0,
    "height": 36.0,
    "page_number": 15,
    "page_width": 612,
    "page_height": 792,
    "text": "4.1.4 AI-Assisted Coding Efficiency . While our study highlighted challenges like context switching, it also revealed key benefits of AI coding assistants, particularly in enhancing coding efficiency for developers who are visually impaired. This efficiency improvement stemmed from two main factors:",
    "type": "Text"
  },
  {
    "left": 83.0,
    "top": 554.0,
    "width": 419.0,
    "height": 22.0,
    "page_number": 15,
    "page_width": 612,
    "page_height": 792,
    "text": "(1) Copilot\u2019s Proactive Code Generation , which anticipated and generated relevant code, reducing manual effort. (2) Copilot as an Accessible, Always-Available Coding Partner , providing instant non-judgmental support.",
    "type": "Text"
  },
  {
    "left": 73.0,
    "top": 589.0,
    "width": 429.0,
    "height": 63.0,
    "page_number": 15,
    "page_width": 612,
    "page_height": 792,
    "text": "Proactive Code Generation . Participants highlighted how the AI assistant boosted their productivity by anticipating their needs\u2014proactively generating code that resolved existing issues or introduced features they had not initially considered. For instance, P7 described a moment when the AI assistant demonstrated foresight by automatically parsing and transforming a date into a usable format. Upon reflection, P7 realized that this step aligned perfectly with their next intended action, streamlining their workflow and reducing the need for manual adjustments:",
    "type": "Text"
  },
  {
    "left": 414.0,
    "top": 658.0,
    "width": 86.0,
    "height": 7.0,
    "page_number": 15,
    "page_width": 612,
    "page_height": 792,
    "text": "Manuscript submitted to ACM",
    "type": "Page footer"
  },
  {
    "left": 109.0,
    "top": 71.0,
    "width": 8.0,
    "height": 8.0,
    "page_number": 16,
    "page_width": 612,
    "page_height": 792,
    "text": "16",
    "type": "Page header"
  },
  {
    "left": 463.0,
    "top": 70.0,
    "width": 75.0,
    "height": 8.0,
    "page_number": 16,
    "page_width": 612,
    "page_height": 792,
    "text": "Flores-Saviaga, et al.",
    "type": "Page header"
  },
  {
    "left": 135.0,
    "top": 98.0,
    "width": 380.0,
    "height": 103.0,
    "page_number": 16,
    "page_width": 612,
    "page_height": 792,
    "text": "\u201cIt [AI assistant] was a couple steps ahead of me. [The participant\u2019s coding task involved calculating the number of days until a birthday provided by an end-user.] I was initially focused on getting the date and calculating a year later, but I didn\u2019t actually really consider that you\u2019d have to sort of parse that date [date given by the end-user] and convert it into an actual date first [converting to an actual date was something the generative AI did for them]. That makes perfect sense in hindsight [...] So when it [AI assistant] made it a constructor and just transformed it into month, day, year, I\u2019m like, okay, well, that\u2019s not immediately what I had in mind, but on second thought, that does make a lot of sense. [...] I probably would have done that as a next step myself, but it just sort of preempted me on there.\u201d - P7, Developer with no vision.",
    "type": "Text"
  },
  {
    "left": 109.0,
    "top": 214.0,
    "width": 429.0,
    "height": 21.0,
    "page_number": 16,
    "page_width": 612,
    "page_height": 792,
    "text": "Similarly, P1 emphasized their appreciation for the AI\u2019s ability to proactively generate code, particularly in how it anticipated their next steps and aligned with their intentions as a developer:",
    "type": "Text"
  },
  {
    "left": 134.0,
    "top": 249.0,
    "width": 380.0,
    "height": 75.0,
    "page_number": 16,
    "page_width": 612,
    "page_height": 792,
    "text": "\u201cI\u2019m gonna try something else. I\u2019m actually very curious [...] I\u2019ll auto modify that [The participant used a Copilot command to \u2019auto-modify\u2019 their code, allowing the AI to proactively edit and expand their initial work]. That sounds good [The participant was reviewing the code generated by the AI\u201d]. There are days until your next birthday. Yeah, format days until next birthday [The participant continued reviewing the code generated by the AI.] That [code generated by the AI] is scarily good. Actually that [AI generated code] is exactly what I was going to do.\u201d - P1, Developer with no vision.",
    "type": "Text"
  },
  {
    "left": 109.0,
    "top": 337.0,
    "width": 429.0,
    "height": 90.0,
    "page_number": 16,
    "page_width": 612,
    "page_height": 792,
    "text": "Prior research has documented the challenges that developers with visual impairments face when navigating and understanding code structures in traditional development environments [ 5 , 11 , 78 ]. Given these challenges, we argue that AI\u2019s proactive code generation holds potential for this population. Developers who are visually impaired often need to traverse multiple documentation pages or code files to construct appropriate solutions\u2014a process that is not only time-consuming but also more prone to errors when relying on screen readers [ 6 , 20 ]. In this context, AI\u2019s ability to predict coding needs and generate relevant code snippets is especially valuable, as it can reduce cognitive load and enhance efficiency for developers who are visually impaired.",
    "type": "Text"
  },
  {
    "left": 109.0,
    "top": 433.0,
    "width": 429.0,
    "height": 62.0,
    "page_number": 16,
    "page_width": 612,
    "page_height": 792,
    "text": "AI as an Accessible, Always-Available Coding Partner. Some participants described the AI assistant as a supportive \u2019buddy\u2019 that guided them through their coding tasks, providing assistance and enhancing their productivity. They appreciated having an AI-powered companion they could rely on for coding assistance, providing quick answers and relevant code snippets when needed. For example, Participant P3 likened the AI assistant to a knowledgeable colleague who is readily available to offer solutions and assist with coding challenges:",
    "type": "Text"
  },
  {
    "left": 135.0,
    "top": 508.0,
    "width": 379.0,
    "height": 49.0,
    "page_number": 16,
    "page_width": 612,
    "page_height": 792,
    "text": "\u201c[with the AI coding assistant] you have that kind of buddy to kind of ask real quick, you know, what was that? You know, what was the daytime method that I needed to use to convert that particular string into the right thing? [The participant refers to asking the AI about functions and methods needed for the date-related coding task]\u201d - P3, Developer with low vision.",
    "type": "Text"
  },
  {
    "left": 109.0,
    "top": 569.0,
    "width": 431.0,
    "height": 35.0,
    "page_number": 16,
    "page_width": 612,
    "page_height": 792,
    "text": "All participants agreed that the AI assistant was beneficial in helping them complete their software development tasks. However, the degree of reliance on the assistant varied among individuals. Some, like P6, depended on it extensively, using it to complete nearly their entire assigned workload:",
    "type": "Text"
  },
  {
    "left": 135.0,
    "top": 617.0,
    "width": 380.0,
    "height": 35.0,
    "page_number": 16,
    "page_width": 612,
    "page_height": 792,
    "text": "\u201cI just copy and pasted the whole task [instructions for a coding task assigned in our study] into chat [Copilot\u2019s chat interface], and it [AI assistant] gave me the whole implementation that we had to do. Very, very minor tweaks left to do. I mean, the date formats worked out, right? [The participant was assigned a coding task",
    "type": "Text"
  },
  {
    "left": 109.0,
    "top": 658.0,
    "width": 86.0,
    "height": 6.0,
    "page_number": 16,
    "page_width": 612,
    "page_height": 792,
    "text": "Manuscript submitted to ACM",
    "type": "Text"
  },
  {
    "left": 492.0,
    "top": 78.0,
    "width": 8.0,
    "height": 9.0,
    "page_number": 17,
    "page_width": 612,
    "page_height": 792,
    "text": "17",
    "type": "Page header"
  },
  {
    "left": 72.0,
    "top": 67.0,
    "width": 186.0,
    "height": 20.0,
    "page_number": 17,
    "page_width": 612,
    "page_height": 792,
    "text": "The Impact of Generative AI Coding Assistants on Developers Who Are Visually Impaired",
    "type": "Text"
  },
  {
    "left": 97.0,
    "top": 98.0,
    "width": 379.0,
    "height": 21.0,
    "page_number": 17,
    "page_width": 612,
    "page_height": 792,
    "text": "involving date formats.] Essentially we just added comments and tinkered with the code [...] But otherwise, it [AI assistant] just did everything for us.\u201d - P6, Developer with low vision.",
    "type": "Text"
  },
  {
    "left": 72.0,
    "top": 129.0,
    "width": 429.0,
    "height": 22.0,
    "page_number": 17,
    "page_width": 612,
    "page_height": 792,
    "text": "Even participants with limited experience using AI assistants, such as P9, acknowledged its potential to accelerate coding tasks. Their experience in our study sparked greater interest in exploring the technology further:",
    "type": "Text"
  },
  {
    "left": 98.0,
    "top": 160.0,
    "width": 380.0,
    "height": 36.0,
    "page_number": 17,
    "page_width": 612,
    "page_height": 792,
    "text": "\u201cI would love to try and explore more [about AI coding assistants]. But, it [the AI coding assistant] has definitely a potential [...] just doing quick work, especially writing quick functions and doing also all those tasks [...] It\u2019s [the AI assistant is] bringing a lot of time saving.\u201d - P9, Developer with no vision.",
    "type": "Text"
  },
  {
    "left": 73.0,
    "top": 204.0,
    "width": 428.0,
    "height": 64.0,
    "page_number": 17,
    "page_width": 612,
    "page_height": 792,
    "text": "For developers who are visually impaired, this aspect of AI assistance could be particularly valuable, as it offers constant, non-judgmental support without requiring face-to-face interaction. This can be especially beneficial in workplace environments where they may feel hesitant to frequently ask colleagues for help [ 6 ]. Generative AI assistants have the potential to make software development more accessible and efficient, enabling developers to work more independently without relying on coworkers for assistance.",
    "type": "Text"
  },
  {
    "left": 73.0,
    "top": 273.0,
    "width": 428.0,
    "height": 119.0,
    "page_number": 17,
    "page_width": 612,
    "page_height": 792,
    "text": "From the perspective of Activity Theory, Copilot serves as a mediating artifact that reshapes the coding activity by shifting its role from a passive tool to an active collaborator. Within the framework of Activity Theory, the interaction between the subject (developer), object (coding task), and tool (AI assistant) is no longer a linear process but a dynamic, adaptive exchange. Instead of developers following a rigid, step-by-step workflow, Copilot enables a more fluid interaction where AI-generated suggestions proactively shape the problem-solving process. Acting as a readily available and non-judgmental coding companion, Copilot can function as a \u201cbuddy\u201d that developers can turn to at any moment to clarify uncertainties, propose solutions, and reduce cognitive load. By integrating AI as an active collaborator within the activity system, Copilot can help developers navigate complex programming tasks with greater confidence and independence.",
    "type": "Text"
  },
  {
    "left": 72.0,
    "top": 409.0,
    "width": 68.0,
    "height": 7.0,
    "page_number": 17,
    "page_width": 612,
    "page_height": 792,
    "text": "5 DISCUSSION",
    "type": "Section header"
  },
  {
    "left": 73.0,
    "top": 425.0,
    "width": 428.0,
    "height": 76.0,
    "page_number": 17,
    "page_width": 612,
    "page_height": 792,
    "text": "Our findings show that AI coding assistants provide powerful capabilities, new opportunities, and greater control for developers who are visually impaired, but they also introduce new accessibility challenges. Issues such as context switching and managing AI-generated suggestions highlight the need for a new approach to accessibility in AI coding environments. Building on Nielsen\u2019s argument that generative AI has introduced a new paradigm for HCI [ 68 ] and the design principles for generative AI tools outlined by Weisz et al. [ 104 ], we propose design recommendations to ensure AI coding assistants are accessible and beneficial for all developers.",
    "type": "Text"
  },
  {
    "left": 73.0,
    "top": 519.0,
    "width": 312.0,
    "height": 7.0,
    "page_number": 17,
    "page_width": 612,
    "page_height": 792,
    "text": "5.1 AI Control and Context-Switching Management in AI Coding Assistants",
    "type": "Section header"
  },
  {
    "left": 73.0,
    "top": 535.0,
    "width": 428.0,
    "height": 63.0,
    "page_number": 17,
    "page_width": 612,
    "page_height": 792,
    "text": "Our study highlights the mixed experiences of developers who are visually impaired when using AI coding assistants. While these assistants empower developers by allowing them to focus on higher-level strategic thinking, they also introduce new challenges. Participants, such as P5 and P9, reported difficulties in navigating between their static code and the dynamic windows used for AI interactions. This constant context switching led to frustration, disrupting their workflow and breaking their cognitive focus.",
    "type": "Text"
  },
  {
    "left": 73.0,
    "top": 604.0,
    "width": 428.0,
    "height": 50.0,
    "page_number": 17,
    "page_width": 612,
    "page_height": 792,
    "text": "Previous research highlights that the visually oriented nature of Integrated Development Environments (IDEs) presents challenges for developers who are visually impaired, often leading to a loss of control [ 6 , 22 , 96 ]. P1 also noted that screen readers require users to read code sequentially, making context switching particularly difficult [ 5 \u2013 7 , 59 , 90 ]. Several tools, such as StructJumper and CodeTalk, have been designed to aid navigation in traditional static coding",
    "type": "Text"
  },
  {
    "left": 414.0,
    "top": 658.0,
    "width": 86.0,
    "height": 7.0,
    "page_number": 17,
    "page_width": 612,
    "page_height": 792,
    "text": "Manuscript submitted to ACM",
    "type": "Page footer"
  },
  {
    "left": 109.0,
    "top": 70.0,
    "width": 9.0,
    "height": 8.0,
    "page_number": 18,
    "page_width": 612,
    "page_height": 792,
    "text": "18",
    "type": "Page header"
  },
  {
    "left": 463.0,
    "top": 70.0,
    "width": 76.0,
    "height": 8.0,
    "page_number": 18,
    "page_width": 612,
    "page_height": 792,
    "text": "Flores-Saviaga, et al.",
    "type": "Page header"
  },
  {
    "left": 109.0,
    "top": 98.0,
    "width": 431.0,
    "height": 131.0,
    "page_number": 18,
    "page_width": 612,
    "page_height": 792,
    "text": "environments [ 10 , 11 , 77 , 78 ]. However, these tools primarily focus on static code elements. In contrast, AI-assisted coding environments introduce new challenges by incorporating dynamic code elements [ 73 ]. Our findings reveal that developers who are visually impaired must now manage the additional complexity of interacting with AI-generated suggestions, making context switching even more difficult. Navigating between static code and AI-generated content requires frequent shifts in focus across different interface elements [ 66 , 73 ]. Developers must assess their own code, review AI-generated suggestions, and interact with various UI windows required for AI engagement [ 105 ]. This continuous back-and-forth process can increase cognitive load, forcing developers to constantly evaluate AI outputs while maintaining an understanding of their overall code structure [ 84 ]. As a result, the interplay between AI assistance and manual coding can fragment attention, disrupt workflow continuity, and impact productivity, code quality, and trust in the AI-generated content [ 55 , 73 , 103 ].",
    "type": "Text"
  },
  {
    "left": 109.0,
    "top": 234.0,
    "width": 431.0,
    "height": 50.0,
    "page_number": 18,
    "page_width": 612,
    "page_height": 792,
    "text": "Our findings highlight the urgent need for accessible tools specifically designed for dynamic coding environments. These tools should aim to streamline workflows, minimize AI disruptions, and provide better support for developers who are visually impaired. By addressing the challenges of context switching and maintaining control, such tools can help developers navigate AI-assisted coding environments more effectively and improve overall accessibility.",
    "type": "Text"
  },
  {
    "left": 109.0,
    "top": 296.0,
    "width": 431.0,
    "height": 50.0,
    "page_number": 18,
    "page_width": 612,
    "page_height": 792,
    "text": "5.1.1 Addressing the Research Gap. Our research revealed both new accessibility opportunities and challenges in AI coding assistants for developers who are visually impaired. On one hand, AI coding assistants empowered developers by shifting their role toward supervisory control over the code. However, these benefits were accompanied by significant challenges, especially related to context switching, which disrupted their workflow and made navigation more complex.",
    "type": "Text"
  },
  {
    "left": 109.0,
    "top": 351.0,
    "width": 431.0,
    "height": 118.0,
    "page_number": 18,
    "page_width": 612,
    "page_height": 792,
    "text": "While previous studies [ 6 , 22 , 96 ] have identified accessibility barriers in traditional IDEs\u2014such as visually-oriented interfaces and linear screen reader navigation for static code [ 5 , 7 , 59 , 90 ]\u2014our findings reveal that AI-driven coding environments exacerbate these issues. The dynamic nature of AI-assisted coding introduces additional complexities that amplify accessibility barriers. Existing tools like StructJumper and CodeTalk [ 10 , 11 , 77 , 78 ], designed for static code, may not fully support AI-driven workflows. Furthermore, prior research on AI-assisted coding has examined cognitive strain and productivity for general developers [ 55 , 66 , 73 , 105 ]. But, our work introduces an accessibility perspective. Frequent context switching and fragmented workflows present significant challenges for developers who are visually impaired, emphasizing the urgent need for AI tools designed with accessibility at their core to ensure equitable participation in evolving coding practices.",
    "type": "Text"
  },
  {
    "left": 109.0,
    "top": 481.0,
    "width": 430.0,
    "height": 77.0,
    "page_number": 18,
    "page_width": 612,
    "page_height": 792,
    "text": "5.1.2 Design Recommendations. Based on our findings, we propose a set of design recommendations aimed at improving interaction continuity, personalization, and information management in AI-assisted coding environments. These recommendations build on established principles such as Design for Generative Variability by Weisz et al. [ 104 ], which emphasizes the importance of visualizing the user\u2019s journey to accommodate diverse needs. From an Activity Theory perspective, our recommendations seek to realign the AI coding assistant ( tool ) with developers who are visually impaired ( subject ) to help them successfully complete coding tasks ( object ).",
    "type": "Text"
  },
  {
    "left": 109.0,
    "top": 563.0,
    "width": 430.0,
    "height": 50.0,
    "page_number": 18,
    "page_width": 612,
    "page_height": 792,
    "text": "First, we recommend implementing a context history log [ 21 ] to mitigate workflow disruptions caused by AI-driven context switching. This feature would provide a sequential record of user interactions with the AI, allowing developers to review and revisit previous steps in their coding process. For visually impaired users, a structured history log could be especially valuable for maintaining workflow continuity and recovering from unexpected focus shifts.",
    "type": "Text"
  },
  {
    "left": 109.0,
    "top": 618.0,
    "width": 430.0,
    "height": 47.0,
    "page_number": 18,
    "page_width": 612,
    "page_height": 792,
    "text": "Additionally, this log could enhance the system\u2019s adaptability by learning from user behavior. For example, if a developer frequently accesses the inline chat for code explanations, the AI could prioritize and streamline access to this feature, reducing cognitive load and improving efficiency. By addressing workflow contradictions , a context history Manuscript submitted to ACM",
    "type": "Text"
  },
  {
    "left": 492.0,
    "top": 78.0,
    "width": 8.0,
    "height": 9.0,
    "page_number": 19,
    "page_width": 612,
    "page_height": 792,
    "text": "19",
    "type": "Page header"
  },
  {
    "left": 72.0,
    "top": 67.0,
    "width": 186.0,
    "height": 20.0,
    "page_number": 19,
    "page_width": 612,
    "page_height": 792,
    "text": "The Impact of Generative AI Coding Assistants on Developers Who Are Visually Impaired",
    "type": "Text"
  },
  {
    "left": 73.0,
    "top": 97.0,
    "width": 428.0,
    "height": 22.0,
    "page_number": 19,
    "page_width": 612,
    "page_height": 792,
    "text": "log would ensure that developers maintain control over their interactions with the AI, making AI-assisted coding environments more predictable and user-friendly.",
    "type": "Text"
  },
  {
    "left": 73.0,
    "top": 124.0,
    "width": 429.0,
    "height": 64.0,
    "page_number": 19,
    "page_width": 612,
    "page_height": 792,
    "text": "Second, we propose integrating an interaction organizer to help mitigate the challenges caused by the sequential navigation constraints of screen readers. Unlike sighted developers, who can visually scan and filter information quickly, developers who are visually impaired must process content in a linear fashion, which can make it difficult to efficiently navigate AI-generated suggestions [ 20 ]. The interaction organizer would allow users to structure AI-generated suggestions more effectively by enabling them to:",
    "type": "Text"
  },
  {
    "left": 88.0,
    "top": 201.0,
    "width": 211.0,
    "height": 11.0,
    "page_number": 19,
    "page_width": 612,
    "page_height": 792,
    "text": "\u2022 Group related AI suggestions into folders or categories.",
    "type": "List item"
  },
  {
    "left": 88.0,
    "top": 214.0,
    "width": 222.0,
    "height": 11.0,
    "page_number": 19,
    "page_width": 612,
    "page_height": 792,
    "text": "\u2022 Assign meaningful labels and keywords for quick retrieval.",
    "type": "List item"
  },
  {
    "left": 88.0,
    "top": 228.0,
    "width": 219.0,
    "height": 11.0,
    "page_number": 19,
    "page_width": 612,
    "page_height": 792,
    "text": "\u2022 Attach personal notes or comments to AI-generated code.",
    "type": "List item"
  },
  {
    "left": 73.0,
    "top": 253.0,
    "width": 430.0,
    "height": 78.0,
    "page_number": 19,
    "page_width": 612,
    "page_height": 792,
    "text": "By incorporating these capabilities, the interaction organizer would help developers streamline their workflow, making it easier to manage and retrieve AI-generated outputs while reducing cognitive strain. From an Activity Theory perspective, this feature helps resolve contradictions between the dynamic and non-linear nature of AI-generated suggestions and the sequential workflows that visually impaired developers rely on. By providing structured ways to categorize and personalize AI outputs, the interaction organizer improves the tool\u2019s role as a mediator in the coding process, making AI-assisted development more efficient and accessible.",
    "type": "Text"
  },
  {
    "left": 72.0,
    "top": 351.0,
    "width": 141.0,
    "height": 8.0,
    "page_number": 19,
    "page_width": 612,
    "page_height": 792,
    "text": "5.2 The Need for \"AI Timeouts\" in",
    "type": "Section header"
  },
  {
    "left": 92.0,
    "top": 366.0,
    "width": 78.0,
    "height": 7.0,
    "page_number": 19,
    "page_width": 612,
    "page_height": 792,
    "text": "AI-Assisted Coding",
    "type": "Section header"
  },
  {
    "left": 73.0,
    "top": 382.0,
    "width": 430.0,
    "height": 64.0,
    "page_number": 19,
    "page_width": 612,
    "page_height": 792,
    "text": "Our study uncovered a complex relationship between increased productivity and cognitive overload in AI-assisted coding environments for developers who are visually impaired. While participants reported productivity gains\u2014such as AI proactively anticipating their coding needs\u2014these benefits also introduced a challenge: the need for AI timeouts . These timeouts represent intentional breaks from AI interventions, allowing developers to manage information overload and maintain focus during their workflow.",
    "type": "Text"
  },
  {
    "left": 73.0,
    "top": 450.0,
    "width": 429.0,
    "height": 36.0,
    "page_number": 19,
    "page_width": 612,
    "page_height": 792,
    "text": "The continuous stream of AI-generated suggestions, particularly inline ghost text , seemed to have contributed to cognitive overload among participants. This overload created a need for AI timeouts \u2014temporary pauses in AI interventions to allow for uninterrupted focus and reduce mental strain.",
    "type": "Text"
  },
  {
    "left": 73.0,
    "top": 492.0,
    "width": 430.0,
    "height": 91.0,
    "page_number": 19,
    "page_width": 612,
    "page_height": 792,
    "text": "Activity Theory provides a useful framework for understanding this challenge, as it reveals a contradiction between the AI assistant\u2019s intended role of enhancing productivity and its unintended effect of disrupting focus. This finding aligns with prior research on information overload in visual interfaces [ 3 , 32 ], which shows that excessive information can overwhelm users, particularly those who are visually impaired. Our study extends this research by demonstrating how AI-generated content can intensify cognitive overload in AI-assisted coding environments. This underscores the importance of designing AI interactions that are more controlled and customizable, ensuring that developers who are visually impaired can maintain focus and effectively manage their workflows.",
    "type": "Text"
  },
  {
    "left": 73.0,
    "top": 588.0,
    "width": 429.0,
    "height": 64.0,
    "page_number": 19,
    "page_width": 612,
    "page_height": 792,
    "text": "The need for AI timeouts varied among participants, highlighting the complexity of designing AI coding assistants for developers who are visually impaired. While some participants valued proactive AI assistance, others wanted greater control over when and how AI intervened in their coding process. This variation underscores the importance of flexible, personalized customization rather than a one-size-fits-all approach, which is often emphasized in existing research on accessible development tools [ 10 , 11 , 77 , 78 ].",
    "type": "Text"
  },
  {
    "left": 414.0,
    "top": 658.0,
    "width": 86.0,
    "height": 7.0,
    "page_number": 19,
    "page_width": 612,
    "page_height": 792,
    "text": "Manuscript submitted to ACM",
    "type": "Page footer"
  },
  {
    "left": 109.0,
    "top": 70.0,
    "width": 9.0,
    "height": 8.0,
    "page_number": 20,
    "page_width": 612,
    "page_height": 792,
    "text": "20",
    "type": "Page header"
  },
  {
    "left": 463.0,
    "top": 70.0,
    "width": 75.0,
    "height": 8.0,
    "page_number": 20,
    "page_width": 612,
    "page_height": 792,
    "text": "Flores-Saviaga, et al.",
    "type": "Page header"
  },
  {
    "left": 109.0,
    "top": 98.0,
    "width": 431.0,
    "height": 90.0,
    "page_number": 20,
    "page_width": 612,
    "page_height": 792,
    "text": "Building on Gajos et al.\u2019s adaptive interfaces concept [ 31 ], our findings suggest that AI-assisted coding environments could benefit from adaptive features. From an Activity Theory perspective, these adaptive interfaces help resolve contradictions by aligning AI mediation with user goals and preferences. Specifically, AI coding assistants could learn individual preferences for AI intervention, dynamically adjusting the frequency and type of AI suggestions based on task complexity. Additionally, providing easily accessible controls for enabling and disabling AI assistance would grant developers greater autonomy over their workflow. This approach ensures that AI remains a supportive tool rather than a source of cognitive overload.",
    "type": "Text"
  },
  {
    "left": 109.0,
    "top": 202.0,
    "width": 430.0,
    "height": 104.0,
    "page_number": 20,
    "page_width": 612,
    "page_height": 792,
    "text": "5.2.1 Addressing the Research Gap. Our research introduces AI timeouts as a strategy to mitigate cognitive overload for developers who are visually impaired using AI coding assistants. Prior work highlights AI\u2019s ability to enhance productivity by automating repetitive tasks and offering anticipatory suggestions [ 4 , 70 , 106 ]. However, our findings reveal new challenges, such as cognitive strain from continuous AI-generated inputs like inline ghost text . Building on studies of information overload for visually impaired users [ 3 , 32 , 73 , 84 ], we extend this discussion to dynamic AI-driven environments, where proactive AI mediation can disrupt cognitive coherence [ 73 , 84 ]. Using Activity Theory, we frame this tension as a contradiction between AI assistance and focus disruption, proposing AI timeouts as a novel accessibility strategy to balance intervention and cognitive load.",
    "type": "Text"
  },
  {
    "left": 109.0,
    "top": 320.0,
    "width": 430.0,
    "height": 132.0,
    "page_number": 20,
    "page_width": 612,
    "page_height": 792,
    "text": "5.2.2 Design Recommendations. To improve the accessibility and usability of AI coding assistants for developers who are visually impaired, we recommend design strategies aligned with the Design for Mental Models principle by Weisz et al. [ 104 ]. This principle emphasizes the importance of aligning AI behavior with the user\u2019s expectations to balance supportive AI intervention with user autonomy. One of our recommendation is to allow developers to customize the AI\u2019s behavior to match their mental model. For instance, tools could offer adjustable modes such as \"Low Detail\" and \"High Detail,\" enabling users to control the level of information the AI provides based on task complexity or cognitive load. This flexibility ensures that AI assistance aligns with individual problem-solving preferences, reducing unnecessary cognitive strain. Customization can also resolve contradictions between the user\u2019s mental model and the often unpredictable nature of AI-generated suggestions, which may sometimes provide excessive or distracting information.",
    "type": "Text"
  },
  {
    "left": 120.0,
    "top": 457.0,
    "width": 413.0,
    "height": 9.0,
    "page_number": 20,
    "page_width": 612,
    "page_height": 792,
    "text": "Another essential feature that we propose is the implementation of AI timeouts , which serve two key purposes:",
    "type": "Text"
  },
  {
    "left": 126.0,
    "top": 475.0,
    "width": 414.0,
    "height": 50.0,
    "page_number": 20,
    "page_width": 612,
    "page_height": 792,
    "text": "\u2022 Preserving Autonomy : Timeouts allow developers to temporarily pause AI interventions, giving them space to reflect and solve problems independently. This can prevent over-reliance on AI and help maintain control over the coding process. From an Activity Theory perspective, these timeouts address contradictions by giving users greater control over the tool, ensuring AI assistance aligns with their goals and cognitive needs.",
    "type": "List item"
  },
  {
    "left": 126.0,
    "top": 529.0,
    "width": 413.0,
    "height": 50.0,
    "page_number": 20,
    "page_width": 612,
    "page_height": 792,
    "text": "\u2022 Enhancing Learning : By pausing AI interventions, developers have the opportunity to engage with their own problem-solving strategies. This reinforces their mental model, strengthens coding skills, and promotes deeper understanding. This aligns with Activity Theory\u2019s emphasis on fostering user agency, allowing developers to actively shape their interactions with Copilot.",
    "type": "List item"
  },
  {
    "left": 109.0,
    "top": 590.0,
    "width": 430.0,
    "height": 66.0,
    "page_number": 20,
    "page_width": 612,
    "page_height": 792,
    "text": "For developers who are visually impaired, maintaining a clear and consistent mental model of the coding environment can be essential for effective work. Customizable AI behavior and strategic pauses could help ensure interactions remain predictable and aligned with user expectations, fostering a more intuitive and personalized experience. By supporting mental model alignment, these design features bridge the gap between user cognition and AI functionality, ultimately improving accessibility and productivity.",
    "type": "Text"
  },
  {
    "left": 109.0,
    "top": 658.0,
    "width": 86.0,
    "height": 7.0,
    "page_number": 20,
    "page_width": 612,
    "page_height": 792,
    "text": "Manuscript submitted to ACM",
    "type": "Text"
  },
  {
    "left": 492.0,
    "top": 78.0,
    "width": 8.0,
    "height": 9.0,
    "page_number": 21,
    "page_width": 612,
    "page_height": 792,
    "text": "21",
    "type": "Page header"
  },
  {
    "left": 72.0,
    "top": 67.0,
    "width": 186.0,
    "height": 20.0,
    "page_number": 21,
    "page_width": 612,
    "page_height": 792,
    "text": "The Impact of Generative AI Coding Assistants on Developers Who Are Visually Impaired",
    "type": "Text"
  },
  {
    "left": 73.0,
    "top": 99.0,
    "width": 140.0,
    "height": 7.0,
    "page_number": 21,
    "page_width": 612,
    "page_height": 792,
    "text": "5.3 Limitations and Future Work.",
    "type": "Section header"
  },
  {
    "left": 73.0,
    "top": 115.0,
    "width": 429.0,
    "height": 76.0,
    "page_number": 21,
    "page_width": 612,
    "page_height": 792,
    "text": "Our study provides valuable insights into the experiences of developers who are visually impaired using AI coding assistants. But it also has limitations. We interviewed a small group of 10 male participants, which restricts the diversity and generalizability of our findings. Studying emerging technologies like GitHub Copilot and recruiting a niche population, such as developers who are visually impaired, often results in a limited and homogeneous sample. However, despite participants\u2019 varying levels of experience with AI coding assistants, their shared challenges and opportunities provide foundational insights into how these tools impact accessibility.",
    "type": "Text"
  },
  {
    "left": 73.0,
    "top": 197.0,
    "width": 429.0,
    "height": 90.0,
    "page_number": 21,
    "page_width": 612,
    "page_height": 792,
    "text": "Additionally, our study focused exclusively on GitHub Copilot, meaning we did not explore other AI coding assistants that may have different features and accessibility considerations. Future research should examine a broader range of AI coding tools to gain a more comprehensive understanding of accessibility challenges across different platforms. Another limitation is that participants had limited prior exposure to GitHub Copilot, meaning our findings may not fully capture the long-term benefits and challenges of using AI coding assistants. Longitudinal studies are needed to investigate how developers who are visually impaired adapt to AI-assisted environments over time, as well as any lasting accessibility barriers or professional impacts that may emerge.",
    "type": "Text"
  },
  {
    "left": 72.0,
    "top": 305.0,
    "width": 74.0,
    "height": 7.0,
    "page_number": 21,
    "page_width": 612,
    "page_height": 792,
    "text": "6 CONCLUSION",
    "type": "Section header"
  },
  {
    "left": 73.0,
    "top": 321.0,
    "width": 429.0,
    "height": 104.0,
    "page_number": 21,
    "page_width": 612,
    "page_height": 792,
    "text": "We examined the experiences of 10 developers who are visually impaired as they interacted with an AI coding assistant. Our study highlights the dual impact of AI coding assistants on developers who are visually impaired. While these tools enhance control and provide valuable support, they also introduce new accessibility challenges and cognitive demands. Participants\u2019 experiences underscore the need to rethink accessibility in AI-driven coding environments. As AI continues to reshape software development, the design decisions made today will determine the inclusivity of the tech industry for years to come. Our findings call on researchers, designers, and industry leaders to make accessibility a priority in the development of next-generation AI tools, ensuring they empower all developers and foster equal opportunities in the field.",
    "type": "Text"
  },
  {
    "left": 73.0,
    "top": 430.0,
    "width": 429.0,
    "height": 37.0,
    "page_number": 21,
    "page_width": 612,
    "page_height": 792,
    "text": "ACKNOWLEDGMENTS. Special thanks to all the anonymous reviewers who helped us to strengthen the paper as well as the software developers who participated in the study. This work was partially supported by NSF grants 2339443 and 2403252.",
    "type": "Text"
  },
  {
    "left": 73.0,
    "top": 483.0,
    "width": 55.0,
    "height": 7.0,
    "page_number": 21,
    "page_width": 612,
    "page_height": 792,
    "text": "REFERENCES",
    "type": "Section header"
  },
  {
    "left": 79.0,
    "top": 498.0,
    "width": 422.0,
    "height": 16.0,
    "page_number": 21,
    "page_width": 612,
    "page_height": 792,
    "text": "[1] Shadi Abou-Zahra, Judy Brewer, and Michael Cooper. 2018. Artificial intelligence (AI) for web accessibility: Is conformance evaluation a way forward?. In Proceedings of the 15th international web for all conference . 1\u20134.",
    "type": "List item"
  },
  {
    "left": 80.0,
    "top": 518.0,
    "width": 422.0,
    "height": 16.0,
    "page_number": 21,
    "page_width": 612,
    "page_height": 792,
    "text": "[2] Rudaiba Adnin and Maitraye Das. 2024. \" I look at it as the king of knowledge\": How Blind People Use and Understand Generative AI Tools. In Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility . 1\u201314.",
    "type": "List item"
  },
  {
    "left": 80.0,
    "top": 538.0,
    "width": 421.0,
    "height": 16.0,
    "page_number": 21,
    "page_width": 612,
    "page_height": 792,
    "text": "[3] Faisal Ahmed, Yevgen Borodin, Yury Puzis, and IV Ramakrishnan. 2012. Why read if you can skim: towards enabling faster screen reading. In Proceedings of the International Cross-Disciplinary Conference on Web Accessibility . 1\u201310.",
    "type": "List item"
  },
  {
    "left": 80.0,
    "top": 557.0,
    "width": 421.0,
    "height": 16.0,
    "page_number": 21,
    "page_width": 612,
    "page_height": 792,
    "text": "[4] Humaid Al Naqbi, Zied Bahroun, and Vian Ahmed. 2024. Enhancing work productivity through generative artificial intelligence: A comprehensive literature review. Sustainability 16, 3 (2024), 1166.",
    "type": "List item"
  },
  {
    "left": 80.0,
    "top": 577.0,
    "width": 422.0,
    "height": 16.0,
    "page_number": 21,
    "page_width": 612,
    "page_height": 792,
    "text": "[5] Khaled Albusays and Stephanie Ludi. 2016. Eliciting programming challenges faced by developers with visual impairments: exploratory study. In Proceedings of the 9th International Workshop on Cooperative and Human Aspects of Software Engineering . 82\u201385.",
    "type": "List item"
  },
  {
    "left": 79.0,
    "top": 597.0,
    "width": 421.0,
    "height": 17.0,
    "page_number": 21,
    "page_width": 612,
    "page_height": 792,
    "text": "[6] Khaled Albusays, Stephanie Ludi, and Matt Huenerfauth. 2017. Interviews and observation of blind software developers at work to understand code navigation challenges. In Proceedings of the 19th International ACM SIGACCESS Conference on Computers and Accessibility . 91\u2013100.",
    "type": "List item"
  },
  {
    "left": 80.0,
    "top": 617.0,
    "width": 421.0,
    "height": 16.0,
    "page_number": 21,
    "page_width": 612,
    "page_height": 792,
    "text": "[7] Khaled L Albusays. 2020. The Role of Sonification as a Code Navigation Aid: Improving Programming Structure Readability and Understandability For Non-Visual Users . Rochester Institute of Technology.",
    "type": "List item"
  },
  {
    "left": 79.0,
    "top": 637.0,
    "width": 422.0,
    "height": 16.0,
    "page_number": 21,
    "page_width": 612,
    "page_height": 792,
    "text": "[8] Nasser Ali Aljarallah and Ashit Kumar Dutta. 2024. A Systematic Review on Developing Computer Programming Skills for Visually Impaired Students. Journal of Disability Research 3, 2 (2024), 20240018.",
    "type": "List item"
  },
  {
    "left": 414.0,
    "top": 658.0,
    "width": 87.0,
    "height": 7.0,
    "page_number": 21,
    "page_width": 612,
    "page_height": 792,
    "text": "Manuscript submitted to ACM",
    "type": "Page footer"
  },
  {
    "left": 109.0,
    "top": 70.0,
    "width": 10.0,
    "height": 8.0,
    "page_number": 22,
    "page_width": 612,
    "page_height": 792,
    "text": "22",
    "type": "Page header"
  },
  {
    "left": 463.0,
    "top": 70.0,
    "width": 77.0,
    "height": 8.0,
    "page_number": 22,
    "page_width": 612,
    "page_height": 792,
    "text": "Flores-Saviaga, et al.",
    "type": "Page header"
  },
  {
    "left": 116.0,
    "top": 99.0,
    "width": 424.0,
    "height": 15.0,
    "page_number": 22,
    "page_width": 612,
    "page_height": 792,
    "text": "[9] Humberto Lidio Antonelli, Leonardo Sensiate, Willian Massami Watanabe, and Renata Pontin de Mattos Fortes. 2019. Challenges of automatically evaluating rich internet applications accessibility. In Proceedings of the 37th ACM International Conference on the Design of Communication . 1\u20136.",
    "type": "List item"
  },
  {
    "left": 113.0,
    "top": 119.0,
    "width": 426.0,
    "height": 16.0,
    "page_number": 22,
    "page_width": 612,
    "page_height": 792,
    "text": "[10] Ameer Armaly, Paige Rodeghero, and Collin McMillan. 2018. Audiohighlight: Code skimming for blind programmers. In 2018 IEEE International Conference on Software Maintenance and Evolution (ICSME) . IEEE, 206\u2013216.",
    "type": "List item"
  },
  {
    "left": 113.0,
    "top": 139.0,
    "width": 425.0,
    "height": 16.0,
    "page_number": 22,
    "page_width": 612,
    "page_height": 792,
    "text": "[11] Catherine M Baker, Lauren R Milne, and Richard E Ladner. 2015. Structjumper: A tool to help blind programmers navigate and understand the structure of code. In Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems . 3043\u20133052.",
    "type": "List item"
  },
  {
    "left": 113.0,
    "top": 159.0,
    "width": 425.0,
    "height": 16.0,
    "page_number": 22,
    "page_width": 612,
    "page_height": 792,
    "text": "[12] Mark S Baldwin, Jennifer Mankoff, Bonnie Nardi, and Gillian Hayes. 2020. An activity centered approach to nonvisual computer interaction. ACM Transactions on Computer-Human Interaction (TOCHI) 27, 2 (2020), 1\u201327.",
    "type": "List item"
  },
  {
    "left": 113.0,
    "top": 179.0,
    "width": 425.0,
    "height": 16.0,
    "page_number": 22,
    "page_width": 612,
    "page_height": 792,
    "text": "[13] Saidarshan Bhagat, Padmaja Joshi, Avinash Agarwal, and Shubhanshu Gupta. 2024. Accessibility evaluation of major assistive mobile applications available for the visually impaired. arXiv preprint arXiv:2407.17496 (2024).",
    "type": "List item"
  },
  {
    "left": 113.0,
    "top": 199.0,
    "width": 426.0,
    "height": 26.0,
    "page_number": 22,
    "page_width": 612,
    "page_height": 792,
    "text": "[14] Jeffrey P Bigham, Chandrika Jayant, Hanjie Ji, Greg Little, Andrew Miller, Robert C Miller, Robin Miller, Aubrey Tatarowicz, Brandyn White, Samual White, et al. 2010. Vizwiz: nearly real-time answers to visual questions. In Proceedings of the 23nd annual ACM symposium on User interface software and technology . 333\u2013342.",
    "type": "List item"
  },
  {
    "left": 113.0,
    "top": 229.0,
    "width": 425.0,
    "height": 16.0,
    "page_number": 22,
    "page_width": 612,
    "page_height": 792,
    "text": "[15] Jeffrey P Bigham, Raja Kushalnagar, Ting-Hao Kenneth Huang, Juan Pablo Flores, and Saiph Savage. 2017. On how deaf people might use speech to control devices. In Proceedings of the 19th international ACM SIGACCESS conference on computers and accessibility . 383\u2013384.",
    "type": "List item"
  },
  {
    "left": 112.0,
    "top": 249.0,
    "width": 427.0,
    "height": 16.0,
    "page_number": 22,
    "page_width": 612,
    "page_height": 792,
    "text": "[16] Jeffrey P Bigham, Richard E Ladner, and Yevgen Borodin. 2011. The design of human-powered access technology. In The proceedings of the 13th international ACM SIGACCESS conference on Computers and accessibility . 3\u201310.",
    "type": "List item"
  },
  {
    "left": 113.0,
    "top": 269.0,
    "width": 426.0,
    "height": 16.0,
    "page_number": 22,
    "page_width": 612,
    "page_height": 792,
    "text": "[17] Jeffrey P Bigham, Irene Lin, and Saiph Savage. 2017. The Effects of\" Not Knowing What You Don\u2019t Know\" on Web Accessibility for Blind Web Users. In Proceedings of the 19th international ACM SIGACCESS conference on computers and accessibility . 101\u2013109.",
    "type": "List item"
  },
  {
    "left": 113.0,
    "top": 289.0,
    "width": 354.0,
    "height": 6.0,
    "page_number": 22,
    "page_width": 612,
    "page_height": 792,
    "text": "[18] Susanne Bodker. 1989. A human activity approach to user interfaces. Human-Computer Interaction 4, 3 (1989), 171\u2013195.",
    "type": "List item"
  },
  {
    "left": 113.0,
    "top": 299.0,
    "width": 318.0,
    "height": 6.0,
    "page_number": 22,
    "page_width": 612,
    "page_height": 792,
    "text": "[19] Susanne Bodker. 2021. Through the interface: A human activity approach to user interface design . CRC Press.",
    "type": "List item"
  },
  {
    "left": 113.0,
    "top": 309.0,
    "width": 426.0,
    "height": 16.0,
    "page_number": 22,
    "page_width": 612,
    "page_height": 792,
    "text": "[20] Yevgen Borodin, Jeffrey P Bigham, Glenn Dausch, and IV Ramakrishnan. 2010. More than meets the eye: a survey of screen-reader browsing strategies. In Proceedings of the 2010 International Cross Disciplinary Conference on Web Accessibility (W4A) . 1\u201310.",
    "type": "List item"
  },
  {
    "left": 113.0,
    "top": 328.0,
    "width": 304.0,
    "height": 9.0,
    "page_number": 22,
    "page_width": 612,
    "page_height": 792,
    "text": "[21] Hee Eon Byun and Keith Cheverst. 2004. Utilizing context history to provide dynamic adaptations.",
    "type": "Text"
  },
  {
    "left": 420.0,
    "top": 329.0,
    "width": 83.0,
    "height": 6.0,
    "page_number": 22,
    "page_width": 612,
    "page_height": 792,
    "text": "Applied Artificial Intelligence",
    "type": "Text"
  },
  {
    "left": 505.0,
    "top": 328.0,
    "width": 34.0,
    "height": 9.0,
    "page_number": 22,
    "page_width": 612,
    "page_height": 792,
    "text": "18, 6 (2004),",
    "type": "Text"
  },
  {
    "left": 129.0,
    "top": 337.0,
    "width": 25.0,
    "height": 9.0,
    "page_number": 22,
    "page_width": 612,
    "page_height": 792,
    "text": "533\u2013548.",
    "type": "Text"
  },
  {
    "left": 113.0,
    "top": 349.0,
    "width": 427.0,
    "height": 25.0,
    "page_number": 22,
    "page_width": 612,
    "page_height": 792,
    "text": "[22] Yoonha Cha, Victoria Jackson, Isabela Figueira, Stacy Marie Branham, and Andr\u00e9 Van der Hoek. 2024. Understanding the Career Mobility of Blind and Low Vision Software Professionals. In Proceedings of the 2024 IEEE/ACM 17th International Conference on Cooperative and Human Aspects of Software Engineering . 170\u2013181.",
    "type": "List item"
  },
  {
    "left": 113.0,
    "top": 378.0,
    "width": 425.0,
    "height": 16.0,
    "page_number": 22,
    "page_width": 612,
    "page_height": 792,
    "text": "[23] Khansa Chemnad and Achraf Othman. 2024. Digital accessibility in the era of artificial intelligence\u2014Bibliometric analysis and systematic review. Frontiers in Artificial Intelligence 7 (2024), 1349668.",
    "type": "List item"
  },
  {
    "left": 113.0,
    "top": 398.0,
    "width": 425.0,
    "height": 16.0,
    "page_number": 22,
    "page_width": 612,
    "page_height": 792,
    "text": "[24] Mark Chignell, Lu Wang, Atefeh Zare, and Jamy Li. 2023. The evolution of HCI and human factors: Integrating human and artificial intelligence. ACM Transactions on Computer-Human Interaction 30, 2 (2023), 1\u201330.",
    "type": "List item"
  },
  {
    "left": 113.0,
    "top": 418.0,
    "width": 426.0,
    "height": 16.0,
    "page_number": 22,
    "page_width": 612,
    "page_height": 792,
    "text": "[25] Chris Creed and Sayan Sarcar. 2024. Voice coding experiences for developers with physical impairments. Journal of Enabling Technologies 18, 4 (2024), 265\u2013275.",
    "type": "List item"
  },
  {
    "left": 113.0,
    "top": 438.0,
    "width": 425.0,
    "height": 16.0,
    "page_number": 22,
    "page_width": 612,
    "page_height": 792,
    "text": "[26] Arghavan Moradi Dakhel, Vahid Majdinasab, Amin Nikanjam, Foutse Khomh, Michel C Desmarais, and Zhen Ming Jack Jiang. 2023. Github copilot ai pair programmer: Asset or liability? Journal of Systems and Software 203 (2023), 111734.",
    "type": "List item"
  },
  {
    "left": 114.0,
    "top": 458.0,
    "width": 425.0,
    "height": 16.0,
    "page_number": 22,
    "page_width": 612,
    "page_height": 792,
    "text": "[27] Md Ehtesham-Ul-Haque, Syed Mostofa Monsur, and Syed Masum Billah. 2022. Grid-coding: An accessible, efficient, and structured coding paradigm for blind and low-vision programmers. In Proceedings of the 35th Annual ACM Symposium on User Interface Software and Technology . 1\u201321.",
    "type": "List item"
  },
  {
    "left": 113.0,
    "top": 478.0,
    "width": 347.0,
    "height": 6.0,
    "page_number": 22,
    "page_width": 612,
    "page_height": 792,
    "text": "[28] Yrj\u00f6 Engestr\u00f6m. 1987. An activity-theoretical approach to developmental research. Helsinki: Orienta-Konsultit (1987).",
    "type": "List item"
  },
  {
    "left": 113.0,
    "top": 488.0,
    "width": 420.0,
    "height": 6.0,
    "page_number": 22,
    "page_width": 612,
    "page_height": 792,
    "text": "[29] Y Engestr\u00f6m. 1999. Activity theory and individual and social transformation. Perspectives on activity theory/Cambridge University Press (1999).",
    "type": "List item"
  },
  {
    "left": 113.0,
    "top": 498.0,
    "width": 426.0,
    "height": 17.0,
    "page_number": 22,
    "page_width": 612,
    "page_height": 792,
    "text": "[30] Claudia Flores-Saviaga, Shangbin Feng, and Saiph Savage. 2022. Datavoidant: An ai system for addressing political data voids on social media. Proceedings of the ACM on human-computer interaction 6, CSCW2 (2022), 1\u201329.",
    "type": "List item"
  },
  {
    "left": 113.0,
    "top": 518.0,
    "width": 426.0,
    "height": 16.0,
    "page_number": 22,
    "page_width": 612,
    "page_height": 792,
    "text": "[31] Krzysztof Z Gajos, Jacob O Wobbrock, and Daniel S Weld. 2008. Improving the performance of motor-impaired users with automatically-generated, ability-based interfaces. In Proceedings of the SIGCHI conference on Human Factors in Computing Systems . 1257\u20131266.",
    "type": "List item"
  },
  {
    "left": 113.0,
    "top": 538.0,
    "width": 426.0,
    "height": 16.0,
    "page_number": 22,
    "page_width": 612,
    "page_height": 792,
    "text": "[32] St\u00e9phanie Giraud, Pierre Th\u00e9rouanne, and Dirk D Steiner. 2018. Web accessibility: Filtering redundant and irrelevant information improves website usability for blind users. International Journal of Human-Computer Studies 111 (2018), 23\u201335.",
    "type": "List item"
  },
  {
    "left": 113.0,
    "top": 558.0,
    "width": 419.0,
    "height": 6.0,
    "page_number": 22,
    "page_width": 612,
    "page_height": 792,
    "text": "[33] GitHub. 2022. GitHub Copilot now available for everyone . https://github.blog/2022-06-21-github-copilot-now-available/ Accessed: 2023-12-06.",
    "type": "List item"
  },
  {
    "left": 113.0,
    "top": 568.0,
    "width": 360.0,
    "height": 6.0,
    "page_number": 22,
    "page_width": 612,
    "page_height": 792,
    "text": "[34] GitHub. 2023. GitHub Copilot \u00b7 Your AI pair programmer. https://github.com/features/copilot Accessed: December 2023.",
    "type": "List item"
  },
  {
    "left": 113.0,
    "top": 578.0,
    "width": 427.0,
    "height": 26.0,
    "page_number": 22,
    "page_width": 612,
    "page_height": 792,
    "text": "[35] Cole Gleason, Dragan Ahmetovic, Saiph Savage, Carlos Toxtli, Carl Posthuma, Chieko Asakawa, Kris M Kitani, and Jeffrey P Bigham. 2018. Crowdsourcing the installation and maintenance of indoor localization infrastructure to support blind navigation. Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies 2, 1 (2018), 1\u201325.",
    "type": "List item"
  },
  {
    "left": 113.0,
    "top": 607.0,
    "width": 425.0,
    "height": 16.0,
    "page_number": 22,
    "page_width": 612,
    "page_height": 792,
    "text": "[36] Cole Gleason, Dragan Ahmetovic, Carlos Toxtli, Saiph Savage, Jeffrey P Bigham, and Chieko Asakawa. 2017. LuzDeploy: A collective action system for installing navigation infrastructure for blind people. In Proceedings of the 14th International Web for All Conference . 1\u20132.",
    "type": "List item"
  },
  {
    "left": 113.0,
    "top": 628.0,
    "width": 373.0,
    "height": 6.0,
    "page_number": 22,
    "page_width": 612,
    "page_height": 792,
    "text": "[37] Monica Hegde. 2023. User Experience Study of Screen Readers for Visually Challenged Users . Master\u2019s thesis. Purdue University.",
    "type": "List item"
  },
  {
    "left": 113.0,
    "top": 637.0,
    "width": 426.0,
    "height": 16.0,
    "page_number": 22,
    "page_width": 612,
    "page_height": 792,
    "text": "[38] Shawn Lawton Henry, Shadi Abou-Zahra, and Judy Brewer. 2014. The role of accessibility in a universal web. In Proceedings of the 11th Web for all Conference . 1\u20134.",
    "type": "List item"
  },
  {
    "left": 109.0,
    "top": 658.0,
    "width": 86.0,
    "height": 6.0,
    "page_number": 22,
    "page_width": 612,
    "page_height": 792,
    "text": "Manuscript submitted to ACM",
    "type": "Text"
  },
  {
    "left": 492.0,
    "top": 78.0,
    "width": 8.0,
    "height": 9.0,
    "page_number": 23,
    "page_width": 612,
    "page_height": 792,
    "text": "23",
    "type": "Page header"
  },
  {
    "left": 72.0,
    "top": 67.0,
    "width": 186.0,
    "height": 20.0,
    "page_number": 23,
    "page_width": 612,
    "page_height": 792,
    "text": "The Impact of Generative AI Coding Assistants on Developers Who Are Visually Impaired",
    "type": "Section header"
  },
  {
    "left": 76.0,
    "top": 99.0,
    "width": 426.0,
    "height": 16.0,
    "page_number": 23,
    "page_width": 612,
    "page_height": 792,
    "text": "[39] Xinyi Hou, Yanjie Zhao, Yue Liu, Zhou Yang, Kailong Wang, Li Li, Xiapu Luo, David Lo, John Grundy, and Haoyu Wang. 2024. Large language models for software engineering: A systematic literature review. ACM Transactions on Software Engineering and Methodology 33, 8 (2024), 1\u201379.",
    "type": "List item"
  },
  {
    "left": 76.0,
    "top": 118.0,
    "width": 425.0,
    "height": 16.0,
    "page_number": 23,
    "page_width": 612,
    "page_height": 792,
    "text": "[40] Yosef Jabareen. 2009. Building a conceptual framework: philosophy, definitions, and procedure. International journal of qualitative methods 8, 4 (2009), 49\u201362.",
    "type": "List item"
  },
  {
    "left": 77.0,
    "top": 138.0,
    "width": 413.0,
    "height": 6.0,
    "page_number": 23,
    "page_width": 612,
    "page_height": 792,
    "text": "[41] Sajed Jalil. 2023. The Transformative Influence of Large Language Models on Software Development. arXiv preprint arXiv:2311.16429 (2023).",
    "type": "List item"
  },
  {
    "left": 76.0,
    "top": 149.0,
    "width": 164.0,
    "height": 6.0,
    "page_number": 23,
    "page_width": 612,
    "page_height": 792,
    "text": "[42] Philip N Johnson-Laird. 1989. Mental models. (1989).",
    "type": "List item"
  },
  {
    "left": 76.0,
    "top": 158.0,
    "width": 426.0,
    "height": 17.0,
    "page_number": 23,
    "page_width": 612,
    "page_height": 792,
    "text": "[43] Shaun K Kane, Jeffrey P Bigham, and Jacob O Wobbrock. 2008. Slide rule: making mobile touch screens accessible to blind people using multi-touch interaction techniques. In Proceedings of the 10th international ACM SIGACCESS conference on Computers and accessibility . 73\u201380.",
    "type": "List item"
  },
  {
    "left": 76.0,
    "top": 179.0,
    "width": 348.0,
    "height": 6.0,
    "page_number": 23,
    "page_width": 612,
    "page_height": 792,
    "text": "[44] Victor Kaptelinin and Bonnie A Nardi. 2009. Acting with technology: Activity theory and interaction design . MIT press.",
    "type": "List item"
  },
  {
    "left": 77.0,
    "top": 189.0,
    "width": 403.0,
    "height": 6.0,
    "page_number": 23,
    "page_width": 612,
    "page_height": 792,
    "text": "[45] Victor Kaptelinin and Bonnie A Nardi. 2012. Activity theory in HCI: Fundamentals and reflections . Vol. 13. Morgan & Claypool Publishers.",
    "type": "List item"
  },
  {
    "left": 76.0,
    "top": 199.0,
    "width": 427.0,
    "height": 26.0,
    "page_number": 23,
    "page_width": 612,
    "page_height": 792,
    "text": "[46] Majeed Kazemitabaar, Justin Chow, Carl Ka To Ma, Barbara J Ericson, David Weintrop, and Tovi Grossman. 2023. Studying the effect of AI code generators on supporting novice learners in introductory programming. In Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems . 1\u201323.",
    "type": "List item"
  },
  {
    "left": 76.0,
    "top": 229.0,
    "width": 425.0,
    "height": 16.0,
    "page_number": 23,
    "page_width": 612,
    "page_height": 792,
    "text": "[47] B Kelly, L Phipps, and C Howell. 2005. Implementing a holistic approach to e-learning accessibility [Electronic version]. In Exploring the frontiers of e-learning: Borders, outposts and migration (ALT-C 2005 12th International Conference Research Proceedings). Retrieved November , Vol. 27. 2006.",
    "type": "List item"
  },
  {
    "left": 76.0,
    "top": 249.0,
    "width": 425.0,
    "height": 16.0,
    "page_number": 23,
    "page_width": 612,
    "page_height": 792,
    "text": "[48] Hourieh Khalajzadeh and John Grundy. 2024. Accessibility of low-code approaches: A systematic literature review. Information and Software Technology (2024), 107570.",
    "type": "List item"
  },
  {
    "left": 76.0,
    "top": 268.0,
    "width": 355.0,
    "height": 6.0,
    "page_number": 23,
    "page_width": 612,
    "page_height": 792,
    "text": "[49] Mukta Kulkarni. 2019. Digital accessibility: Challenges and opportunities. IIMB Management Review 31, 1 (2019), 91\u201398.",
    "type": "List item"
  },
  {
    "left": 76.0,
    "top": 279.0,
    "width": 426.0,
    "height": 16.0,
    "page_number": 23,
    "page_width": 612,
    "page_height": 792,
    "text": "[50] Thomas D LaToza, Gina Venolia, and Robert DeLine. 2006. Maintaining mental models: a study of developer work habits. In Proceedings of the 28th international conference on Software engineering . 492\u2013501.",
    "type": "List item"
  },
  {
    "left": 76.0,
    "top": 299.0,
    "width": 426.0,
    "height": 16.0,
    "page_number": 23,
    "page_width": 612,
    "page_height": 792,
    "text": "[51] Jonathan Lazar, Alfreda Dudley-Sponaugle, and Kisha-Dawn Greenidge. 2004. Improving web accessibility: a study of webmaster perceptions. Computers in human behavior 20, 2 (2004), 269\u2013288.",
    "type": "List item"
  },
  {
    "left": 76.0,
    "top": 319.0,
    "width": 237.0,
    "height": 6.0,
    "page_number": 23,
    "page_width": 612,
    "page_height": 792,
    "text": "[52] AN Le\u00f3ntiev. 1981. Problems of the development of the mind (Published 1931).",
    "type": "List item"
  },
  {
    "left": 76.0,
    "top": 328.0,
    "width": 233.0,
    "height": 6.0,
    "page_number": 23,
    "page_width": 612,
    "page_height": 792,
    "text": "[53] Aleksei Nikolaevich Leont\u2019ev. 1978. Activity, consciousness, and personality.",
    "type": "List item"
  },
  {
    "left": 76.0,
    "top": 338.0,
    "width": 426.0,
    "height": 26.0,
    "page_number": 23,
    "page_width": 612,
    "page_height": 792,
    "text": "[54] Bowen Li, Wenhan Wu, Ziwei Tang, Lin Shi, John Yang, Jinyang Li, Shunyu Yao, Chen Qian, Binyuan Hui, Qicheng Zhang, et al. 2025. Prompting Large Language Models to Tackle the Full Software Development Lifecycle: A Case Study. In Proceedings of the 31st International Conference on Computational Linguistics . 7511\u20137531.",
    "type": "List item"
  },
  {
    "left": 76.0,
    "top": 368.0,
    "width": 425.0,
    "height": 16.0,
    "page_number": 23,
    "page_width": 612,
    "page_height": 792,
    "text": "[55] Jenny T Liang, Chenyang Yang, and Brad A Myers. 2024. A large-scale survey on the usability of ai programming assistants: Successes and challenges. In Proceedings of the 46th IEEE/ACM International Conference on Software Engineering . 1\u201313.",
    "type": "List item"
  },
  {
    "left": 76.0,
    "top": 388.0,
    "width": 426.0,
    "height": 16.0,
    "page_number": 23,
    "page_width": 612,
    "page_height": 792,
    "text": "[56] Stephanie Ludi. 2015. Position paper: Towards making block-based programming accessible for blind users. In 2015 IEEE Blocks and Beyond Workshop (Blocks and Beyond) . IEEE, 67\u201369.",
    "type": "List item"
  },
  {
    "left": 76.0,
    "top": 408.0,
    "width": 426.0,
    "height": 26.0,
    "page_number": 23,
    "page_width": 612,
    "page_height": 792,
    "text": "[57] Stephanie Ludi, Jamie Simpson, and Wil Merchant. 2016. Exploration of the use of auditory cues in code comprehension and navigation for individuals with visual impairments in a visual programming environment. In Proceedings of the 18th International ACM SIGACCESS Conference on Computers and Accessibility . 279\u2013280.",
    "type": "List item"
  },
  {
    "left": 76.0,
    "top": 438.0,
    "width": 425.0,
    "height": 16.0,
    "page_number": 23,
    "page_width": 612,
    "page_height": 792,
    "text": "[58] Qianou Ma, Tongshuang Wu, and Kenneth Koedinger. 2023. Is AI the better programming partner? Human-Human pair programming vs. Human-AI pAIr programming. arXiv preprint arXiv:2306.05153 (2023).",
    "type": "List item"
  },
  {
    "left": 76.0,
    "top": 458.0,
    "width": 425.0,
    "height": 16.0,
    "page_number": 23,
    "page_width": 612,
    "page_height": 792,
    "text": "[59] Sean Mealin and Emerson Murphy-Hill. 2012. An exploratory study of blind software developers. In 2012 ieee symposium on visual languages and human-centric computing (vl/hcc) . IEEE, 71\u201374.",
    "type": "List item"
  },
  {
    "left": 76.0,
    "top": 478.0,
    "width": 295.0,
    "height": 6.0,
    "page_number": 23,
    "page_width": 612,
    "page_height": 792,
    "text": "[60] Matthew B Miles. 1994. Qualitative data analysis: An expanded sourcebook. Thousand Oaks (1994).",
    "type": "List item"
  },
  {
    "left": 76.0,
    "top": 488.0,
    "width": 426.0,
    "height": 16.0,
    "page_number": 23,
    "page_width": 612,
    "page_height": 792,
    "text": "[61] Meredith Ringel Morris, Jazette Johnson, Cynthia L Bennett, and Edward Cutrell. 2018. Rich representations of visual content for screen reader users. In Proceedings of the 2018 CHI conference on human factors in computing systems . 1\u201311.",
    "type": "List item"
  },
  {
    "left": 76.0,
    "top": 508.0,
    "width": 426.0,
    "height": 18.0,
    "page_number": 23,
    "page_width": 612,
    "page_height": 792,
    "text": "[62] Aboubakar Mountapmbeme, Obianuju Okafor, and Stephanie Ludi. 2022. Accessible blockly: An accessible block-based programming library for people with visual impairments. In Proceedings of the 24th International ACM SIGACCESS Conference on Computers and Accessibility . 1\u201315.",
    "type": "List item"
  },
  {
    "left": 76.0,
    "top": 528.0,
    "width": 426.0,
    "height": 16.0,
    "page_number": 23,
    "page_width": 612,
    "page_height": 792,
    "text": "[63] Aboubakar Mountapmbeme, Obianuju Okafor, and Stephanie Ludi. 2022. Addressing accessibility barriers in programming for people with visual impairments: A literature review. ACM Transactions on Accessible Computing (TACCESS) 15, 1 (2022), 1\u201326.",
    "type": "List item"
  },
  {
    "left": 76.0,
    "top": 548.0,
    "width": 426.0,
    "height": 17.0,
    "page_number": 23,
    "page_width": 612,
    "page_height": 792,
    "text": "[64] Omar Moured, Morris Baumgarten-Egemole, Karin M\u00fcller, Alina Roitberg, Thorsten Schwarz, and Rainer Stiefelhagen. 2024. Chart4blind: An intelligent interface for chart accessibility conversion. In Proceedings of the 29th International Conference on Intelligent User Interfaces . 504\u2013514.",
    "type": "List item"
  },
  {
    "left": 76.0,
    "top": 568.0,
    "width": 426.0,
    "height": 16.0,
    "page_number": 23,
    "page_width": 612,
    "page_height": 792,
    "text": "[65] Peya Mowar, Yi-Hao Peng, Aaron Steinfeld, and Jeffrey P Bigham. 2024. Tab to Autocomplete: The Effects of AI Coding Assistants on Web Accessibility. In Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility . 1\u20136.",
    "type": "List item"
  },
  {
    "left": 76.0,
    "top": 588.0,
    "width": 425.0,
    "height": 16.0,
    "page_number": 23,
    "page_width": 612,
    "page_height": 792,
    "text": "[66] Hussein Mozannar, Gagan Bansal, Adam Fourney, and Eric Horvitz. 2024. Reading between the lines: Modeling user behavior and costs in AI-assisted programming. In Proceedings of the CHI Conference on Human Factors in Computing Systems . 1\u201316.",
    "type": "List item"
  },
  {
    "left": 76.0,
    "top": 607.0,
    "width": 426.0,
    "height": 16.0,
    "page_number": 23,
    "page_width": 612,
    "page_height": 792,
    "text": "[67] Sydney Nguyen, Hannah McLean Babe, Yangtian Zi, Arjun Guha, Carolyn Jane Anderson, and Molly Q Feldman. 2024. How Beginning Programmers and Code LLMs (Mis) read Each Other. In Proceedings of the CHI Conference on Human Factors in Computing Systems . 1\u201326.",
    "type": "List item"
  },
  {
    "left": 76.0,
    "top": 627.0,
    "width": 303.0,
    "height": 6.0,
    "page_number": 23,
    "page_width": 612,
    "page_height": 792,
    "text": "[68] Jakob Nielsen. 2023. AI: First New UI Paradigm in 60 Years. Nielsen Norman Group 18, 06 (2023), 2023.",
    "type": "List item"
  },
  {
    "left": 76.0,
    "top": 637.0,
    "width": 426.0,
    "height": 16.0,
    "page_number": 23,
    "page_width": 612,
    "page_height": 792,
    "text": "[69] Sadia Nowrin, Patricia Ord\u00f3\u00f1ez, and Keith Vertanen. 2022. Exploring Motor-impaired Programmers\u2019 Use of Speech Recognition. In Proceedings of the 24th International ACM SIGACCESS Conference on Computers and Accessibility .",
    "type": "List item"
  },
  {
    "left": 414.0,
    "top": 658.0,
    "width": 87.0,
    "height": 6.0,
    "page_number": 23,
    "page_width": 612,
    "page_height": 792,
    "text": "Manuscript submitted to ACM",
    "type": "Page footer"
  },
  {
    "left": 109.0,
    "top": 70.0,
    "width": 9.0,
    "height": 8.0,
    "page_number": 24,
    "page_width": 612,
    "page_height": 792,
    "text": "24",
    "type": "Page header"
  },
  {
    "left": 463.0,
    "top": 70.0,
    "width": 75.0,
    "height": 8.0,
    "page_number": 24,
    "page_width": 612,
    "page_height": 792,
    "text": "Flores-Saviaga, et al.",
    "type": "Page header"
  },
  {
    "left": 113.0,
    "top": 99.0,
    "width": 425.0,
    "height": 16.0,
    "page_number": 24,
    "page_width": 612,
    "page_height": 792,
    "text": "[70] Shakked Noy and Whitney Zhang. 2023. Experimental evidence on the productivity effects of generative artificial intelligence. Science 381, 6654 (2023), 187\u2013192.",
    "type": "List item"
  },
  {
    "left": 113.0,
    "top": 118.0,
    "width": 425.0,
    "height": 17.0,
    "page_number": 24,
    "page_width": 612,
    "page_height": 792,
    "text": "[71] Sushil K Oswal and Hitender K Oswal. 2024. Examining the accessibility of generative AI website builder tools for blind and low vision users: 21 best practices for designers and developers. In 2024 IEEE International Professional Communication Conference (ProComm) . IEEE, 121\u2013128.",
    "type": "List item"
  },
  {
    "left": 113.0,
    "top": 139.0,
    "width": 327.0,
    "height": 6.0,
    "page_number": 24,
    "page_width": 612,
    "page_height": 792,
    "text": "[72] Linus P\u00e5hlstorp and Lukas Gwardak. 2007. Exploring usability guidelines for rich internet applications. (2007).",
    "type": "List item"
  },
  {
    "left": 113.0,
    "top": 149.0,
    "width": 425.0,
    "height": 16.0,
    "page_number": 24,
    "page_width": 612,
    "page_height": 792,
    "text": "[73] Sida Peng, Eirini Kalliamvakou, Peter Cihon, and Mert Demirer. 2023. The impact of ai on developer productivity: Evidence from github copilot. arXiv preprint arXiv:2302.06590 (2023).",
    "type": "List item"
  },
  {
    "left": 113.0,
    "top": 169.0,
    "width": 425.0,
    "height": 16.0,
    "page_number": 24,
    "page_width": 612,
    "page_height": 792,
    "text": "[74] Helen Petrie and Omar Kheir. 2007. The relationship between accessibility and usability of websites. In Proceedings of the SIGCHI conference on Human factors in computing systems . 397\u2013406.",
    "type": "List item"
  },
  {
    "left": 113.0,
    "top": 189.0,
    "width": 425.0,
    "height": 18.0,
    "page_number": 24,
    "page_width": 612,
    "page_height": 792,
    "text": "[75] Mahika Phutane, Crescentia Jung, Niu Chen, and Shiri Azenkot. 2023. Speaking with My Screen Reader: Using Audio Fictions to Explore Conversational Access to Interfaces. In Proceedings of the 25th International ACM SIGACCESS Conference on Computers and Accessibility . 1\u201318.",
    "type": "List item"
  },
  {
    "left": 112.0,
    "top": 209.0,
    "width": 425.0,
    "height": 16.0,
    "page_number": 24,
    "page_width": 612,
    "page_height": 792,
    "text": "[76] Augustin Popa. 2023. Using Copilot Chat with C++ in Visual Studio: Generate Code, Fix Functions, and More . https://devblogs.microsoft.com/ visualstudio/using-copilot-chat-with-c-in-visual-studio-generate-code-fix-functions-and-more/ Microsoft Visual Studio Blog.",
    "type": "List item"
  },
  {
    "left": 113.0,
    "top": 228.0,
    "width": 426.0,
    "height": 26.0,
    "page_number": 24,
    "page_width": 612,
    "page_height": 792,
    "text": "[77] Venkatesh Potluri, Maulishree Pandey, Andrew Begel, Michael Barnett, and Scott Reitherman. 2022. Codewalk: Facilitating shared awareness in mixed-ability collaborative software development. In Proceedings of the 24th International ACM SIGACCESS Conference on Computers and Accessibility . 1\u201316.",
    "type": "List item"
  },
  {
    "left": 113.0,
    "top": 258.0,
    "width": 426.0,
    "height": 26.0,
    "page_number": 24,
    "page_width": 612,
    "page_height": 792,
    "text": "[78] Venkatesh Potluri, Priyan Vaithilingam, Suresh Iyengar, Y Vidya, Manohar Swaminathan, and Gopal Srinivasa. 2018. Codetalk: Improving programming environment accessibility for visually impaired developers. In Proceedings of the 2018 chi conference on human factors in computing systems . 1\u201311.",
    "type": "List item"
  },
  {
    "left": 112.0,
    "top": 289.0,
    "width": 426.0,
    "height": 16.0,
    "page_number": 24,
    "page_width": 612,
    "page_height": 792,
    "text": "[79] Mercy Rajaselvi, F Jane Gloria, V Mohitha, and Guhan Selvarajan. 2021. A survey of programming editors for the visually impaired. Accessed: Aug 12 (2021).",
    "type": "List item"
  },
  {
    "left": 113.0,
    "top": 309.0,
    "width": 365.0,
    "height": 6.0,
    "page_number": 24,
    "page_width": 612,
    "page_height": 792,
    "text": "[80] Sharon M Ravitch and Matthew Riggan. 2016. Reason & rigor: How conceptual frameworks guide research . Sage Publications.",
    "type": "List item"
  },
  {
    "left": 113.0,
    "top": 319.0,
    "width": 426.0,
    "height": 16.0,
    "page_number": 24,
    "page_width": 612,
    "page_height": 792,
    "text": "[81] Joshua Robins. 2019. Barrier Determination Framework for Video Game Analysis Regarding Users with Visual Impairments . Ph. D. Dissertation. University of Huddersfield.",
    "type": "List item"
  },
  {
    "left": 113.0,
    "top": 338.0,
    "width": 425.0,
    "height": 16.0,
    "page_number": 24,
    "page_width": 612,
    "page_height": 792,
    "text": "[82] Hyman Rodman. 1980. Are conceptual frameworks necessary for theory building? The case of family sociology. Sociological Quarterly 21, 3 (1980), 429\u2013441.",
    "type": "List item"
  },
  {
    "left": 113.0,
    "top": 358.0,
    "width": 426.0,
    "height": 26.0,
    "page_number": 24,
    "page_width": 612,
    "page_height": 792,
    "text": "[83] Lucas Rosenblatt, Patrick Carrington, Kotaro Hara, and Jeffrey P. Bigham. 2018. Vocal Programming for People with Upper-Body Motor Impairments. In Proceedings of the 15th International Web for All Conference (Lyon, France) (W4A \u201918) . Association for Computing Machinery, New York, NY, USA, Article 30, 10 pages. https://doi.org/10.1145/3192714.3192821",
    "type": "List item"
  },
  {
    "left": 113.0,
    "top": 388.0,
    "width": 426.0,
    "height": 16.0,
    "page_number": 24,
    "page_width": 612,
    "page_height": 792,
    "text": "[84] Daniel Russo. 2024. Navigating the complexity of generative ai adoption in software engineering. ACM Transactions on Software Engineering and Methodology (2024).",
    "type": "List item"
  },
  {
    "left": 113.0,
    "top": 408.0,
    "width": 424.0,
    "height": 16.0,
    "page_number": 24,
    "page_width": 612,
    "page_height": 792,
    "text": "[85] Saiph Savage, Claudia Flores-Saviaga, Rachel Rodney, Liliana Savage, Jon Schull, and Jennifer Mankoff. 2022. The global care ecosystems of 3D printed assistive devices. ACM Transactions on Accessible Computing 15, 4 (2022), 1\u201329.",
    "type": "List item"
  },
  {
    "left": 113.0,
    "top": 427.0,
    "width": 426.0,
    "height": 17.0,
    "page_number": 24,
    "page_width": 612,
    "page_height": 792,
    "text": "[86] Ather Sharif, Sanjana Shivani Chintalapati, Jacob O Wobbrock, and Katharina Reinecke. 2021. Understanding screen-reader users\u2019 experiences with online data visualizations. In Proceedings of the 23rd International ACM SIGACCESS Conference on Computers and Accessibility . 1\u201316.",
    "type": "List item"
  },
  {
    "left": 113.0,
    "top": 448.0,
    "width": 281.0,
    "height": 6.0,
    "page_number": 24,
    "page_width": 612,
    "page_height": 792,
    "text": "[87] Thomas B Sheridan. 1992. Telerobotics, automation, and human supervisory control . MIT press.",
    "type": "List item"
  },
  {
    "left": 113.0,
    "top": 458.0,
    "width": 425.0,
    "height": 16.0,
    "page_number": 24,
    "page_width": 612,
    "page_height": 792,
    "text": "[88] Patricia M Shields and Nandhini Rangarajan. 2013. A playbook for research methods: Integrating conceptual frameworks and project management New Forums Press.",
    "type": "List item"
  },
  {
    "left": 538.0,
    "top": 457.0,
    "width": 2.0,
    "height": 9.0,
    "page_number": 24,
    "page_width": 612,
    "page_height": 792,
    "text": ".",
    "type": "Text"
  },
  {
    "left": 113.0,
    "top": 478.0,
    "width": 427.0,
    "height": 26.0,
    "page_number": 24,
    "page_width": 612,
    "page_height": 792,
    "text": "[89] Kristen Shinohara, Murtaza Tamjeed, Michael McQuaid, and Dymen A. Barkins. 2022. Usability, Accessibility and Social Entanglements in Advanced Tool Use by Vision Impaired Graduate Students. Proc. ACM Hum.-Comput. Interact. 6, CSCW2, Article 551 (nov 2022), 21 pages. https://doi.org/10.1145/3555609",
    "type": "List item"
  },
  {
    "left": 113.0,
    "top": 508.0,
    "width": 425.0,
    "height": 17.0,
    "page_number": 24,
    "page_width": 612,
    "page_height": 792,
    "text": "[90] Ann C Smith, Justin S Cook, Joan M Francioni, Asif Hossain, Mohd Anwar, and M Fayezur Rahman. 2003. Nonvisual tool for navigating hierarchical structures. ACM SIGACCESS Accessibility and Computing 77-78 (2003), 133\u2013139.",
    "type": "List item"
  },
  {
    "left": 113.0,
    "top": 528.0,
    "width": 426.0,
    "height": 16.0,
    "page_number": 24,
    "page_width": 612,
    "page_height": 792,
    "text": "[91] Mads Soegaard and Rikke Friis Dam. 2012. The encyclopedia of human-computer interaction. The encyclopedia of human-computer interaction (2012).",
    "type": "List item"
  },
  {
    "left": 113.0,
    "top": 548.0,
    "width": 357.0,
    "height": 6.0,
    "page_number": 24,
    "page_width": 612,
    "page_height": 792,
    "text": "[92] Stack Overflow. 2022. Stack Overflow Developer Survey 2022 . https://survey.stackoverflow.co/2022/ Accessed: 2023-12-06.",
    "type": "List item"
  },
  {
    "left": 114.0,
    "top": 558.0,
    "width": 425.0,
    "height": 16.0,
    "page_number": 24,
    "page_width": 612,
    "page_height": 792,
    "text": "[93] Stack Overflow. 2023. Stack Overflow Developer Survey 2023 . https://visualstudiomagazine.com/articles/2023/06/28/so-2023.aspx Accessed: 2023-12-06.",
    "type": "List item"
  },
  {
    "left": 113.0,
    "top": 578.0,
    "width": 425.0,
    "height": 16.0,
    "page_number": 24,
    "page_width": 612,
    "page_height": 792,
    "text": "[94] Andreas Stefik, Roger Alexander, Robert Patterson, and Jonathan Brown. 2007. WAD: A feasibility study using the wicked audio debugger. In 15th IEEE International Conference on Program Comprehension (ICPC\u201907) . 69\u201380.",
    "type": "List item"
  },
  {
    "left": 113.0,
    "top": 597.0,
    "width": 425.0,
    "height": 9.0,
    "page_number": 24,
    "page_width": 612,
    "page_height": 792,
    "text": "[95] Andreas M Stefik, Christopher Hundhausen, and Derrick Smith. 2011. On the design of an educational infrastructure for the blind and visually",
    "type": "Text"
  },
  {
    "left": 129.0,
    "top": 606.0,
    "width": 93.0,
    "height": 9.0,
    "page_number": 24,
    "page_width": 612,
    "page_height": 792,
    "text": "impaired in computer science. In",
    "type": "Text"
  },
  {
    "left": 224.0,
    "top": 608.0,
    "width": 227.0,
    "height": 6.0,
    "page_number": 24,
    "page_width": 612,
    "page_height": 792,
    "text": "Proceedings of the 42nd ACM technical symposium on Computer science education",
    "type": "Text"
  },
  {
    "left": 451.0,
    "top": 606.0,
    "width": 28.0,
    "height": 9.0,
    "page_number": 24,
    "page_width": 612,
    "page_height": 792,
    "text": ". 571\u2013576.",
    "type": "Text"
  },
  {
    "left": 113.0,
    "top": 618.0,
    "width": 426.0,
    "height": 25.0,
    "page_number": 24,
    "page_width": 612,
    "page_height": 792,
    "text": "[96] Sarit Felicia Anais Szpiro, Shafeka Hashash, Yuhang Zhao, and Shiri Azenkot. 2016. How people with low vision access computing devices: Understanding challenges and opportunities. In Proceedings of the 18th International ACM SIGACCESS Conference on Computers and Accessibility . 171\u2013180.",
    "type": "List item"
  },
  {
    "left": 109.0,
    "top": 658.0,
    "width": 86.0,
    "height": 6.0,
    "page_number": 24,
    "page_width": 612,
    "page_height": 792,
    "text": "Manuscript submitted to ACM",
    "type": "Text"
  },
  {
    "left": 492.0,
    "top": 78.0,
    "width": 8.0,
    "height": 9.0,
    "page_number": 25,
    "page_width": 612,
    "page_height": 792,
    "text": "25",
    "type": "Page header"
  },
  {
    "left": 72.0,
    "top": 67.0,
    "width": 186.0,
    "height": 20.0,
    "page_number": 25,
    "page_width": 612,
    "page_height": 792,
    "text": "The Impact of Generative AI Coding Assistants on Developers Who Are Visually Impaired",
    "type": "Section header"
  },
  {
    "left": 76.0,
    "top": 99.0,
    "width": 425.0,
    "height": 16.0,
    "page_number": 25,
    "page_width": 612,
    "page_height": 792,
    "text": "[97] Delphine Szymczak. 2023. Tools in and out of sight: an analysis informed by Cultural-Historical Activity Theory of audio-haptic activities involving people with visual impairments supported by technology. (2023).",
    "type": "List item"
  },
  {
    "left": 77.0,
    "top": 118.0,
    "width": 425.0,
    "height": 17.0,
    "page_number": 25,
    "page_width": 612,
    "page_height": 792,
    "text": "[98] A Tlili et al. 2021. Game-based learning for learners with disabilities\u2013what is next? A systematic literature review from the activity theory perspective. Front. Psychol. 12, 814691 (2022).",
    "type": "List item"
  },
  {
    "left": 75.0,
    "top": 139.0,
    "width": 426.0,
    "height": 16.0,
    "page_number": 25,
    "page_width": 612,
    "page_height": 792,
    "text": "[99] Emmanuel Utreras and Enrico Pontelli. 2020. Accessibility of block-based introductory programming languages and a tangible programming tool prototype. In International Conference on Computers Helping People with Special Needs . Springer, 27\u201334.",
    "type": "List item"
  },
  {
    "left": 73.0,
    "top": 159.0,
    "width": 428.0,
    "height": 16.0,
    "page_number": 25,
    "page_width": 612,
    "page_height": 792,
    "text": "[100] Priyan Vaithilingam, Tianyi Zhang, and Elena L Glassman. 2022. Expectation vs. experience: Evaluating the usability of code generation tools powered by large language models. In Chi conference on human factors in computing systems extended abstracts . 1\u20137.",
    "type": "List item"
  },
  {
    "left": 73.0,
    "top": 179.0,
    "width": 428.0,
    "height": 16.0,
    "page_number": 25,
    "page_width": 612,
    "page_height": 792,
    "text": "[101] Visual Studio Code Documentation. 2023. GitHub Copilot Overview: Seamless Integration with Visual Studio Code . https://code.visualstudio.com/ docs/copilot/overview Accessed: 2023-12-06.",
    "type": "List item"
  },
  {
    "left": 73.0,
    "top": 199.0,
    "width": 178.0,
    "height": 7.0,
    "page_number": 25,
    "page_width": 612,
    "page_height": 792,
    "text": "[102] Lev S Vygotsky. 2012. Thought and language . MIT press.",
    "type": "List item"
  },
  {
    "left": 73.0,
    "top": 208.0,
    "width": 429.0,
    "height": 17.0,
    "page_number": 25,
    "page_width": 612,
    "page_height": 792,
    "text": "[103] Ruotong Wang, Ruijia Cheng, Denae Ford, and Thomas Zimmermann. 2024. Investigating and designing for trust in ai-powered code generation tools. In The 2024 ACM Conference on Fairness, Accountability, and Transparency .",
    "type": "List item"
  },
  {
    "left": 73.0,
    "top": 228.0,
    "width": 429.0,
    "height": 17.0,
    "page_number": 25,
    "page_width": 612,
    "page_height": 792,
    "text": "[104] Justin D Weisz, Jessica He, Michael Muller, Gabriela Hoefer, Rachel Miles, and Werner Geyer. 2024. Design Principles for Generative AI Applications. In Proceedings of the CHI Conference on Human Factors in Computing Systems .",
    "type": "List item"
  },
  {
    "left": 73.0,
    "top": 249.0,
    "width": 429.0,
    "height": 16.0,
    "page_number": 25,
    "page_width": 612,
    "page_height": 792,
    "text": "[105] Man-Fai Wong, Shangxin Guo, Ching-Nam Hang, Siu-Wai Ho, and Chee-Wei Tan. 2023. Natural language generation and understanding of big code for AI-assisted programming: A review. Entropy 25, 6 (2023), 888.",
    "type": "List item"
  },
  {
    "left": 73.0,
    "top": 269.0,
    "width": 391.0,
    "height": 6.0,
    "page_number": 25,
    "page_width": 612,
    "page_height": 792,
    "text": "[106] Jason Yu and Cheryl Qi. 2024. The Impact of Generative AI on Employment and Labor Productivity. Review of Business 44, 1 (2024).",
    "type": "List item"
  },
  {
    "left": 73.0,
    "top": 279.0,
    "width": 428.0,
    "height": 16.0,
    "page_number": 25,
    "page_width": 612,
    "page_height": 792,
    "text": "[107] Lotus Zhang, Simon Sun, and Leah Findlater. 2023. Understanding Digital Content Creation Needs of Blind and Low Vision People. In Proceedings of the 25th International ACM SIGACCESS Conference on Computers and Accessibility .",
    "type": "List item"
  },
  {
    "left": 73.0,
    "top": 299.0,
    "width": 430.0,
    "height": 26.0,
    "page_number": 25,
    "page_width": 612,
    "page_height": 792,
    "text": "[108] Albert Ziegler, Eirini Kalliamvakou, X Alice Li, Andrew Rice, Devon Rifkin, Shawn Simister, Ganesh Sittampalam, and Edward Aftandilian. 2022. Productivity assessment of neural code completion. In Proceedings of the 6th ACM SIGPLAN International Symposium on Machine Programming . 21\u201329.",
    "type": "List item"
  },
  {
    "left": 73.0,
    "top": 329.0,
    "width": 428.0,
    "height": 16.0,
    "page_number": 25,
    "page_width": 612,
    "page_height": 792,
    "text": "[109] Jonathan Zong, Crystal Lee, Alan Lundgard, JiWoong Jang, Daniel Hajas, and Arvind Satyanarayan. 2022. Rich screen reader experiences for accessible data visualization. In Computer Graphics Forum , Vol. 41. Wiley Online Library.",
    "type": "List item"
  },
  {
    "left": 414.0,
    "top": 658.0,
    "width": 87.0,
    "height": 7.0,
    "page_number": 25,
    "page_width": 612,
    "page_height": 792,
    "text": "Manuscript submitted to ACM",
    "type": "Page footer"
  }
]